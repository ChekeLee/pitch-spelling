{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fosfrancesco/pitch-spelling/blob/main/rnncrf_pitch_spelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fifMg_hxNSOg",
    "outputId": "a8b320f9-4231-40d9-8f10-a7b8acd1da37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-crf\n",
      "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "hsciybUBNkur"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "import music21 as m21\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn\n",
    "import music21 as m21\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchcrf import CRF\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "# import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Naq6UG5jRbyK"
   },
   "source": [
    "# RNN-CRF for Pitch Spelling\n",
    "\n",
    "Dataset: different authors from ASAP collection\n",
    "Challenges:\n",
    "- extremely long sequences\n",
    "- small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mHJvrZ2Wo_e",
    "outputId": "1319f78b-cfb1-4e2a-937c-c47cf952757c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'C'), (1, 'B#'), (2, 'D--'), (3, 'C#'), (4, 'B##'), (5, 'D-'), (6, 'D'), (7, 'C##'), (8, 'E--'), (9, 'D#'), (10, 'E-'), (11, 'F--'), (12, 'E'), (13, 'D##'), (14, 'F-'), (15, 'F'), (16, 'E#'), (17, 'G--'), (18, 'F#'), (19, 'E##'), (20, 'G-'), (21, 'G'), (22, 'F##'), (23, 'A--'), (24, 'G#'), (25, 'A-'), (26, 'A'), (27, 'G##'), (28, 'B--'), (29, 'A#'), (30, 'B-'), (31, 'C--'), (32, 'B'), (33, 'A##'), (34, 'C-')]\n",
      "['D--', 'B##', 'C##', 'E--', 'F--', 'D##', 'G--', 'E##', 'F##', 'A--', 'G##', 'B--', 'C--', 'A##']\n",
      "[(0, 'P1'), (1, 'd2'), (2, 'A7'), (3, 'm2'), (4, 'A1'), (5, 'M2'), (6, 'd3'), (7, 'AA1'), (8, 'm3'), (9, 'A2'), (10, 'M3'), (11, 'd4'), (12, 'AA2'), (13, 'P4'), (14, 'A3'), (15, 'd5'), (16, 'A4'), (17, 'P5'), (18, 'd6'), (19, 'AA4'), (20, 'm6'), (21, 'A5'), (22, 'M6'), (23, 'd7'), (24, 'AA5'), (25, 'm7'), (26, 'A6'), (27, 'M7'), (28, 'd1'), (29, 'AA6')]\n"
     ]
    }
   ],
   "source": [
    "pitches_dict = {\n",
    "    0 : [\"C\",\"B#\",\"D--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    1 : [\"C#\",\"B##\",\"D-\"], # nn.Linear(input_size+context_size, 2)\n",
    "    2 : [\"D\",\"C##\",\"E--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    3 : [\"D#\",\"E-\",\"F--\"],\n",
    "    4 : [\"E\",\"D##\",\"F-\"],\n",
    "    5 : [\"F\",\"E#\",\"G--\"],\n",
    "    6 : [\"F#\",\"E##\",\"G-\"],\n",
    "    7 : [\"G\",\"F##\",\"A--\"],\n",
    "    8 : [\"G#\",\"A-\"],\n",
    "    9 : [\"A\",\"G##\",\"B--\"],\n",
    "    10 : [\"A#\",\"B-\",\"C--\"],\n",
    "    11 : [\"B\",\"A##\",\"C-\"]\n",
    "}\n",
    "\n",
    "accepted_pitches = [ii for i in pitches_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_pitches)])\n",
    "\n",
    "double_acc_pitches = [ii for i in pitches_dict.values() for ii in i if ii.endswith(\"##\") or  ii.endswith(\"--\") ]\n",
    "print(double_acc_pitches)\n",
    "\n",
    "def score2midi_numbers(score):\n",
    "    return [p.midi%12 for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "def score2pitches(score):\n",
    "    return [p.name for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "interval_dict = {\n",
    "    0 : [\"P1\",\"d2\",\"A7\"], \n",
    "    1 : [\"m2\",\"A1\"], \n",
    "    2 : [\"M2\",\"d3\",\"AA1\"], \n",
    "    3 : [\"m3\",\"A2\"],\n",
    "    4 : [\"M3\",\"d4\",\"AA2\"],\n",
    "    5 : [\"P4\",\"A3\"],\n",
    "    6 : [\"d5\",\"A4\"],\n",
    "    7 : [\"P5\",\"d6\",\"AA4\"],\n",
    "    8 : [\"m6\",\"A5\"],\n",
    "    9 : [\"M6\",\"d7\",\"AA5\"],\n",
    "    10 : [\"m7\",\"A6\"],\n",
    "    11 : [\"M7\",\"d1\",\"AA6\"]\n",
    "}\n",
    "\n",
    "accepted_intervals = [ii for i in interval_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_intervals)])\n",
    "\n",
    "def transp_score(score):\n",
    "    \"\"\" For each input return len(accepted_intervals) transposed scores\"\"\"\n",
    "    return [score.transpose(interval) for interval in accepted_intervals]\n",
    "\n",
    "def smart_transp_score(score):\n",
    "    \"\"\" For each chromatic interval chose the interval that lead to the smallest number of accidentals\"\"\"\n",
    "    scores = []\n",
    "    for chromatic_int in interval_dict.keys():\n",
    "        temp_scores = []\n",
    "        temp_acc_number = []\n",
    "        for diat_interval in interval_dict[chromatic_int]:\n",
    "            new_score = score.transpose(diat_interval)\n",
    "            temp_scores.append(new_score)\n",
    "            temp_acc_number.append(sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in score2pitches(new_score)]))\n",
    "            # print(\"choice:\", [note.name for note in temp_scores[-1].flat.notes][0:10],\"acc:\",temp_acc_number[-1] )\n",
    "        #keep only the one with the lowest number of accidentals\n",
    "        min_index = np.argmin(temp_acc_number)\n",
    "        # print(\"preferred the number\", min_index)\n",
    "        scores.append(temp_scores[min_index])\n",
    "    return scores\n",
    "\n",
    "def acc_simple_enough(score,accepted_ratio = 0.2 ):\n",
    "    pitches = score2pitches(score)\n",
    "    double_acc = sum(el in double_acc_pitches for el in pitches)\n",
    "    if double_acc/len(pitches) < accepted_ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "diatonic_pitches = [\"C\",\"D\", \"E\", \"F\", \"G\", \"A\", \"B\"]\n",
    "\n",
    "# #test acc_simple_enough()\n",
    "# score = m21.converter.parse(paths[356])\n",
    "# scores = smart_transp_score(score)\n",
    "# #delete the pieces with non accepted pitches (e.g. triple sharps)\n",
    "# scores = [s for s in scores if all(pitch in accepted_pitches for pitch in score2pitches(s))]\n",
    "# for s in scores:\n",
    "#     print(s.parts[0].flat.getElementsByClass(m21.key.KeySignature)[0], \"simple enough:\", acc_simple_enough(s))\n",
    "#     print([n.name for n in s.flat.notes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw-SuL4ZB_2C"
   },
   "source": [
    "## Import ASAP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrZ0BwLEj2Gp",
    "outputId": "6b521f78-28db-4d4f-f4ef-9345c5d91db9"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/fosfrancesco/pitch-spelling.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "WaINjDS2kpxE"
   },
   "outputs": [],
   "source": [
    "basepath = \"./\" #to change if running locally or on colab\n",
    "\n",
    "# load the asap datasets\n",
    "with open(Path(basepath,'datasets','baroque_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_baroque = pickle.load( fid)\n",
    "\n",
    "with open(Path(basepath,'datasets','classical_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_classical = pickle.load( fid)\n",
    "\n",
    "with open(Path(basepath,'datasets','romantic_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_romantic = pickle.load( fid)\n",
    "        \n",
    "with open(Path(basepath,'datasets','remaining_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_remaining = pickle.load( fid)\n",
    "\n",
    "# merge the three files together\n",
    "full_dict_dataset = dataset_baroque + dataset_classical + dataset_romantic + dataset_remaining\n",
    "# full_dict_dataset = dataset_baroque + dataset_classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYQdkJAiTS6_",
    "outputId": "72835948-2884-40bb-e5b4-6ebbc8488895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 different pieces\n",
      "Average number of notes:  2410.253424657534\n"
     ]
    }
   ],
   "source": [
    "paths = list(set([e[\"original_path\"] for e in full_dict_dataset ]))\n",
    "\n",
    "# print(paths)\n",
    "print(len(paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_dict_dataset ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMdKkzNnCTrK"
   },
   "source": [
    "## Chose the convenient data augmentation\n",
    "Two possibilities:\n",
    "- for each chromatic interval, take only the diatonic transposition that produce the smallest number of accidentals (or the original if present)\n",
    "- take only a certain interval of time signatures\n",
    "\n",
    "The second is probably better for a smaller and simple dataset, but gives the problem of chosing between for example F# and G# that are both present in this bigger dataset. So we go for the first criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oign7EZ9BSX4",
    "outputId": "9aa3f694-289a-43fd-fd14-9cad3b8dd3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No options for Ravel/Miroirs/4_Alborada_del_gracioso/xml_score.musicxml . Chromatic:  11\n",
      "No options for Scriabin/Sonatas/5/xml_score.musicxml . Chromatic:  1\n",
      "No options for Scriabin/Sonatas/5/xml_score.musicxml . Chromatic:  6\n",
      "No options for Scriabin/Sonatas/5/xml_score.musicxml . Chromatic:  11\n",
      "No options for Liszt/Mephisto_Waltz/xml_score.musicxml . Chromatic:  11\n",
      "No options for Liszt/Transcendental_Etudes/9/xml_score.musicxml . Chromatic:  6\n",
      "No options for Liszt/Transcendental_Etudes/9/xml_score.musicxml . Chromatic:  11\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  1\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  4\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  6\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  9\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  1\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  3\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  8\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  10\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  11\n",
      "No options for Ravel/Gaspard_de_la_Nuit/1_Ondine/xml_score.musicxml . Chromatic:  4\n",
      "No options for Debussy/Images_Book_1/1_Reflets_dans_lEau/xml_score.musicxml . Chromatic:  3\n",
      "No options for Debussy/Images_Book_1/1_Reflets_dans_lEau/xml_score.musicxml . Chromatic:  8\n",
      "No options for Liszt/Transcendental_Etudes/10/xml_score.musicxml . Chromatic:  1\n",
      "No options for Liszt/Transcendental_Etudes/10/xml_score.musicxml . Chromatic:  6\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  1\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  4\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  6\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  9\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  11\n",
      "No options for Liszt/Transcendental_Etudes/11/xml_score.musicxml . Chromatic:  1\n",
      "No options for Liszt/Transcendental_Etudes/11/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml . Chromatic:  1\n",
      "No options for Liszt/Transcendental_Etudes/4/xml_score.musicxml . Chromatic:  2\n",
      "No options for Liszt/Transcendental_Etudes/4/xml_score.musicxml . Chromatic:  4\n",
      "No options for Liszt/Transcendental_Etudes/4/xml_score.musicxml . Chromatic:  9\n",
      "No options for Liszt/Sonata/xml_score.musicxml . Chromatic:  4\n",
      "No options for Liszt/Sonata/xml_score.musicxml . Chromatic:  6\n",
      "No options for Liszt/Sonata/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Ballades/4/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  9\n",
      "Bach/Fugue/bwv_867/xml_score.musicxml P1 -5\n",
      "['B-', 'F', 'G-', 'F', 'E-', 'D-', 'F', 'C', 'D-', 'B-']\n",
      "[10, 5, 6, 5, 3, 1, 5, 0, 1, 10]\n",
      "Bach/Fugue/bwv_867/xml_score.musicxml A1 2\n",
      "['B', 'F#', 'G', 'F#', 'E', 'D', 'F#', 'C#', 'D', 'B']\n",
      "[11, 6, 7, 6, 4, 2, 6, 1, 2, 11]\n",
      "Bach/Fugue/bwv_867/xml_score.musicxml M2 -3\n",
      "['C', 'G', 'A-', 'G', 'F', 'E-', 'G', 'D', 'E-', 'C']\n",
      "[0, 7, 8, 7, 5, 3, 7, 2, 3, 0]\n",
      "Bach/Fugue/bwv_867/xml_score.musicxml A2 4\n",
      "['C#', 'G#', 'A', 'G#', 'F#', 'E', 'G#', 'D#', 'E', 'C#']\n",
      "[1, 8, 9, 8, 6, 4, 8, 3, 4, 1]\n",
      "Bach/Fugue/bwv_867/xml_score.musicxml M3 -1\n",
      "['D', 'A', 'B-', 'A', 'G', 'F', 'A', 'E', 'F', 'D']\n",
      "[2, 9, 10, 9, 7, 5, 9, 4, 5, 2]\n",
      "Bach/Fugue/bwv_867/xml_score.musicxml P4 -6\n",
      "['E-', 'B-', 'C-', 'B-', 'A-', 'G-', 'B-', 'F', 'G-', 'E-']\n",
      "[3, 10, 11, 10, 8, 6, 10, 5, 6, 3]\n",
      "Bach/Fugue/bwv_867/xml_score.musicxml A4 1\n",
      "['E', 'B', 'C', 'B', 'A', 'G', 'B', 'F#', 'G', 'E']\n",
      "[4, 11, 0, 11, 9, 7, 11, 6, 7, 4]\n",
      "Bach/Fugue/bwv_867/xml_score.musicxml P5 -4\n",
      "['F', 'C', 'D-', 'C', 'B-', 'A-', 'C', 'G', 'A-', 'F']\n",
      "[5, 0, 1, 0, 10, 8, 0, 7, 8, 5]\n",
      "Bach/Fugue/bwv_867/xml_score.musicxml A5 3\n",
      "['F#', 'C#', 'D', 'C#', 'B', 'A', 'C#', 'G#', 'A', 'F#']\n",
      "[6, 1, 2, 1, 11, 9, 1, 8, 9, 6]\n",
      "Bach/Fugue/bwv_867/xml_score.musicxml M6 -2\n",
      "['G', 'D', 'E-', 'D', 'C', 'B-', 'D', 'A', 'B-', 'G']\n",
      "[7, 2, 3, 2, 0, 10, 2, 9, 10, 7]\n",
      "Bach/Fugue/bwv_867/xml_score.musicxml A6 5\n",
      "['G#', 'D#', 'E', 'D#', 'C#', 'B', 'D#', 'A#', 'B', 'G#']\n",
      "[8, 3, 4, 3, 1, 11, 3, 10, 11, 8]\n",
      "Bach/Fugue/bwv_867/xml_score.musicxml M7 0\n",
      "['A', 'E', 'F', 'E', 'D', 'C', 'E', 'B', 'C', 'A']\n",
      "[9, 4, 5, 4, 2, 0, 4, 11, 0, 9]\n",
      "Beethoven/Piano_Sonatas/7-1/xml_score.musicxml P1 2\n",
      "['D', 'D', 'D', 'C#', 'C#', 'B', 'B', 'A', 'A', 'C#']\n",
      "[2, 2, 2, 1, 1, 11, 11, 9, 9, 1]\n",
      "Beethoven/Piano_Sonatas/7-1/xml_score.musicxml m2 -3\n",
      "['E-', 'E-', 'E-', 'D', 'D', 'C', 'C', 'B-', 'B-', 'D']\n",
      "[3, 3, 3, 2, 2, 0, 0, 10, 10, 2]\n",
      "Beethoven/Piano_Sonatas/7-1/xml_score.musicxml M2 4\n",
      "['E', 'E', 'E', 'D#', 'D#', 'C#', 'C#', 'B', 'B', 'D#']\n",
      "[4, 4, 4, 3, 3, 1, 1, 11, 11, 3]\n",
      "Beethoven/Piano_Sonatas/7-1/xml_score.musicxml m3 -1\n",
      "['F', 'F', 'F', 'E', 'E', 'D', 'D', 'C', 'C', 'E']\n",
      "[5, 5, 5, 4, 4, 2, 2, 0, 0, 4]\n",
      "Beethoven/Piano_Sonatas/7-1/xml_score.musicxml M3 6\n",
      "['F#', 'F#', 'F#', 'E#', 'E#', 'D#', 'D#', 'C#', 'C#', 'E#']\n",
      "[6, 6, 6, 5, 5, 3, 3, 1, 1, 5]\n",
      "Beethoven/Piano_Sonatas/7-1/xml_score.musicxml P4 1\n",
      "['G', 'G', 'G', 'F#', 'F#', 'E', 'E', 'D', 'D', 'F#']\n",
      "[7, 7, 7, 6, 6, 4, 4, 2, 2, 6]\n",
      "Beethoven/Piano_Sonatas/7-1/xml_score.musicxml d5 -4\n",
      "['A-', 'A-', 'A-', 'G', 'G', 'F', 'F', 'E-', 'E-', 'G']\n",
      "[8, 8, 8, 7, 7, 5, 5, 3, 3, 7]\n",
      "Beethoven/Piano_Sonatas/7-1/xml_score.musicxml P5 3\n",
      "['A', 'A', 'A', 'G#', 'G#', 'F#', 'F#', 'E', 'E', 'G#']\n",
      "[9, 9, 9, 8, 8, 6, 6, 4, 4, 8]\n",
      "Beethoven/Piano_Sonatas/7-1/xml_score.musicxml m6 -2\n",
      "['B-', 'B-', 'B-', 'A', 'A', 'G', 'G', 'F', 'F', 'A']\n",
      "[10, 10, 10, 9, 9, 7, 7, 5, 5, 9]\n",
      "Beethoven/Piano_Sonatas/7-1/xml_score.musicxml M6 5\n",
      "['B', 'B', 'B', 'A#', 'A#', 'G#', 'G#', 'F#', 'F#', 'A#']\n",
      "[11, 11, 11, 10, 10, 8, 8, 6, 6, 10]\n",
      "Beethoven/Piano_Sonatas/7-1/xml_score.musicxml m7 0\n",
      "['C', 'C', 'C', 'B', 'B', 'A', 'A', 'G', 'G', 'B']\n",
      "[0, 0, 0, 11, 11, 9, 9, 7, 7, 11]\n",
      "Beethoven/Piano_Sonatas/7-1/xml_score.musicxml d1 -5\n",
      "['D-', 'D-', 'D-', 'C', 'C', 'B-', 'B-', 'A-', 'A-', 'C']\n",
      "[1, 1, 1, 0, 0, 10, 10, 8, 8, 0]\n",
      "Beethoven/Piano_Sonatas/22-1/xml_score.musicxml P1 -1\n",
      "['C', 'E', 'F', 'A', 'F', 'F', 'B-', 'G', 'F', 'C']\n",
      "[0, 4, 5, 9, 5, 5, 10, 7, 5, 0]\n",
      "Beethoven/Piano_Sonatas/22-1/xml_score.musicxml A1 6\n",
      "['C#', 'E#', 'F#', 'A#', 'F#', 'F#', 'B', 'G#', 'F#', 'C#']\n",
      "[1, 5, 6, 10, 6, 6, 11, 8, 6, 1]\n",
      "Beethoven/Piano_Sonatas/22-1/xml_score.musicxml M2 1\n",
      "['D', 'F#', 'G', 'B', 'G', 'G', 'C', 'A', 'G', 'D']\n",
      "[2, 6, 7, 11, 7, 7, 0, 9, 7, 2]\n",
      "Beethoven/Piano_Sonatas/22-1/xml_score.musicxml m3 -4\n",
      "['E-', 'G', 'A-', 'C', 'A-', 'A-', 'D-', 'B-', 'A-', 'E-']\n",
      "[3, 7, 8, 0, 8, 8, 1, 10, 8, 3]\n",
      "Beethoven/Piano_Sonatas/22-1/xml_score.musicxml M3 3\n",
      "['E', 'G#', 'A', 'C#', 'A', 'A', 'D', 'B', 'A', 'E']\n",
      "[4, 8, 9, 1, 9, 9, 2, 11, 9, 4]\n",
      "Beethoven/Piano_Sonatas/22-1/xml_score.musicxml P4 -2\n",
      "['F', 'A', 'B-', 'D', 'B-', 'B-', 'E-', 'C', 'B-', 'F']\n",
      "[5, 9, 10, 2, 10, 10, 3, 0, 10, 5]\n",
      "Beethoven/Piano_Sonatas/22-1/xml_score.musicxml A4 5\n",
      "['F#', 'A#', 'B', 'D#', 'B', 'B', 'E', 'C#', 'B', 'F#']\n",
      "[6, 10, 11, 3, 11, 11, 4, 1, 11, 6]\n",
      "Beethoven/Piano_Sonatas/22-1/xml_score.musicxml P5 0\n",
      "['G', 'B', 'C', 'E', 'C', 'C', 'F', 'D', 'C', 'G']\n",
      "[7, 11, 0, 4, 0, 0, 5, 2, 0, 7]\n",
      "Beethoven/Piano_Sonatas/22-1/xml_score.musicxml m6 -5\n",
      "['A-', 'C', 'D-', 'F', 'D-', 'D-', 'G-', 'E-', 'D-', 'A-']\n",
      "[8, 0, 1, 5, 1, 1, 6, 3, 1, 8]\n",
      "Beethoven/Piano_Sonatas/22-1/xml_score.musicxml M6 2\n",
      "['A', 'C#', 'D', 'F#', 'D', 'D', 'G', 'E', 'D', 'A']\n",
      "[9, 1, 2, 6, 2, 2, 7, 4, 2, 9]\n",
      "Beethoven/Piano_Sonatas/22-1/xml_score.musicxml m7 -3\n",
      "['B-', 'D', 'E-', 'G', 'E-', 'E-', 'A-', 'F', 'E-', 'B-']\n",
      "[10, 2, 3, 7, 3, 3, 8, 5, 3, 10]\n",
      "Beethoven/Piano_Sonatas/22-1/xml_score.musicxml M7 4\n",
      "['B', 'D#', 'E', 'G#', 'E', 'E', 'A', 'F#', 'E', 'B']\n",
      "[11, 3, 4, 8, 4, 4, 9, 6, 4, 11]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml P1 3\n",
      "['A', 'A', 'A', 'E', 'E', 'E', 'E', 'E', 'D', 'D']\n",
      "[9, 9, 9, 4, 4, 4, 4, 4, 2, 2]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml m2 -2\n",
      "['B-', 'B-', 'B-', 'F', 'F', 'F', 'F', 'F', 'E-', 'E-']\n",
      "[10, 10, 10, 5, 5, 5, 5, 5, 3, 3]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml M2 5\n",
      "['B', 'B', 'B', 'F#', 'F#', 'F#', 'F#', 'F#', 'E', 'E']\n",
      "[11, 11, 11, 6, 6, 6, 6, 6, 4, 4]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml m3 0\n",
      "['C', 'C', 'C', 'G', 'G', 'G', 'G', 'G', 'F', 'F']\n",
      "[0, 0, 0, 7, 7, 7, 7, 7, 5, 5]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml M3 7\n",
      "['C#', 'C#', 'C#', 'G#', 'G#', 'G#', 'G#', 'G#', 'F#', 'F#']\n",
      "[1, 1, 1, 8, 8, 8, 8, 8, 6, 6]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml P4 2\n",
      "['D', 'D', 'D', 'A', 'A', 'A', 'A', 'A', 'G', 'G']\n",
      "[2, 2, 2, 9, 9, 9, 9, 9, 7, 7]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml d5 -3\n",
      "['E-', 'E-', 'E-', 'B-', 'B-', 'B-', 'B-', 'B-', 'A-', 'A-']\n",
      "[3, 3, 3, 10, 10, 10, 10, 10, 8, 8]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml P5 4\n",
      "['E', 'E', 'E', 'B', 'B', 'B', 'B', 'B', 'A', 'A']\n",
      "[4, 4, 4, 11, 11, 11, 11, 11, 9, 9]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml m6 -1\n",
      "['F', 'F', 'F', 'C', 'C', 'C', 'C', 'C', 'B-', 'B-']\n",
      "[5, 5, 5, 0, 0, 0, 0, 0, 10, 10]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml M6 6\n",
      "['F#', 'F#', 'F#', 'C#', 'C#', 'C#', 'C#', 'C#', 'B', 'B']\n",
      "[6, 6, 6, 1, 1, 1, 1, 1, 11, 11]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml m7 1\n",
      "['G', 'G', 'G', 'D', 'D', 'D', 'D', 'D', 'C', 'C']\n",
      "[7, 7, 7, 2, 2, 2, 2, 2, 0, 0]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml d1 -4\n",
      "['A-', 'A-', 'A-', 'E-', 'E-', 'E-', 'E-', 'E-', 'D-', 'D-']\n",
      "[8, 8, 8, 3, 3, 3, 3, 3, 1, 1]\n",
      "Bach/Prelude/bwv_865/xml_score.musicxml P1 0\n",
      "['A', 'A', 'B', 'C', 'E', 'C', 'A', 'G#', 'A', 'A']\n",
      "[9, 9, 11, 0, 4, 0, 9, 8, 9, 9]\n",
      "Bach/Prelude/bwv_865/xml_score.musicxml m2 -5\n",
      "['B-', 'B-', 'C', 'D-', 'F', 'D-', 'B-', 'A', 'B-', 'B-']\n",
      "[10, 10, 0, 1, 5, 1, 10, 9, 10, 10]\n",
      "Bach/Prelude/bwv_865/xml_score.musicxml M2 2\n",
      "['B', 'B', 'C#', 'D', 'F#', 'D', 'B', 'A#', 'B', 'B']\n",
      "[11, 11, 1, 2, 6, 2, 11, 10, 11, 11]\n",
      "Bach/Prelude/bwv_865/xml_score.musicxml m3 -3\n",
      "['C', 'C', 'D', 'E-', 'G', 'E-', 'C', 'B', 'C', 'C']\n",
      "[0, 0, 2, 3, 7, 3, 0, 11, 0, 0]\n",
      "Bach/Prelude/bwv_865/xml_score.musicxml M3 4\n",
      "['C#', 'C#', 'D#', 'E', 'G#', 'E', 'C#', 'B#', 'C#', 'C#']\n",
      "[1, 1, 3, 4, 8, 4, 1, 0, 1, 1]\n",
      "Bach/Prelude/bwv_865/xml_score.musicxml P4 -1\n",
      "['D', 'D', 'E', 'F', 'A', 'F', 'D', 'C#', 'D', 'D']\n",
      "[2, 2, 4, 5, 9, 5, 2, 1, 2, 2]\n",
      "Bach/Prelude/bwv_865/xml_score.musicxml d5 -6\n",
      "['E-', 'E-', 'F', 'G-', 'B-', 'G-', 'E-', 'D', 'E-', 'E-']\n",
      "[3, 3, 5, 6, 10, 6, 3, 2, 3, 3]\n",
      "Bach/Prelude/bwv_865/xml_score.musicxml P5 1\n",
      "['E', 'E', 'F#', 'G', 'B', 'G', 'E', 'D#', 'E', 'E']\n",
      "[4, 4, 6, 7, 11, 7, 4, 3, 4, 4]\n",
      "Bach/Prelude/bwv_865/xml_score.musicxml m6 -4\n",
      "['F', 'F', 'G', 'A-', 'C', 'A-', 'F', 'E', 'F', 'F']\n",
      "[5, 5, 7, 8, 0, 8, 5, 4, 5, 5]\n",
      "Bach/Prelude/bwv_865/xml_score.musicxml M6 3\n",
      "['F#', 'F#', 'G#', 'A', 'C#', 'A', 'F#', 'E#', 'F#', 'F#']\n",
      "[6, 6, 8, 9, 1, 9, 6, 5, 6, 6]\n",
      "Bach/Prelude/bwv_865/xml_score.musicxml m7 -2\n",
      "['G', 'G', 'A', 'B-', 'D', 'B-', 'G', 'F#', 'G', 'G']\n",
      "[7, 7, 9, 10, 2, 10, 7, 6, 7, 7]\n",
      "Bach/Prelude/bwv_865/xml_score.musicxml M7 5\n",
      "['G#', 'G#', 'A#', 'B', 'D#', 'B', 'G#', 'F##', 'G#', 'G#']\n",
      "[8, 8, 10, 11, 3, 11, 8, 7, 8, 8]\n",
      "Bach/Prelude/bwv_858/xml_score.musicxml P1 6\n",
      "['F#', 'A#', 'C#', 'A#', 'F#', 'C#', 'C#', 'F#', 'A#', 'C#']\n",
      "[6, 10, 1, 10, 6, 1, 1, 6, 10, 1]\n",
      "Bach/Prelude/bwv_858/xml_score.musicxml m2 1\n",
      "['G', 'B', 'D', 'B', 'G', 'D', 'D', 'G', 'B', 'D']\n",
      "[7, 11, 2, 11, 7, 2, 2, 7, 11, 2]\n",
      "Bach/Prelude/bwv_858/xml_score.musicxml d3 -4\n",
      "['A-', 'C', 'E-', 'C', 'A-', 'E-', 'E-', 'A-', 'C', 'E-']\n",
      "[8, 0, 3, 0, 8, 3, 3, 8, 0, 3]\n",
      "Bach/Prelude/bwv_858/xml_score.musicxml m3 3\n",
      "['A', 'C#', 'E', 'C#', 'A', 'E', 'E', 'A', 'C#', 'E']\n",
      "[9, 1, 4, 1, 9, 4, 4, 9, 1, 4]\n",
      "Bach/Prelude/bwv_858/xml_score.musicxml d4 -2\n",
      "['B-', 'D', 'F', 'D', 'B-', 'F', 'F', 'B-', 'D', 'F']\n",
      "[10, 2, 5, 2, 10, 5, 5, 10, 2, 5]\n",
      "Bach/Prelude/bwv_858/xml_score.musicxml P4 5\n",
      "['B', 'D#', 'F#', 'D#', 'B', 'F#', 'F#', 'B', 'D#', 'F#']\n",
      "[11, 3, 6, 3, 11, 6, 6, 11, 3, 6]\n",
      "Bach/Prelude/bwv_858/xml_score.musicxml d5 0\n",
      "['C', 'E', 'G', 'E', 'C', 'G', 'G', 'C', 'E', 'G']\n",
      "[0, 4, 7, 4, 0, 7, 7, 0, 4, 7]\n",
      "Bach/Prelude/bwv_858/xml_score.musicxml d6 -5\n",
      "['D-', 'F', 'A-', 'F', 'D-', 'A-', 'A-', 'D-', 'F', 'A-']\n",
      "[1, 5, 8, 5, 1, 8, 8, 1, 5, 8]\n",
      "Bach/Prelude/bwv_858/xml_score.musicxml m6 2\n",
      "['D', 'F#', 'A', 'F#', 'D', 'A', 'A', 'D', 'F#', 'A']\n",
      "[2, 6, 9, 6, 2, 9, 9, 2, 6, 9]\n",
      "Bach/Prelude/bwv_858/xml_score.musicxml d7 -3\n",
      "['E-', 'G', 'B-', 'G', 'E-', 'B-', 'B-', 'E-', 'G', 'B-']\n",
      "[3, 7, 10, 7, 3, 10, 10, 3, 7, 10]\n",
      "Bach/Prelude/bwv_858/xml_score.musicxml m7 4\n",
      "['E', 'G#', 'B', 'G#', 'E', 'B', 'B', 'E', 'G#', 'B']\n",
      "[4, 8, 11, 8, 4, 11, 11, 4, 8, 11]\n",
      "Bach/Prelude/bwv_858/xml_score.musicxml d1 -1\n",
      "['F', 'A', 'C', 'A', 'F', 'C', 'C', 'F', 'A', 'C']\n",
      "[5, 9, 0, 9, 5, 0, 0, 5, 9, 0]\n",
      "Beethoven/Piano_Sonatas/11-3/xml_score.musicxml P1 -2\n",
      "['D', 'E-', 'F', 'B-', 'B-', 'D', 'B-', 'A', 'G', 'E-']\n",
      "[2, 3, 5, 10, 10, 2, 10, 9, 7, 3]\n",
      "Beethoven/Piano_Sonatas/11-3/xml_score.musicxml A1 5\n",
      "['D#', 'E', 'F#', 'B', 'B', 'D#', 'B', 'A#', 'G#', 'E']\n",
      "[3, 4, 6, 11, 11, 3, 11, 10, 8, 4]\n",
      "Beethoven/Piano_Sonatas/11-3/xml_score.musicxml M2 0\n",
      "['E', 'F', 'G', 'C', 'C', 'E', 'C', 'B', 'A', 'F']\n",
      "[4, 5, 7, 0, 0, 4, 0, 11, 9, 5]\n",
      "Beethoven/Piano_Sonatas/11-3/xml_score.musicxml m3 -5\n",
      "['F', 'G-', 'A-', 'D-', 'D-', 'F', 'D-', 'C', 'B-', 'G-']\n",
      "[5, 6, 8, 1, 1, 5, 1, 0, 10, 6]\n",
      "Beethoven/Piano_Sonatas/11-3/xml_score.musicxml M3 2\n",
      "['F#', 'G', 'A', 'D', 'D', 'F#', 'D', 'C#', 'B', 'G']\n",
      "[6, 7, 9, 2, 2, 6, 2, 1, 11, 7]\n",
      "Beethoven/Piano_Sonatas/11-3/xml_score.musicxml P4 -3\n",
      "['G', 'A-', 'B-', 'E-', 'E-', 'G', 'E-', 'D', 'C', 'A-']\n",
      "[7, 8, 10, 3, 3, 7, 3, 2, 0, 8]\n",
      "Beethoven/Piano_Sonatas/11-3/xml_score.musicxml A4 4\n",
      "['G#', 'A', 'B', 'E', 'E', 'G#', 'E', 'D#', 'C#', 'A']\n",
      "[8, 9, 11, 4, 4, 8, 4, 3, 1, 9]\n",
      "Beethoven/Piano_Sonatas/11-3/xml_score.musicxml P5 -1\n",
      "['A', 'B-', 'C', 'F', 'F', 'A', 'F', 'E', 'D', 'B-']\n",
      "[9, 10, 0, 5, 5, 9, 5, 4, 2, 10]\n",
      "Beethoven/Piano_Sonatas/11-3/xml_score.musicxml m6 -6\n",
      "['B-', 'C-', 'D-', 'G-', 'G-', 'B-', 'G-', 'F', 'E-', 'C-']\n",
      "[10, 11, 1, 6, 6, 10, 6, 5, 3, 11]\n",
      "Beethoven/Piano_Sonatas/11-3/xml_score.musicxml M6 1\n",
      "['B', 'C', 'D', 'G', 'G', 'B', 'G', 'F#', 'E', 'C']\n",
      "[11, 0, 2, 7, 7, 11, 7, 6, 4, 0]\n",
      "Beethoven/Piano_Sonatas/11-3/xml_score.musicxml m7 -4\n",
      "['C', 'D-', 'E-', 'A-', 'A-', 'C', 'A-', 'G', 'F', 'D-']\n",
      "[0, 1, 3, 8, 8, 0, 8, 7, 5, 1]\n",
      "Beethoven/Piano_Sonatas/11-3/xml_score.musicxml M7 3\n",
      "['C#', 'D', 'E', 'A', 'A', 'C#', 'A', 'G#', 'F#', 'D']\n",
      "[1, 2, 4, 9, 9, 1, 9, 8, 6, 2]\n",
      "Chopin/Etudes_op_25/2/xml_score.musicxml P1 -4\n",
      "['C', 'C', 'E', 'D-', 'B', 'G', 'C', 'E-', 'C', 'D-']\n",
      "[0, 0, 4, 1, 11, 7, 0, 3, 0, 1]\n",
      "Chopin/Etudes_op_25/2/xml_score.musicxml A1 3\n",
      "['C#', 'C#', 'E#', 'D', 'B#', 'G#', 'C#', 'E', 'C#', 'D']\n",
      "[1, 1, 5, 2, 0, 8, 1, 4, 1, 2]\n",
      "Chopin/Etudes_op_25/2/xml_score.musicxml M2 -2\n",
      "['D', 'D', 'F#', 'E-', 'C#', 'A', 'D', 'F', 'D', 'E-']\n",
      "[2, 2, 6, 3, 1, 9, 2, 5, 2, 3]\n",
      "Chopin/Etudes_op_25/2/xml_score.musicxml A2 5\n",
      "['D#', 'D#', 'F##', 'E', 'C##', 'A#', 'D#', 'F#', 'D#', 'E']\n",
      "[3, 3, 7, 4, 2, 10, 3, 6, 3, 4]\n",
      "Chopin/Etudes_op_25/2/xml_score.musicxml M3 0\n",
      "['E', 'E', 'G#', 'F', 'D#', 'B', 'E', 'G', 'E', 'F']\n",
      "[4, 4, 8, 5, 3, 11, 4, 7, 4, 5]\n",
      "Chopin/Etudes_op_25/2/xml_score.musicxml P4 -5\n",
      "['F', 'F', 'A', 'G-', 'E', 'C', 'F', 'A-', 'F', 'G-']\n",
      "[5, 5, 9, 6, 4, 0, 5, 8, 5, 6]\n",
      "Chopin/Etudes_op_25/2/xml_score.musicxml A4 2\n",
      "['F#', 'F#', 'A#', 'G', 'E#', 'C#', 'F#', 'A', 'F#', 'G']\n",
      "[6, 6, 10, 7, 5, 1, 6, 9, 6, 7]\n",
      "Chopin/Etudes_op_25/2/xml_score.musicxml P5 -3\n",
      "['G', 'G', 'B', 'A-', 'F#', 'D', 'G', 'B-', 'G', 'A-']\n",
      "[7, 7, 11, 8, 6, 2, 7, 10, 7, 8]\n",
      "Chopin/Etudes_op_25/2/xml_score.musicxml A5 4\n",
      "['G#', 'G#', 'B#', 'A', 'F##', 'D#', 'G#', 'B', 'G#', 'A']\n",
      "[8, 8, 0, 9, 7, 3, 8, 11, 8, 9]\n",
      "Chopin/Etudes_op_25/2/xml_score.musicxml M6 -1\n",
      "['A', 'A', 'C#', 'B-', 'G#', 'E', 'A', 'C', 'A', 'B-']\n",
      "[9, 9, 1, 10, 8, 4, 9, 0, 9, 10]\n",
      "Chopin/Etudes_op_25/2/xml_score.musicxml m7 -6\n",
      "['B-', 'B-', 'D', 'C-', 'A', 'F', 'B-', 'D-', 'B-', 'C-']\n",
      "[10, 10, 2, 11, 9, 5, 10, 1, 10, 11]\n",
      "Chopin/Etudes_op_25/2/xml_score.musicxml M7 1\n",
      "['B', 'B', 'D#', 'C', 'A#', 'F#', 'B', 'D', 'B', 'C']\n",
      "[11, 11, 3, 0, 10, 6, 11, 2, 11, 0]\n",
      "Schubert/Impromptu_op.90_D.899/4/xml_score.musicxml P1 -4\n",
      "['C-', 'A-', 'E-', 'C-', 'A-', 'A-', 'A-', 'C-', 'E-', 'C-']\n",
      "[11, 8, 3, 11, 8, 8, 8, 11, 3, 11]\n",
      "Schubert/Impromptu_op.90_D.899/4/xml_score.musicxml m2 -9\n",
      "['D--', 'B--', 'F-', 'D--', 'B--', 'B--', 'B--', 'D--', 'F-', 'D--']\n",
      "[0, 9, 4, 0, 9, 9, 9, 0, 4, 0]\n",
      "Schubert/Impromptu_op.90_D.899/4/xml_score.musicxml M2 -2\n",
      "['D-', 'B-', 'F', 'D-', 'B-', 'B-', 'B-', 'D-', 'F', 'D-']\n",
      "[1, 10, 5, 1, 10, 10, 10, 1, 5, 1]\n",
      "Schubert/Impromptu_op.90_D.899/4/xml_score.musicxml m3 -7\n",
      "['E--', 'C-', 'G-', 'E--', 'C-', 'C-', 'C-', 'E--', 'G-', 'E--']\n",
      "[2, 11, 6, 2, 11, 11, 11, 2, 6, 2]\n",
      "Schubert/Impromptu_op.90_D.899/4/xml_score.musicxml M3 0\n",
      "['E-', 'C', 'G', 'E-', 'C', 'C', 'C', 'E-', 'G', 'E-']\n",
      "[3, 0, 7, 3, 0, 0, 0, 3, 7, 3]\n"
     ]
    }
   ],
   "source": [
    "# choose only one enharmonic version for each chromatic interval for each piece\n",
    "dict_dataset = []\n",
    "for path in paths:\n",
    "    for c in range(12):\n",
    "        pieces_to_consider = [opus for opus in full_dict_dataset \n",
    "                              if (opus[\"original_path\"] == path and opus[\"transposed_of\"] in interval_dict[c])  ]\n",
    "        # if the original is in pieces_to_consider, go with the original\n",
    "        originals = [opus for opus in pieces_to_consider if opus[\"transposed_of\"] == \"P1\"]\n",
    "        if len(originals) == 1:\n",
    "            dict_dataset.append(originals[0])\n",
    "        else: #we go with the accidental minization criteria\n",
    "            n_accidentals = [sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in opus[\"pitches\"]]) \n",
    "                            for opus in pieces_to_consider]\n",
    "            if len(pieces_to_consider)>0:\n",
    "                dict_dataset.append(pieces_to_consider[np.argmin(n_accidentals)])\n",
    "            else:\n",
    "                print(\"No options for\", path, \". Chromatic: \",c )\n",
    "\n",
    "# accepted_ks = range(-5,6)\n",
    "# dict_dataset = [e for e in full_dict_dataset if e[\"key_signature\"] in accepted_ks]\n",
    "\n",
    "#test if it worked\n",
    "for i,e in enumerate(dict_dataset):\n",
    "    print(e[\"original_path\"], e[\"transposed_of\"], e[\"key_signature\"])\n",
    "    print(e[\"pitches\"][:10])\n",
    "    print(e[\"midi_number\"][:10])\n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgHkMeoJdb42",
    "outputId": "1f3d172f-3f93-47ce-aa1b-e37a2afba24e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2618\n",
      "Counter({'Bach': 59, 'Beethoven': 57, 'Chopin': 34, 'Liszt': 16, 'Schubert': 13, 'Haydn': 11, 'Schumann': 10, 'Mozart': 6, 'Ravel': 4, 'Rachmaninoff': 4, 'Scriabin': 2, 'Debussy': 2, 'Balakirev': 1, 'Prokofiev': 1, 'Brahms': 1, 'Glinka': 1})\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_dataset))\n",
    "\n",
    "c = Counter()\n",
    "for p in paths:\n",
    "    c[p.split(\"/\")[0]] +=1\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove pieces from asap that are in Musedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GRCM2W3qqeW",
    "outputId": "d53c8146-8b32-43df-cd69-b7423f1ceda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation lenghts:  161 29\n"
     ]
    }
   ],
   "source": [
    "# Temporary remove composer with only one piece, because they create problems with sklearn stratify\n",
    "one_piece_composers = ['Balakirev','Prokofiev','Brahms','Glinka]\n",
    "paths = [p for p in paths if p.split(\"/\")[0] not in one_piece_composers]\n",
    "\n",
    "# Divide train and validation set\n",
    "path_train, path_validation = sklearn.model_selection.train_test_split(paths, test_size=0.15,stratify=[p.split(\"/\")[0] for p in paths ])\n",
    "print(\"Train and validation lenghts: \",len(path_train),len(path_validation))\n",
    "\n",
    "#Put back one piece composers in the validation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "KIZ2_bX1bom5",
    "outputId": "ae8d5b50-ed4d-4376-f9d6-e96c6aa73046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chopin', 'Mozart', 'Haydn', 'Schubert', 'Bach', 'Schumann', 'Beethoven']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv8AAAHwCAYAAAAxRQBqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAABYlAAAWJQFJUiTwAAA8XUlEQVR4nO3deZwcdZ3/8dcnCYQzCeEQFCRBgQAKmCBgwhHAg0MuCcfKskTEE34KHogIMqzIse6CiKsoCuFYDkExIpciCacuSxARDSjigCKoMCSEhARCvr8/qjr09HRPJjM96cl8X8/HI4/OfOtbVd+uq99d9a3qSCkhSZIkafAb0uoGSJIkSVoxDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiaGtboB/SEi/gyMANpb3BRJkiQNbmOAF1NKY1vdkJ4YlOEfGLH66quP3mqrrUa3uiGSJEkavGbPns3LL7/c6mb02GAN/+1bbbXV6FmzZrW6HZIkSRrEJkyYwIMPPtje6nb0lH3+JUmSpEwY/iVJkqRMGP4lSZKkTBj+JUmSpEwY/iVJkqRMGP4lSZKkTBj+JUmSpEwM1uf899iSJUvo6Ohg3rx5LFq0iJRSq5skARARDB8+nLXXXpvRo0czZIjf1SVJUt9kHf6XLFnCX/7yFxYsWNDqpkhdpJRYuHAhCxcuZP78+WyyySZ+AZAkSX2Sdfjv6OhgwYIFDBs2jA033JA111zTcKUBY8mSJcyfP59nn32WBQsW0NHRwXrrrdfqZkmSpJVY1kl33rx5AGy44YasvfbaBn8NKEOGDGHttddmww03BF7fXiVJknor67S7aNEiANZcc80Wt0RqrLJ9VrZXSZKk3so6/Fdu7vWMvwayiADwZnRJktRnTUm9EdEeEanBv2cbjDMxIm6OiI6IeDkiHo6IEyJiaDPaJA0WlfAvSZLUV8284Xcu8PU65S/VFkTEgcAPgYXAtUAHsD9wPjAJOLSJ7ZIkSZJEc8P/nJRS27IqRcQI4GLgNWBySumBsvw04A5gSkQckVK6poltkyRJkrLXis7uU4D1gWsqwR8gpbQQOLX88xMtaJdWoLa2NiKCmTNntropkiRJ2Wjmmf/hEfGvwJuB+cDDwF0ppddq6u1Zvt5aZxp3AQuAiRExPKXU7eNNImJWg0Hjet7s7o05+aZmTapftJ+zX3Om097O2LFjOfroo5k2bVpTpilJkqSBpZnhf0PgipqyP0fEh1JKd1aVbVm+/qF2AimlxRHxZ2AbYDNgdhPbpwHk+OOP54gjjuDNb35zq5siSQ2tiBNAzTqJI0k90azwfylwN/A7YB5FcD8e+ChwS0S8K6X0m7LuyPJ1boNpVcpHLWumKaUJ9crLKwLje9RytcR6663nr9VKkiStYE3p859SOiOldEdK6e8ppQUppUdSSh8HzgNWB9qaMR/1j7a2NsaOHQvAZZddRkQs/Tdt2jRmzpxJRNDW1sb999/Pfvvtx+jRo4kI2tvbAZgxYwYf/ehH2XrrrRkxYgSrr746b3vb2zjjjDNYuHBh3XnW6/MfEUyePJnnnnuOj370o2y00UYMHz6cbbbZhksvvbS/F4UkSdKg1sxuP/VcBHwW2K2qrHJmf2TX6p3K5/RTm1Rj8uTJzJkzhwsuuIDtttuOgw46aOmw7bffnjlz5gDwy1/+krPPPptddtmFY445hueee45VV10VgHPPPZdHH32UiRMnst9++7Fw4ULuvfde2tramDlzJrfffjtDh/bsJxzmzJnDpEmTWHXVVZkyZQqLFi3iuuuu45hjjmHIkCEcffTRzV4EkiRJWejv8P/P8nXNqrLHgB2ALYBON+xGxDBgLLAYeKKf26bS5MmTGTNmDBdccAHbb789bW1tnYZXzs7/7Gc/46KLLuJjH/tYl2l861vfYuzYsV1+kOq0007jzDPP5Prrr+fwww/vUXt+85vf8OEPf5jvfOc7S78wnHDCCWy77bace+65hn9JkqRe6u9Hfe5cvlYH+TvK173r1N8NWAO4b1lP+tGKt/3229cN/gCbbbZZ3V+iPfHEEwG47bbbejyfNdZYg/POO6/TlYKtt96aSZMmMXv2bF56qcvvxkmSJKkH+hz+I2KriFizTvkY4Jvln1dWDboeeA44IiJ2qKq/GnBm+ee3+9ouNd+OO+7YcNj8+fM566yzeOc738nIkSMZMmQIEcG6664LwNNPP93j+Wy++eaMGDGiS/kmm2wCwAsvvLCcLZckSRI0p9vP4cBnI+Iu4EmKp/28BdgPWA24GfjPSuWU0osR8RGKLwEzI+IaoAM4gOIxoNcD1zahXWqyDTfcsG75q6++yp577sn999/P2972Ng4//HDWX399VlllFQDOOOMMFi3q+YWcUaNG1S0fNqzYXF97rfanIyRJktQTzQj/MyhC+zuASRT9++cA91A89/+KlFKqHiGl9OOI2B34EnAIxZeEx4HPAN+ora+BoV63HoDp06dz//33M3Xq1C5P5HnmmWc444wzVkTzJEmStAx9Dv/lD3jducyKXce7F9i3r/NXc1T61/fmrPrjjz8OwAc+8IEuw+68c7k3DUmSJPWT/r7hVyuJddZZh4jgqaeeWu5xx4wZA9Dlmf1PPPEEX/jCF5rQOkmSJDVDfz/qUyuJtdZai5122om7776bI488ki222IKhQ4dywAEHLHPc/fffn7e+9a2cd955/Pa3v+Ud73gHTz31FD/96U/Zb7/9evWFQpIkSc1n+NdSV1xxBSeeeCK33norV199NSklNt5446Vn9htZc801ueOOOzj55JOZOXMmd999N5ttthmnnXYan/nMZ7j2Wu/fliRJGghiMN5bGxGzxo8fP37WrFnd1ps9ezYAW2211YpoltRrbqtSa4w5+aZ+n0f7Ofv1+zwk9Z8JEybw4IMPPphSmtDqtvSEff4lSZKkTBj+JUmSpEwY/iVJkqRMeMOvJElSxry3JS+e+ZckSZIyYfiXJEmSMmH4lyRJkjJh+JckSZIyYfiXJEmSMmH4lyRJkjJh+JckSZIyYfiXJEmSMmH4lyRJkjJh+NcKMWbMGMaMGdOpbNq0aUQE06ZN6/F0pk6dSkTQ3t7e1PbVqtdeSZKkld2wVjdgwGsb2eoWdK9tbqtbsFKaPHkyd955JymlVjdFkiRphTH8q2UOPvhgdt55ZzbaaKNWN6WLX/ziF61ugiRJUtMZ/tUyI0eOZOTIgXll5S1veUurmyBJktR09vkXv/rVr4gIDj744IZ1ttpqK4YPH05HRwevvPIK3/zmN9l3333ZdNNNGT58OKNHj+bd7343t9xyS4/n212f/9tvv51dd92VNddck9GjR3PQQQfx6KOPdjutQw45hM0224zVV1+dESNGMGnSJK688spO9drb24kI7rzzTgAiYum/yZMnL63XqM//okWLOOecc3j729/OGmuswYgRI9h11135wQ9+0KVuZV5Tp06lvb2dI444gvXWW4/VVluNHXbYgZ/+9Kc9W1CSJElN4pl/sfPOO7Plllty88038/zzz7Puuut2Gn7//ffz6KOPcsghhzB69GieffZZPv3pTzNx4kTe8573sP766/PMM89w4403su+++3LxxRdz7LHH9ro9119/PYcffjirrroqhx9+OBtttBH33HMP73rXu9h2223rjvOJT3yCbbbZht12242NNtqI559/nptvvpmjjjqKxx57jK985SsAjBo1itNPP51p06bx5JNPcvrppy+dxrJu8H3llVd43/vex5133sm4ceM47rjjWLBgwdL2PvTQQ5x11lldxnvyySfZcccd2WyzzTjqqKPo6Ojg2muv5cADD+T2229njz326PWykiRJWh6GfwFw9NFHc8opp3D11Vdz/PHHdxp22WWXLa0DsM466/Dkk0+y8cYbd6o3d+5cJk2axEknncSRRx7J6quvvtzteOmll/jYxz7GkCFDuPvuu9lhhx2WDjvxxBP5+te/Xne8Rx55pEtXnVdeeYV99tmHc845h49//OO86U1vYtSoUbS1tTFz5kyefPJJ2traety2//qv/+LOO+9kn3324Sc/+QnDhhW7z+mnn86OO+7I2Wefzfvf/34mTpzYabyZM2fS1tbW6YvGBz/4Qfbee2++9rWvGf4lSdIKY7cfAXDUUUcxZMiQpUG/4pVXXuGaa65hgw02YJ999gFg+PDhXYI/FH34jznmGF544QX+7//+r1ftmD59Oh0dHXzwgx/sFPwB2traGt4jUK+P/qqrrspxxx3H4sWLm3ID7yWXXEJEcN555y0N/gAbbLABp512GgDf+973uoy36aabcuqpp3Yqe9/73seb3/xm7r///j63S5IkqacM/wJg4403Zq+99uKBBx7g97///dLyG2+8kY6ODo488shOgfd3v/sdU6dOXdrHvtJv/rOf/SwATz/9dK/a8eCDDwKw++67dxk2cuRItt9++7rjPfXUUxx33HGMGzeONdZYY2l7DjnkkD61p2LevHk8/vjjvPGNb2TcuHFdhu+5554A/PrXv+4ybPvtt2fo0KFdyjfZZBNeeOGFPrVLkiRpedjtR0tNnTqVn//851x22WWce+65QNcuP1DcILznnnuyePFi9tprLw444ABGjBjBkCFDeOihh5g+fTqLFi3qVRvmzi1+t+ANb3hD3eEbbrhhl7InnniCHXfckRdeeIFdd92V9773vYwcOZKhQ4fS3t7OZZdd1uv21Lar0WNJK+Vz5szpMmzUqFF1xxk2bBhLlizpU7skSZKWh+FfSx188MGMGDGCK6+8krPOOovnn3+eW265he22247ttttuab0zzzyTl19+mRkzZnR6Qg7A2WefzfTp03vdhkq3nr///e91hz/77LNdys477zyef/55Lr30UqZOndpp2NVXX92lK1Nf2lVv/gDPPPNMp3qSJEkDkd1+tNTqq6/OYYcdxt/+9jduv/12rrrqKhYvXtzprD/A448/zujRo7sEf2DpIzR7a/z48Q2nM3fuXB566KEu5Y8//jjA0i4+PWlPpRvOa6+91qN2rb322rzlLW/h6aef5o9//GOX4TNmzOjUfkmSpIHI8K9OKmfOL7/8ci6//HKGDRvGkUce2anOmDFj6Ojo4OGHH+5U/v3vf5/bbrutT/M/8MADWWeddbjqqqt44IEHOg1ra2tb2v2mtj1QPFWn2m233Vb3Blxg6eNMn3rqqR637ZhjjiGlxOc///lOXxqee+65pY8SPeaYY3o8PUmSpBXNbj/qZNKkSbz1rW/luuuu49VXX2X//fdngw026FTnhBNO4LbbbmOXXXbhsMMOY+TIkTzwwAPcc889TJkyheuvv77X819rrbX47ne/y+GHH86uu+7a6Tn/jzzyCLvttht33XVXp3E++clPcumll3LooYcyZcoU3vjGN/LII49w6623cthhh3Httdd2mc9ee+3Fddddxwc+8AH23XdfVl99dTbddFOOOuqohm373Oc+xy233ML06dPZbrvt2HfffVmwYAHXXXcd//jHPzjppJPYZZddev3eJUmS+ptn/tXF0Ucfzauvvrr0/7X23ntvbrzxRrbeemuuvfZavv/97zN8+HBmzJjBfvvt1+f5T5kyhVtvvZUJEybwgx/8gIsuuojRo0fzy1/+krFjx3apv+222zJjxgwmTpzITTfdxLe//W1efPFFfvSjH/Hxj3+87jyOPfZYvvjFLzJ37lz+4z/+g9NOO43vf//73bZr1VVX5ec//zlf/epXAbjwwgu57LLL2HzzzbnqqquW3iQtSZI0UEVKqdVtaLqImDV+/Pjxs2bN6rbe7NmzAdhqq61WRLOkXnNblVpjzMk39fs82s/p+0kTqS/czvtmwoQJPPjggw+mlCa0ui094Zl/SZIkKROGf0mSJCkThn9JkiQpE4Z/SZIkKROGf0mSJCkThn9JkiQpE4Z/aYAbjI/jlSRJrZF1+I8IAJYsWdLilkiNVcJ/ZXuVJEnqrazD//DhwwGYP39+i1siNVbZPivbqyRJUm9lHf7XXnttAJ599lnmzZvHkiVL7GKhASGlxJIlS5g3bx7PPvss8Pr2KkmS1FvDWt2AVho9ejTz589nwYIF/PWvf211c6SG1lhjDUaPHt3qZkiSpJVc1uF/yJAhbLLJJnR0dDBv3jwWLVrkmX8NGBHB8OHDWXvttRk9ejRDhmR9oU6SJDVB1uEfii8A6623Huutt16rmyJJkiT1K08lSpIkSZkw/EuSJEmZMPxLkiRJmTD8S5IkSZkw/EuSJEmZMPxLkiRJmTD8S5IkSZkw/EuSJEmZMPxLkiRJmTD8S5IkSZkw/EuSJEmZMPxLkiRJmTD8S5IkSZkw/EuSJEmZMPxLkiRJmTD8S5IkSZkw/EuSJEmZMPxLkiRJmTD8S5IkSZkw/EuSJEmZMPxLkiRJmeiX8B8R/xoRqfx3bIM674+ImRExNyJeioj/jYij+6M9kiRJkvoh/EfEJsA3gZe6qXM8cCPwNuBK4GLgjcC0iPjPZrdJkiRJUpPDf0QEcCnwPHBRgzpjgP8EOoAdUkrHpZROBLYF/gR8NiLe1cx2SZIkSWr+mf9PAXsCHwLmN6hzDDAc+GZKqb1SmFJ6ATir/PPjTW6XJEmSlL2mhf+I2Ao4B7ggpXRXN1X3LF9vrTPslpo6kiRJkppkWDMmEhHDgCuAp4BTllF9y/L1D7UDUkrPRMR8YOOIWCOltGAZ853VYNC4ZbRBkiRJyk5Twj/wZeAdwC4ppZeXUXdk+Tq3wfC5wJplvW7DvyRJkqSe63P4j4idKM72/1dK6Zd9b1LPpZQmNGjTLGD8imyLJEmSNND1qc9/2d3ncoouPKf1cLTKGf+RDYYv68qAJEmSpF7o6w2/awFbAFsBC6t+2CsBp5d1Li7Lvl7+/Vj5ukXtxCJiI4ouP39dVn9/SZIkScunr91+FgHfbzBsPMV9APdQBP5Kl6A7gEnA3lVlFftU1ZEkSZLURH0K/+XNvcfWGxYRbRTh/7KU0veqBl0KnAQcHxGXVp71HxHr8PqTgur+QJgkSZKk3mvW0356LKX054j4PPAN4IGIuBZ4BZgCbEwLbhyWJEmScrDCwz9ASunCiGgHPgf8G8W9B78HTk0pXdaKNkmSJEmDXb+F/5RSG9DWzfAbgRv7a/6SJEmSOuvr034kSZIkrSQM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImmhL+I+LciPhFRPwlIl6OiI6I+HVEnB4R6zYYZ2JE3FzWfTkiHo6IEyJiaDPaJEmSJKmzZp35PxFYE/g5cAHwP8BioA14OCI2qa4cEQcCdwG7ATcA3wRWBc4HrmlSmyRJkiRVGdak6YxIKS2sLYyIrwKnAF8EPlmWjQAuBl4DJqeUHijLTwPuAKZExBEpJb8ESJIkSU3UlDP/9YJ/6Qfl6+ZVZVOA9YFrKsG/ahqnln9+ohntkiRJkvS6/r7hd//y9eGqsj3L11vr1L8LWABMjIjh/dkwSZIkKTfN6vYDQER8DlgLGAnsAOxCEfzPqaq2Zfn6h9rxU0qLI+LPwDbAZsDsZcxvVoNB45av5ZIkSdLg19TwD3wOeEPV37cCU1NK/6wqG1m+zm0wjUr5qOY2TZIkScpbU8N/SmlDgIh4AzCR4oz/ryPi/SmlB5s5r3J+E+qVl1cExjd7fpIkSdLKrF/6/KeU/p5SugF4L7AucHnV4MqZ/ZFdRuxcPqc/2iZJkiTlql9v+E0pPQn8HtgmItYrix8rX7eorR8Rw4CxFL8R8ER/tk2SJEnKTX8/7QfgjeXra+XrHeXr3nXq7gasAdyXUlrU3w2TJEmSctLn8B8RW0REly48ETGk/JGvDSjC/AvloOuB54AjImKHqvqrAWeWf367r+2SJEmS1FkzbvjdFzg7Iu4B/gw8T/HEn90pHtf5LPCRSuWU0osR8RGKLwEzI+IaoAM4gOIxoNcD1zahXZIkSZKqNCP83w68leKZ/u+geETnfIrn+F8BfCOl1FE9QkrpxxGxO/Al4BBgNeBx4DNl/dSEdkmSJEmq0ufwn1J6BDi+F+PdS3HVYFAZc/JN/T6P9nP26/d5SJIkafBZETf8SpIkSRoADP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJgz/kiRJUiYM/5IkSVImDP+SJElSJvoc/iNi3Yg4NiJuiIjHI+LliJgbEfdExIcjou48ImJiRNwcER3lOA9HxAkRMbSvbZIkSZLU1bAmTONQ4NvAM8AM4CngDcAHgO8B+0TEoSmlVBkhIg4EfggsBK4FOoD9gfOBSeU0JUmSJDVRM8L/H4ADgJtSSksqhRFxCnA/cAjFF4EfluUjgIuB14DJKaUHyvLTgDuAKRFxRErpmia0TZIkSVKpz91+Ukp3pJRurA7+ZfmzwEXln5OrBk0B1geuqQT/sv5C4NTyz0/0tV2SJEmSOuvvG35fLV8XV5XtWb7eWqf+XcACYGJEDO/PhkmSJEm5aUa3n7oiYhjwb+Wf1UF/y/L1D7XjpJQWR8SfgW2AzYDZy5jHrAaDxi1fayVJkqTBrz/P/J8DvA24OaV0W1X5yPJ1boPxKuWj+qldkiRJUpb65cx/RHwK+CzwKHBUf8wDIKU0ocH8ZwHj+2u+kiRJ0sqo6Wf+I+J44ALg98AeKaWOmiqVM/sjqa9SPqfZbZMkSZJy1tTwHxEnABcCj1AE/2frVHusfN2izvjDgLEUNwg/0cy2SZIkSblrWviPiC9Q/EjXQxTB/x8Nqt5Rvu5dZ9huwBrAfSmlRc1qmyRJkqQmhf/yB7rOAWYBe6WUnuum+vXAc8AREbFD1TRWA84s//x2M9olSZIk6XV9vuE3Io4G/p3iF3vvBj4VEbXV2lNK0wBSSi9GxEcovgTMjIhrgA6KXwnesiy/tq/tkiRJktRZM572M7Z8HQqc0KDOncC0yh8ppR9HxO7Al4BDgNWAx4HPAN9IKaUmtEuSJElSlT6H/5RSG9DWi/HuBfbt6/wlSZIk9Ux//siXJEmSpAHE8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlwvAvSZIkZcLwL0mSJGXC8C9JkiRlYlirGyBJGvjGnHxTv8+j/Zz9+n0ekpQ7z/xLkiRJmTD8S5IkSZloSviPiCkRcWFE3B0RL0ZEiogrlzHOxIi4OSI6IuLliHg4Ik6IiKHNaJMkSZKkzprV5/9UYDvgJeCvwLjuKkfEgcAPgYXAtUAHsD9wPjAJOLRJ7ZIkSZJUala3nxOBLYARwCe6qxgRI4CLgdeAySmlD6eUPg9sD/wSmBIRRzSpXZIkSZJKTQn/KaUZKaU/ppRSD6pPAdYHrkkpPVA1jYUUVxBgGV8gJEmSJC2/Vtzwu2f5emudYXcBC4CJETF8xTVJkiRJGvxa8Zz/LcvXP9QOSCktjog/A9sAmwGzu5tQRMxqMKjbew4kSZKkHLXizP/I8nVug+GV8lH93xRJkiQpHyv1L/ymlCbUKy+vCIxfwc2RJEmSBrRWnPmvnNkf2WB4pXxO/zdFkiRJykcrwv9j5esWtQMiYhgwFlgMPLEiGyVJkiQNdq0I/3eUr3vXGbYbsAZwX0pp0YprkiRJkjT4tSL8Xw88BxwRETtUCiNiNeDM8s9vt6BdkiRJ0qDWlBt+I+Ig4KDyzw3L13dFxLTy/8+llD4HkFJ6MSI+QvElYGZEXAN0AAdQPAb0euDaZrRLkiRJ0uua9bSf7YGja8o2K/8BPAl8rjIgpfTjiNgd+BJwCLAa8DjwGeAbPfylYEmSJEnLoSnhP6XUBrQt5zj3Avs2Y/6SVrwxJ9/U7/NoP2e/fp+H1HJtjR5+18x5NPppHVXzuNaP3M4HjFb0+ZckSZLUAoZ/SZIkKROGf0mSJCkThn9JkiQpE4Z/SZIkKROGf0mSJCkThn9JkiQpE4Z/SZIkKROGf0mSJCkThn9JkiQpE4Z/SZIkKROGf0mSJCkThn9JkiQpE4Z/SZIkKROGf0mSJCkThn9JkiQpE4Z/SZIkKROGf0mSJCkThn9JkiQpE4Z/SZIkKROGf0mSJCkThn9JkiQpE4Z/SZIkKROGf0mSJCkThn9JkiQpE4Z/SZIkKROGf0mSJCkThn9JkiQpE4Z/SZIkKROGf0mSJCkThn9JkiQpE4Z/SZIkKRPDWt0A9ULbyBUwj7nLPcqYk2/qh4a8rv2c/fp1+pIkSYOdZ/4lSZKkTBj+JUmSpEwY/iVJkqRMGP4lSZKkTBj+JUmSpEwY/iVJkqRMGP4lSZKkTBj+JUmSpEwY/iVJkqRMGP4lSZKkTBj+JUmSpEwY/iVJkqRMGP4lSZKkTBj+JUmSpEwY/iVJkqRMGP4lSZKkTBj+JUmSpEwY/iVJkqRMGP4lSZKkTBj+JUmSpEwY/iVJkqRMGP4lSZKkTBj+JUmSpEwY/iVJkqRMDGt1AySpobaR/Tz9uf07fS2f/l7f4DqXlD3P/EuSJEmZMPxLkiRJmTD8S5IkSZkw/EuSJEmZMPxLkiRJmTD8S5IkSZkw/EuSJEmZ8Dn/Wnn4DHBJ0srOzzK1mGf+JUmSpEwY/iVJkqRMtDT8R8TGEXFJRPwtIhZFRHtEfD0i1mlluyRJkqTBqGV9/iPiLcB9wAbAdOBRYEfg08DeETEppfR8q9onSZIkDTatPPP/LYrg/6mU0kEppZNTSnsC5wNbAl9tYdskSZKkQacl4b886/9eoB3475rBpwPzgaMiYs0V3DRJkiRp0GrVmf89ytefpZSWVA9IKc0D7gXWAHZe0Q2TJEmSBqtW9fnfsnz9Q4Phf6S4MrAF8ItGE4mIWQ0GbTd79mwmTJjQ+xb20jNP9/+zdScMeanf58GNy7/s+vu9D9T3natBsa27vntsUKxvWO51nuv7zlWu6zvX990ss2fPBhjTkpn3QqSUVvxMI74LfAT4SErpe3WGfxU4BTglpXR2N9NpFP7fBrxE0a2oP4wrXx/tp+mrb1w/A5frZmBz/QxcrpuBzfUzcK2IdTMGeDGlNLYf59E0K/Uv/KaUWvIVr/Klo1XzV/dcPwOX62Zgc/0MXK6bgc31M3C5brpqVZ//yvWlRr9xXSmf0/9NkSRJkvLQqvD/WPm6RYPhm5evje4JkCRJkrScWhX+Z5Sv742ITm2IiLWBScAC4FcrumGSJEnSYNWS8J9S+hPwM4obJI6rGXwGsCZwRUpp/gpumiRJkjRotfKG308C9wHfiIi9gNnAThS/AfAH4EstbJskSZI06LTkUZ9LZx6xCfDvwN7AusAzwA3AGSmlF1rWMEmSJGkQamn4lyRJkrTitOqGX0mSJEkrmOFfkiRJyoThX5IkScqE4V+SJEnKhOFfkiRJykQW4T8ixkREiohprW5LtYiYWrZraqvbIq0sIqKt3G8mt7otrbaijiER0R4R7f05D/WfchuZ2ep2rEh+vuYpImZGhI+xXIaVOvxHxLiIuDAiHomIuRHxSkT8LSJuiogPR8TwVrcxR+UBN0XEkoh4Szf1ZlTVnboCm9hUETG5fA9trW7L8qgs+2XUaS/rjVlBzRqUImJoRHwkIu6MiI6IeDUi/hERD0fE9yLigFa3caBbWcJc1TGt+t+icl+6LCK2anUbBxL3jYFpoG7HETHNz6S+a+Uv/PZJRHwZOJ3iC8wvgcuAl4A3AJOB7wGfAHZoURN74gbgVxQ/bjbYLKbYvj4MnFI7MCI2p1hPlXrSoBQRQ4GfUvyY4RzgJuCvwKrANsAHgXHAT1rURPWPM6r+PxLYEfg34JCI2CWl9FBLWjWAuG+sFNyOB6GVMnRFxCkUG+RfgENTSv9bp877gc+u6LYtj5TSXGBuq9vRT/5O8aXmQxHx5ZTS4prhx5avNwIHr9CWSSvWv1CEm98Au5f7/VIRsQawUysapv6TUmqrLYuIC4HjgROAqSu2RQOS+8YA53Y8OK103X7KSz1twKvAvvWCP0BKqXI2ocv4EXFNRDwXEQsj4oHyi0K9eQ2PiJMj4rcRsSAiXoyIuyPisAbTTeUlqXER8ePyEub8iLgnIt5bZ5y6l7Er/WsjYs2I+FpEPFVebns8Ir4QEdGDRTUQXAxsCHRavhGxCsUB4z7g941GjojNI+LyiHi6qkvX5eVVg+p6lW433f2bXFX/oIi4MiL+UK6f+RExKyI+FRFd9omqy4ybRcT/Ky9HvxxF38JpwIyy6umN5jnYLM8yjIiry+Wxe4NpHVIO/2ZN+YSIuDUi5pX73u0R8a5u2pTKdbJeRHw3Ip4p95vfRcSHmvPOe2Vi+TqtNtwApJQWpJRm1JZHxOER8YvyOLKwPCZcHRF1r2ZGxB7l+68sr5uizqX56KZPbKNjUtXwkRHxzXKfXBgRvy/Xed1jUkTsFBHXR8Sz5T78l4j4TkS8sVG7ImLViPhyRDxWrr9pUfRXv7SsemnNfjam3rwHqJ+Vr+tXF5bL9fMRcUdE/LVcVv+MiJ8sY5sfFxGXlNvGoii6y9wdEZ9oUN99o8n7Rrz+eb1WRJxfbuMvR8RDEXFQWWdYRHwpIv5YtvdPEXF8nXmsGhHHR8TNEfFkuY46ymPfPg3atVx5ITpnlR7noRp1t+OqefxLFN1655TTnR0Rp0aDrtjldjytXHavRMTfI+KqiNiypl4Cji7//HPVMaC9zjSHRcQp5TJfVE773IhYtUEb9ori86ajrP+HiDgnIkbW1Hu0bON6DabzhbJNx9eUbxzFsfOJcvrPl/v3O+tMY+l9bRExJSLujyKDdpTr60315r08VsYz/x8CVgGuSSk90l3FlNKimqJNgfuBJ4ArgNHA4cD0iHh39UGm3EBuA3YHHgX+G1gDmAJcGxHbp5S6dGcBxlJ0Q/ot8B1go3Iet0TEB1NK1/bwfa5Szv+NwC0U3WMOAs4BVqPzpbiB6mrgPIqz/D+uKj8A2AD4AvDWeiOWO8TtwNoUl3x/T3H591+BA8v19X9l9XbqL49VgM9QLK8FVeXnAEuA/wWepriUuSdwAfBO4KgG7+cCYFeKS9M3A68BlTYcDdwJzKyq395gOoPB8izDbwNHAB+lWEa1Pla+XlQpiIiJFOt/VeBHwOPA9hTL945u2jUKuBd4BbgeGA4cClwSEUtSSpf1+B02z/Pl6xY9qVx+WF9KsU09R/H+/wlsDOwBPAY8UDPa+4EDKY4VFwFbA/sC74yIrVNKz/XxPUCxLm6nWMbXlH8fQrHOtwSOq3kfxwDfBRZR7MN/ATanOB7sHxE7p5SeqjOfH1JsQ7dQHDf+QbHe55TvcTrwUFX9OX19YyvQu8vX2vW3FfBV4C6K48sLwJspjpX7RMT+KaVbq0eIiP2A6yi28VspjrejgO2Akyj2u2qjcN/or31jFeDnFJliOsW+8S/AD6M48fdJiisYt1DsD4cCF0bEP2sywWiK/em+cnr/pMgQ+wM3R8RHUkrfazD/5c0L3eahZbzfRtsxEXEJRU77K8W+PAfYGfgKsFdEvKe6J0BE7E2xHleh6AnwOMX6/ACwX0TskVJ6sKx+Rvm+tqNYTnPK8sprtasoPq9vAV6kWOcnUWSPTl94I+JjFPvLfIp96h8U3ZK/QHGsmpRSqszjMuAsivV7YZ35Hk2xj11VNf3xFF+YRlOspx8B65Xv5Z6IODildHOdaX2S4hjwE4rPzp0o1tF2ZQatzbg9l1Jaqf4BvwAScOxyjDOmHCcBp9cMe19ZfnNN+Rcr5cCwqvINKEJdAiY2mMfXaqa1A8WViheAEVXlU8v6U2vqt1fNe/Waec8p/63S6nXRzfJOwF/L/3+P4kC0cdXwWym6O60BnFm7DIAAZpflR9ZM+/Cy/FFgyDLaMa2se35N+Vvq1B1CsVMnYKcG03kaGFtn3Mnl8LZWL/terKdEcSWt0b85ZZ0xfVyGjwALgXVryjej+BJxb836f7SczoE19T9d1e7JDd7P94ChVeVbl9vg71u0nN9B8WGwhOJD9gPApt3U/2j5Pu4HRtYMGwpsVPX31LLuYmCvmrpnl8NOqimfCaQG865Mb2pNeXtZfg8wvKp8NPCncthuVeVblO/5ceBNNdPai+KL8w312gU8DKzX07YNtH8N9qvzgLvLbeBGYO2acUY2eM8bA38DZteUr0dxDH2FortMl/EatMl9o//2jRtr9o1dy/IOipNEo6qGbVa+71/XTGt47bqr2j4eKae1eoP59ygv0MM81MvtuLKMflSnnW3lsE9Xla1DkYueA7auqf82ivs4H6wpn0adz6TadQjMAkZXla9JcTx6DdiwqnxTii9kLwLjaqb1rXJa363ZJ18DHqgz73eW9X9YVTasnO9CavZVii9rT1N0ka7edirL6kXg7TXjXFUOO6xP+16zduIV9Y/iDHAC9l6OcSobeztVB76q4U8Cz9WU/bHcwMfVqf/hcnqX1JnHnNodomaDPbqqrLKjNDqYvLXOdCrh6m2tXhfdLO/E6+F/p/LvL5d/b1ruON8q/64X/ieVZfc1mP7d1ISNOnW+XNb5Mcv4klA1zvjqttZZd59uMN5kVu7w35N/Y/q4DI8ryz9bU175EP63Ouv/zjrTH0pxIE3UD//zqfqCXTXsznL4Wi1a1odRHOCrl+nzFDf9719T97fl8Hf0YLqVY8iVdYaNLYddX1M+k94HnF27GefSqrLzy7L9GsznBopQtnZtu6j5wrestg20f8vYj34HfHA5p/eNctw3V5V9tiy7YDna5L7x+rD+2DfqnRB5ohy2Z51hMyhOCnbJJA3m/xnqfO6xnHmBHuah3mzHwK/L9zSqzrCh5XTvryr7dDm94xq858pxZOuqsmn0LPy/u86wM8ph768q+1JZdlad+utQBPCX6RzOf1aOs01N/W+W5QdUlR1Yln2tQXsry2DfqrK2suzMOvX3KIf9Z1/2u5Wx209fPJRSeq1O+V+Apf0qI2Jtiu4oT6eUHq1Tv9Lt4B11hj2YUppXp3wmxeWgd1DskMsyN6X0eIO2QrFRDngppf+NiN8Cx0TEmRSX/IdQ3A/QyPjytVH3jjuAXSiW5V21AyPiSIqd/AGKA9SSmuHrAp+nuAy4GcUZgWqN+tPd302bV1oppYb3kJR9KTetU768y/ByikvQHwX+q5xG5d6PF4AfVNWtrP8uXYRSSq9FxD1Ao0fI/jGl9GKd8ur95qUG4/ablNIPIuIGigN3ZdvdheKy70ERcTnFsliD4ozX31NKv16OWXS5/E7zjxWLKboj1JpZvlYfDyvH093r9WmlOCs5lOIKwayaYYNiP6veryJiTYqn15wD/E9EbJNS+lJ1/YiYRBEE3kWxfGr7Jr8JqHST2rl8vWU5muS+8bpm7xtzUkp/qlP+N4ovGrXbOBRnfIdR3Bf3dKUwIrahOLbuRtHlZ7Wa8ep9PvUmL/QoD/V0O47i5uztKAL+CVH/NqBFFF3cKirz2S7qPyq70h1sK7q5P7CBnq73hnkjpfRCRPyaYl2Mo7gxHYovIO+hyHQnwdKu4v9C0WWougtP5T1u2uA9Vu5h3KpmvOV5D8ttZQz/z1AspN7c8DCnQfliOt/8PLJqXo3aAEUfylp/bzDOszXTXpY5DcorfeWG9nA6A8HFFGev9qHoazdrGQfvXi//KG4qvYTi7MX7U0oLaoaPorgEO5YiZFxOcSl1cTm9T1Nceq3n2QblWenNMkwpzYuIK4GPl304Z1D0ZdwQ+HpKaWFV9cr6X9a+VM+cBuUt329SSq9SnDH6GSx9zOEhFNvrv1Gc6azcQ/J0vWl0Y06d+S0uP4Cb9Z6faxAW6h3b1i1fP7+Maa7VzfQGjZTSfOD+iPgARV/okyLiopTSXwAi4mCKfvgLKfp6/4niTP0SiiuLu9N5nxpVvi7PdjKnQbn7Rt81emrf4nJ+9YZXlvsqlYKI2JkihA6j6OL8E4ozz0so7nk6kPqfT3O6mz/132d349R9GMwytuN1KLpsrk/xGPaeqBwnPrKMevWOE91Kr/fRr1ZvefQmb9xAsV7+NSK+WB4X30/RDfLrqfPTDSvv8dBlNLnee5xTp6wp++vKGP7vobixcC/g+/00j8qOumGD4RvV1Kv2hgbjVKY1WB/t2Z0rgHMpbrZ6E/Dvy6jfq+UfEeModsqXKS6h1QuPx1KE1jNSzSPMoniqxqe7aVfqvtnZ6O0y/DbwcYobfGfw+o2+362pV1mvy9qXVmrlB8YPIuLtwKkUx7Wfl4P7/DSHbiyB4mkYqesjeEd1M956ETG0zheAese2yv9HNjjb3FAqr20PRimlORHxGMXZxvG8fhbvKxR9wHdIKc2uHicivkMR/qvNKV/fRNEVZlBZCfeNZjkVWB3YI6U0s3pARHyRIvy3XIPtuLLP/zqlNL7hyJ1VxtkupfRwk5vZU9V543d1hnfJGymllyPiBxSfhe+huI/x6HJwbc+OyngHppQGzO9VrHSP+qS40/9Vih+Y2Lq7itHLX/gtu+38CXhT1DxWsrRH+fpgnWHjy25DtSaXr8tzuXJQKL+BX09xo8x8iqdSdKeyjCY3GN5l+UfE+hRPyVgLOCSl1OgSYeXpQj+sM6z2A7anKmFoZboa0xe9Woblwf1e4OCI2IniiRF31YYdXl+vXaZVnhHcZblbPLBVuglGeWbtEeANEVGvW2EzvFC+blJnWHc/ijiM1x/NWG1y+Vp9bPtV+brrcrWse4NlP6tcrq/+/H0rxU23tcF/CPW398ryrfv4x0FkZdk3muWtQEdt8C/19vOpv3TajlNKL1GE520iYnQPp9Gb40SzjwMN80Z5lXt7iitytZ9T08rXo8v8sQ/wcOr6o2f9cSzss5Uu/KeU2iluhlgVuCkaP9d3b5avP2StSyguYX2tDByV6a4HnFZVp9ZIiptNq9uyA3AkxTfAG/rQppXZqRQ/5vW+BvdEVLuX4pFtu0TElOoB5d+7An+guApERKxGcXl0M+BjKaVfdDPt9vJ1cs1030HxhKfeqDyu7s29HH9l016+Tq4u7OEy/DbFvvtDiv3rojp17qNY/7tFRO2ZruNp3N9/QIrimdfvifq/IbEhr1/yrty/8o3y9TvR9RnTQyJiI/qm0qe+06X2iNiLos9qd86uPqlSfsifWv55aVW9b1KcpDk/Iro8xjGK55kv74fhSr+fRfHc97EUy6b6/ol2YPOo+v2D8rGWbRRP5Kl1GUW3g09ExG515rNx0xrdjwbZvtEM7cDoiNi2Zv4fpngSz4DQzXZ8HsXx/ZIyONeOt0752MuKSymuYp0eETvWqT8kIibXFDf7OHAlxfv4fxFR++jxrwAjKG4a7/RYzZTSvRQPhjmQ4or2Krz+haDadIqTycdFxL71GhAR7yrvmVhhVsZuP6SUzoqIYRT9yv4vIu6juDHiJYquArtR3ERR72aJnvpPim9yBwK/iYibKW44OpTiZqz/SCndU2e8u4BjyzOb9/L6c/6HUATT5boEPlik4nne9Z7pXa9uioijKS7zXhsR0yke/bglxU1g8yieDlO5kfdTFDfAPUHjm2qmlV8cL6foh/z1iNiDYufdnKK/3o8o1tXyeoyiH+oREfEqxf0GCbgipfRkL6Y30PVlGV5H8QSHN/H6c7o7Kdf/hynW/w8jovo5/3tRXGLt8gN+A9hOFF2hni1vVv5zWT4W2I/iMv90iqtjUDyOcVeK30r4Y7n9/5PisXB7Upx0aOtDey6lWH9fjIjtKG6k24LieHcDRV/rep6h6G/8SET8hOLDbgrFMe5bKaWlN9+nlB6N4jn/lwC/i4hbKb6wr0Lxob1r+Z7GLUe7f0nxex0nRHHDeeXegAsb9KluqZrj0JoUIb5ypv6Umm6J51N8Ef51RPyQIoxMKse5keI570ullJ6LiA9SbDMzIuIWikekjgC2pThzPbbZ76kfDJZ9o1m+ThHy7ym7lcyluOKwC8UymNJ41P6xPNtxSumSiJhA8Xz6P0XEbRSf+6Mp1uluFMv442X958sTejcAv4qIX1BcPUgU2/C7KPrMV9/0/AuKdXRxua/Mo7jhutOPRPZUSqk9Ik6g+C2nB8vl/k+KKy3vosgeX2gw+uUUXxBOo+iL/z91pv9qeY/EbRQnrO+j+J2SBeV7fCfFicuN6Px7RP2rL48KavU/iht/L6S4FPgiRZ/JZyjO+H+Y8tFMvP5oq2kNpjOTOo/3otjgTimn/zLFRnYP8C916i6dR9mu6RSXEBdQfAl4X51xptL40WHtDdraRp3HHA6kf2X7/trDul0e9Vk1bEuK+wWeofgwfIbiW/qWDZZJd/8mV9XfmuJKwT8ouiHNoui7V3c7YRmPFivrvJPioDSXot/ogF5HVeupy3ZfZ1vs8t6XdxnWjHs+3Tz6rKreBIqgP6/8dzvFwbjuPlCWzWwwrWWuw35czptQPOr0BoovitXHqpspfriuy+NoKa4W3lluUwspgtH/AOOr6tQ9hixrmVA8sePmcrm+RHEM3L3R9MrtoJ3iyuZ/U3zZXURxKfxTFN0y6s3/7eWyf7Ks30FxPP0ONY8/pJvHLFbV2ZviS8BLvL5vr/B1uow21jv+LC7X93TgPQ3Gm0oRCuZTfDG+oVx+dbf3qvV4ebk+XqG4Sf5O4KPuGyt232gwj4bbdKPlTnES5Vfl/OdQ3AS9Wy/n32XboYd5qLfbcdV7+CnF58MrFF/U76f4vK/3+PQxFFcL/1iuzxcpQvcVwEF16n+G4tizqGxXe237u9nHGuWN95bL+oVyuo8D/0Gdx5ZWjfNmim5ICbhxGdv6BhRPSXqEIhe+VL7f6ym28+rfk+qy3nq6/nr6L8qJqY+i+In5PwOXpZSmtrY10sAVETMpPsy2TCn9scXNkSQpKytdn39JK6+yX+fuwG0Gf0mSVryVss+/pJVLRHyCop//hyi6RZ3e2hZJkpQnw7+kFeELFI96fQI4KqU0KH7FVZKklY19/iVJkqRM2OdfkiRJyoThX5IkScqE4V+SJEnKhOFfkiRJyoThX5IkScqE4V+SJEnKhOFfkiRJyoThX5IkScqE4V+SJEnKhOFfkiRJyoThX5IkScqE4V+SJEnKhOFfkiRJysT/Bwoyi02ukmuYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 383
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#need to find a better way to visualize this\n",
    "composers = list(set([p.split(\"/\")[0] for p in paths ]))\n",
    "print(composers)\n",
    "\n",
    "train_composer = [composers.index(p.split(\"/\")[0]) for p in path_train]\n",
    "val_composer = [composers.index(p.split(\"/\")[0]) for p in path_validation]\n",
    "\n",
    "_ = plt.hist([train_composer, val_composer], label=['train', 'validation'])\n",
    "_ = plt.legend(loc='upper left')\n",
    "_ = plt.xticks(list(range(7)), composers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-qaT10ApkCY"
   },
   "source": [
    "## Transform the input into a convenient format for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEYec2TDOWvj",
    "outputId": "1b69573b-cfeb-4dc9-8882-da42f9c25537"
   },
   "outputs": [],
   "source": [
    "# Helper functions to feed the correct input into the NN \n",
    "\n",
    "PAD = \"<PAD>\"\n",
    "\n",
    "tag_to_ix = {p: accepted_pitches.index(p) for p in accepted_pitches}\n",
    "#add PADDING TAD\n",
    "tag_to_ix[PAD] = len(accepted_pitches)\n",
    "\n",
    "midi_to_ix = {m: m for m in range(12)}\n",
    "# #add PADDING TAD\n",
    "# midi_to_ix[PAD] = 12\n",
    "\n",
    "# print(midi_to_ix[1])\n",
    "# print(len(midi_to_ix))\n",
    "\n",
    "duration_delimiter = [0.125,0.25,0.5,1,2,4]\n",
    "\n",
    "\n",
    "class Pitch2Diatonic():\n",
    "    def __call__(self, in_seq,weights = None):\n",
    "        return [p for p in in_seq]\n",
    "\n",
    "class Diatonic2Int():\n",
    "    def __call__(self, in_seq,weights = None):\n",
    "        idxs = [tag_to_ix[w] for w in in_seq]\n",
    "        return idxs\n",
    "\n",
    "class Int2Pitch():\n",
    "    def __call__(self, in_seq):\n",
    "        return [accepted_pitches[i] for i in in_seq]\n",
    "\n",
    "class OneHotEncoder():\n",
    "    def __init__(self, alphabet_len):\n",
    "        self.alphabet_len = alphabet_len\n",
    "        \n",
    "    def __call__(self, sample,weights = None):\n",
    "        onehot = np.zeros([len(sample), self.alphabet_len])\n",
    "        tot_chars = len(sample)\n",
    "        onehot[np.arange(tot_chars), sample] = 1\n",
    "        return onehot\n",
    "\n",
    "# class WeightedOneHotEncoder():\n",
    "#     def __init__(self, alphabet_len):\n",
    "#         self.alphabet_len = alphabet_len\n",
    "        \n",
    "#     def __call__(self, sample, weights=None):\n",
    "#         if weights == None:\n",
    "#             weights = np.ones(len(sample))\n",
    "#         onehot = torch.nn.functional.one_hot(sample,self.alphabet_len)\n",
    "#         return (onehot.t()*torch.Tensor(weights)).t() #transpositions to allow the broadcasting\n",
    "    \n",
    "class DurationOneHotEncoder():\n",
    "    def __init__(self, pitch_alphabet_len, duration_delimiter):\n",
    "        self.pitch_alphabet_len = pitch_alphabet_len\n",
    "        self.dur_alphabet_len = len(duration_delimiter)+2\n",
    "        self.duration_delimiter = duration_delimiter\n",
    "        \n",
    "    def __call__(self, sample, durs):\n",
    "        sample = torch.tensor(sample,dtype=torch.long)\n",
    "        onehot_pitch = torch.nn.functional.one_hot(sample,self.pitch_alphabet_len)\n",
    "        quantized_durations = np.digitize(durs,self.duration_delimiter)\n",
    "        quantized_durations = torch.tensor(quantized_durations,dtype=torch.long)\n",
    "        onehot_duration = torch.nn.functional.one_hot(quantized_durations,self.dur_alphabet_len)\n",
    "        return torch.cat([onehot_pitch,onehot_duration],1)\n",
    "        \n",
    "class ToTensorFloat():\n",
    "    def __call__(self, sample, weight = None):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.float()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.float)\n",
    "\n",
    "class ToTensorLong():\n",
    "    def __call__(self, sample, weights = None):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.long()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.long)\n",
    "    \n",
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, sample, weights):\n",
    "        for t in self.transforms:\n",
    "            sample = t(sample, weights)\n",
    "        return sample\n",
    "\n",
    "pitches_len = len(accepted_pitches)\n",
    "midinote_len = 12\n",
    "\n",
    "### Define the preprocessing pipeline\n",
    "transform_diat = Compose([Pitch2Diatonic(),Diatonic2Int(),ToTensorLong()])\n",
    "transform_chrom = Compose([DurationOneHotEncoder(len(midi_to_ix),duration_delimiter),ToTensorFloat()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =[list(range(10)) for e in range(4)]\n",
    "torch.Tensor(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV9boYaToUs2",
    "outputId": "92bcd8d3-87a2-4d2c-8e92-4a106139f59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1916 29\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n",
      "tensor([ 2, 11,  2,  7,  2, 11,  2,  7,  2, 11,  2,  4,  0,  9,  0,  6,  9,  2,\n",
      "        11,  7, 11,  4,  7,  0,  9,  6,  9,  2,  6, 11])\n",
      "['D', 'B', 'D', 'G', 'D', 'B', 'D', 'G', 'D', 'B', 'D', 'E', 'C', 'A', 'C', 'F#', 'A', 'D', 'B', 'G', 'B', 'E', 'G', 'C', 'A', 'F#', 'A', 'D', 'F#', 'B']\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "\n",
    "class PSDataset(Dataset):\n",
    "    def __init__(self, dict_dataset, paths, transf_c, transf_d, augment_dataset, truncate = None):\n",
    "        if augment_dataset:\n",
    "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset if e[\"original_path\"] in paths]\n",
    "            self.diatonic_sequences = [e[\"pitches\"]\n",
    "                                       for e in dict_dataset \n",
    "                                       if e[\"original_path\"] in paths]\n",
    "            self.durations = [e[\"duration\"] for e in dict_dataset if e[\"original_path\"] in paths]\n",
    "        else: #consider only non transposed pieces\n",
    "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset \n",
    "                                        if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "            self.diatonic_sequences = [e[\"pitches\"]\n",
    "                                       for e in dict_dataset \n",
    "                                       if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "            self.durations = [e[\"duration\"] \n",
    "                              for e in dict_dataset \n",
    "                              if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "        #the transformations to apply to data\n",
    "        self.transf_c = transf_c\n",
    "        self.transf_d = transf_d\n",
    "        self.truncate = truncate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chromatic_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chromatic_seq = self.chromatic_sequences[idx]\n",
    "        diatonic_seq = self.diatonic_sequences[idx]\n",
    "        duration_seq = self.durations[idx]\n",
    "        weights = [dur/4  if dur<=4 else 1 for dur in duration_seq  ] # limit the weights to (0,4)       \n",
    "\n",
    "        #transform\n",
    "        chromatic_seq = self.transf_c(chromatic_seq,weights)\n",
    "        diatonic_seq = self.transf_d(diatonic_seq,None)\n",
    "\n",
    "        if not self.truncate is None:\n",
    "            if len(diatonic_seq) > self.truncate:\n",
    "                chromatic_seq = chromatic_seq[0:self.truncate]\n",
    "                diatonic_seq = diatonic_seq[0:self.truncate]\n",
    "\n",
    "        #sanity check\n",
    "        assert len(chromatic_seq) == len(diatonic_seq)\n",
    "        seq_len = len(diatonic_seq)\n",
    "        \n",
    "        return chromatic_seq, diatonic_seq, seq_len\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\n",
    "\n",
    "print(len(train_dataset),len(validation_dataset))\n",
    "\n",
    "\n",
    "\n",
    "# test if it works\n",
    "for chrom,diat,seq_len in train_dataset:\n",
    "    print(chrom[0:30])\n",
    "    print(torch.argmax(chrom[0:30],1))\n",
    "    # print([diatonic_pitches[p.item()] for p in diat[0:30]])\n",
    "    print([accepted_pitches[p.item()] for p in diat[0:30]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAubyjw2LC8P",
    "outputId": "d6f8574f-8901-41e7-fd7a-9a0c6091eafa"
   },
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (xx, yy, l) = zip(*batch)\n",
    "    \n",
    "    xx_pad = pad_sequence(xx)\n",
    "    yy_pad = pad_sequence(yy, padding_value=tag_to_ix[PAD])\n",
    "\n",
    "    #sort the sequences by length\n",
    "    seq_lengths, perm_idx = torch.Tensor(l).sort(0, descending=True)\n",
    "    xx_pad = xx_pad[:,perm_idx,:]\n",
    "    yy_pad = yy_pad[:,perm_idx]\n",
    "\n",
    "    return xx_pad, yy_pad, seq_lengths\n",
    "\n",
    "# data_loader = DataLoader(dataset=validation_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "\n",
    "\n",
    "# #test if it work\n",
    "# for batch in data_loader:\n",
    "#     print(batch[0].shape,batch[1].shape,batch[2])\n",
    "#     print(batch[1])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O1OA1AjGWO-"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QEkFBY5cUsmN"
   },
   "outputs": [],
   "source": [
    "class RNNTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='sum',ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "       \n",
    "        # # Find the positions where the token is a dummy padding token.\n",
    "        # pad_mask = (sentences == self.pad_word_id).float()\n",
    "\n",
    "        # # For these positions, we add some large number in the column corresponding\n",
    "        # # to the dummy padding label.\n",
    "        # out[:, :, self.pad_label_id] += pad_mask*10000\n",
    "\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        return [predicted[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QE7itQ88Qx17"
   },
   "outputs": [],
   "source": [
    "class RNNCRFTagger(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNCRFTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        self.crf = CRF(self.n_labels)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        ## should I initialize here??\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "      \n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # Compute the outputs of the lower layers, which will be used as emission\n",
    "        # scores for the CRF.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # We return the loss value. The CRF returns the log likelihood, but we return \n",
    "        # the *negative* log likelihood as the loss value.            \n",
    "        # PyTorch's optimizers *minimize* the loss, while we want to *maximize* the\n",
    "        # log likelihood.\n",
    "\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return -self.crf(scores, labels, mask = pad_mask )\n",
    "            \n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the emission scores, as above.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Apply the Viterbi algorithm to get the predictions. This implementation returns\n",
    "        # the result as a list of lists (not a tensor), corresponding to a matrix\n",
    "        # of shape (n_sentences, max_len).\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return self.crf.decode(scores,mask = pad_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXixmVQfvw8T"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3m_nj4HCuCe1"
   },
   "outputs": [],
   "source": [
    "# TODO: search over the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uAMSIlw0AJb6"
   },
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, train_dataloader, val_dataloader, n_epochs):\n",
    "    history = defaultdict(list)  \n",
    "    for i_epoch in range(1,n_epochs +1):\n",
    "        t0 = time.time()\n",
    "        loss_sum = 0\n",
    "        accuracy_sum = 0\n",
    "        model.train()\n",
    "        for seqs, targets, lens in train_dataloader: #seqs, targets, lens are batches\n",
    "            seqs, targets = seqs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = model(seqs,targets,lens) / sum(lens) #normalize for the number of symbol considered (without padding)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            predicted = model.predict(seqs,lens)\n",
    "            for i,p in enumerate(predicted):\n",
    "                acc= accuracy_score(p,targets[:,i][:len(p)].cpu()) #compute the accuracy without considering the padding\n",
    "                accuracy_sum += acc/len(lens) #normalize according to the number of sequences in the batch\n",
    "\n",
    "        train_loss = loss_sum/len(train_dataloader)\n",
    "        train_accuracy = accuracy_sum/len(train_dataloader) #normalize according to the number of batches\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_accuracy\"].append(train_accuracy)\n",
    "\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        all_predicted = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for seqs,targets, lens in val_dataloader:\n",
    "                # Predict the model's output on a batch\n",
    "                predicted = model.predict(seqs.to(device),lens)                   \n",
    "                # Update the lists that will be used to compute the accuracy\n",
    "                for i,p in enumerate(predicted):\n",
    "                    all_predicted.append(torch.Tensor(p))\n",
    "                    all_targets.append(targets[0:int(lens[i]),i])\n",
    "                \n",
    "        # Compute the overall accuracy for the validation set\n",
    "        val_accuracy = accuracy_score(torch.cat(all_predicted),torch.cat(all_targets))\n",
    "        history[\"val_accuracy\"].append(val_accuracy)\n",
    "\n",
    "#         save the model\n",
    "        torch.save(model, \"./models/temp/model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "#         files.download(\"model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "\n",
    "    \n",
    "        t1 = time.time()\n",
    "        print(f'Epoch {i_epoch}: train loss = {train_loss:.4f}, train_accuracy: {train_accuracy:.4f},val_accuracy: {val_accuracy:.4f}, time = {t1-t0:.4f}')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "2g2st8znpGW_",
    "outputId": "fe232e42-e270-4f5d-9bd8-718bba5e7151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda\n",
      "Epoch 1: train loss = 1.3113, train_accuracy: 0.7265,val_accuracy: 0.8634, time = 741.5108\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 1\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True, truncate = None)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\n",
    "val_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False,collate_fn=pad_collate)\n",
    "\n",
    "# model = torch.load(\"./models/temp/model_temp_epoch30-to_restart.pkl\")\n",
    "model = RNNCRFTagger(len(midi_to_ix)+len(duration_delimiter)+2,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "# model = RNNTagger(len(midi_to_ix)+len(duration_delimiter)+2,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_WEIGHT)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_WEIGHT, momentum = 0.9,weight_decay=WEIGHT_DECAY)\n",
    "# otimizer = torch.optim.Adam(model.parameters(),lr = 0.05, weight_decay=1e-4)\n",
    "\n",
    "history = training_loop(model,optimizer,train_dataloader,val_dataloader, n_epochs)\n",
    "\n",
    "# After the final evaluation, we print more detailed evaluation statistics,\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.legend(['training loss', 'training accuracy', 'validation_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy:  0.9548586557910835 at epoch 13\n"
     ]
    }
   ],
   "source": [
    "#find the best working model on the accuracy\n",
    "max_accuracy = np.max(history['val_accuracy'])\n",
    "best_epoch = np.argmax(history['val_accuracy'])\n",
    "print(\"Best validation accuracy: \",max_accuracy, \"at epoch\",best_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tTv2BrGbvSHh",
    "outputId": "801ff32d-24dc-4434-a436-17d9ca832214"
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"./models/model_asap_crf200dur.pkl\")\n",
    "# files.download(\"model_asap_crf300.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXcmLpCKt28l"
   },
   "source": [
    "## Test on Mdata dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./models/model_temp_CRFacc9548.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BacUqgD5usGL"
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "with open(Path(basepath,'./datasets/musedata.pkl'), 'rb') as fid:\n",
    "     full_mdata_dict_dataset = pickle.load( fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgaUwW2fuwg0",
    "outputId": "89fc5f7d-884a-4ee6-fc34-b3d512f0c4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 different pieces\n",
      "Average number of notes:  858.6319771007974\n"
     ]
    }
   ],
   "source": [
    "mdata_paths = list(set([e[\"original_path\"] for e in full_mdata_dict_dataset ]))\n",
    "\n",
    "# # remove the symbphony No.100 from Haydn because of the enharmonic transposition\n",
    "# paths.remove(\"datasets\\\\opnd\\\\haydndoversyms-10004m.opnd-m\")\n",
    "\n",
    "# print(paths)\n",
    "print(len(mdata_paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_mdata_dict_dataset ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "f-Fg6gJKvNLt"
   },
   "outputs": [],
   "source": [
    "mdata_dataset = PSDataset(full_mdata_dict_dataset,mdata_paths, transform_chrom,transform_diat,False)\n",
    "mdata_dataloader  = DataLoader(mdata_dataset,  batch_size=16, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ml905Mtdvj-T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "all_inputs = []\n",
    "all_outputs = []\n",
    "all_targets = []\n",
    "model.eval() # Evaluation mode (e.g. disable dropout)\n",
    "with torch.no_grad(): # Disable gradient tracking\n",
    "    for seqs, targets,lens in mdata_dataloader:\n",
    "        # Move data to device\n",
    "        seqs = seqs.to(device)\n",
    "\n",
    "        # Predict the model's output on a batch.\n",
    "        predicted = model.predict(seqs,lens)                   \n",
    "        # Update the evaluation statistics.\n",
    "        for i,p in enumerate(predicted):\n",
    "            all_inputs.append(torch.argmax(seqs[0:int(lens[i]),i,:].cpu(),1).numpy())\n",
    "            all_outputs.append(torch.Tensor(p))\n",
    "            all_targets.append(targets[0:int(lens[i]),i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsefdSHxvrWy",
    "outputId": "33785b90-5e03-4a6d-86dd-92b6b763a505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['viv', 'tel', 'bee', 'bac', 'han', 'cor', 'moz', 'hay']\n"
     ]
    }
   ],
   "source": [
    "# Divide accuracy according to author\n",
    "authors = []\n",
    "\n",
    "for sequence in all_inputs:\n",
    "    author = [e[\"original_path\"].split(\"\\\\\")[-1][:3] for e in full_mdata_dict_dataset\n",
    "              if len(e[\"midi_number\"]) == len(sequence) and\n",
    "              list(e[\"midi_number\"]) ==list(sequence) ]\n",
    "    # assert len(author) == 1\n",
    "    authors.append(author[0])\n",
    "\n",
    "considered_authors = list(set(authors))\n",
    "print(considered_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgNt_yG7vrfd",
    "outputId": "8473393f-dac6-4930-9d9e-da9c1046f1ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'viv': 36, 'tel': 41, 'bee': 185, 'bac': 101, 'han': 44, 'cor': 14, 'moz': 131, 'hay': 376}\n",
      "{'viv': 0.9985304322978323, 'tel': 0.9983265306122449, 'bee': 0.9924468215408484, 'bac': 0.9958783921648643, 'han': 0.9982040816326531, 'cor': 0.9994284081166047, 'moz': 0.9946517514493345, 'hay': 0.9846467946100449}\n",
      "{'viv': 24497, 'tel': 24500, 'bee': 24493, 'bac': 24505, 'han': 24500, 'cor': 24493, 'moz': 24494, 'hay': 24490}\n",
      "Total errors : 928\n"
     ]
    }
   ],
   "source": [
    "errors_per_author = {}\n",
    "accuracy_per_author = {}\n",
    "notes_per_author = {}\n",
    "for ca in considered_authors:\n",
    "    # ca_inputs = torch.cat([all_inputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_outputs = torch.cat([all_outputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_targets = torch.cat([all_targets[i] for i,a in enumerate(authors) if a == ca])\n",
    "    # print(ca_inputs.shape,ca_outputs.shape,ca_targets.shape,ca_predicted_pitches.shape)\n",
    "    ca_acc = accuracy_score(ca_outputs,ca_targets)\n",
    "    accuracy_per_author[ca] = float(ca_acc)\n",
    "    errors_per_author[ca] = int(len(ca_targets) - sum(torch.eq(ca_outputs,ca_targets)))\n",
    "    notes_per_author[ca] = len(ca_targets)\n",
    "\n",
    "print(errors_per_author)\n",
    "print(accuracy_per_author)\n",
    "print(notes_per_author)\n",
    "print(\"Total errors :\", sum([e for e in errors_per_author.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5s0d56evrje"
   },
   "source": [
    "### Best accuracy for now\n",
    "for now best accuracy is with  no CRF (but considering durations) n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 0.09\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "duration_delimiter = [0.125,0.25,0.5,1,2,4]\n",
    "\n",
    "Model available in: \"model_temp_epoch12-noCRFacc9575.pkl\"\n",
    "accuracy on validation set 0.9575\n",
    "Trained on all dataset\n",
    "\n",
    "\n",
    "{'moz': 98, 'tel': 116, 'bac': 93, 'hay': 200, 'cor': 25, 'bee': 127, 'viv': 45, 'han': 52}\n",
    "{'moz': 0.9959990201682044, 'tel': 0.995265306122449, 'bac': 0.9962048561518058, 'hay': 0.9918334013883218, 'cor': 0.9989793002082228, 'bee': 0.9948148450577716, 'viv': 0.9981630403722905, 'han': 0.9978775510204082}\n",
    "{'moz': 24494, 'tel': 24500, 'bac': 24505, 'hay': 24490, 'cor': 24493, 'bee': 24493, 'viv': 24497, 'han': 24500}\n",
    "Total errors : 756\n",
    "\n",
    "This win by far against ps13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVvP1eH8vrl3"
   },
   "source": [
    "### Best accuracy with CRF\n",
    "n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 1\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "model = RNNCRFTagger(len(midi_to_ix)+len(duration_delimiter)+2,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "\n",
    "Model available in: \"\"./models/model_temp_CRFacc9548.pkl\"\"\n",
    "accuracy on validation set 0.9548586557910835\n",
    "Trained on all asap dataset\n",
    "\n",
    "{'viv': 36, 'tel': 41, 'bee': 185, 'bac': 101, 'han': 44, 'cor': 14, 'moz': 131, 'hay': 376}\n",
    "{'viv': 0.9985304322978323, 'tel': 0.9983265306122449, 'bee': 0.9924468215408484, 'bac': 0.9958783921648643, 'han': 0.9982040816326531, 'cor': 0.9994284081166047, 'moz': 0.9946517514493345, 'hay': 0.9846467946100449}\n",
    "{'viv': 24497, 'tel': 24500, 'bee': 24493, 'bac': 24505, 'han': 24500, 'cor': 24493, 'moz': 24494, 'hay': 24490}\n",
    "Total errors : 928\n",
    "\n",
    "Still win against ps13"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOTDh55Hh2OWCo66dGc+SES",
   "include_colab_link": true,
   "name": "rnncrf_pitch_spelling",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
