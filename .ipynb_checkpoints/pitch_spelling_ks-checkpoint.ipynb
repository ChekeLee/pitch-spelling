{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fosfrancesco/pitch-spelling/blob/main/rnncrf_pitch_spelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fifMg_hxNSOg",
    "outputId": "a8b320f9-4231-40d9-8f10-a7b8acd1da37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-crf\n",
      "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hsciybUBNkur"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "import music21 as m21\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn\n",
    "import music21 as m21\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchcrf import CRF\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "\n",
    "import kmeans1d\n",
    "import jenkspy\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "# import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Naq6UG5jRbyK"
   },
   "source": [
    "# RNN-CRF for Pitch Spelling\n",
    "\n",
    "Dataset: different authors from ASAP collection\n",
    "Challenges:\n",
    "- extremely long sequences\n",
    "- small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mHJvrZ2Wo_e",
    "outputId": "1319f78b-cfb1-4e2a-937c-c47cf952757c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'C'), (1, 'B#'), (2, 'D--'), (3, 'C#'), (4, 'B##'), (5, 'D-'), (6, 'D'), (7, 'C##'), (8, 'E--'), (9, 'D#'), (10, 'E-'), (11, 'F--'), (12, 'E'), (13, 'D##'), (14, 'F-'), (15, 'F'), (16, 'E#'), (17, 'G--'), (18, 'F#'), (19, 'E##'), (20, 'G-'), (21, 'G'), (22, 'F##'), (23, 'A--'), (24, 'G#'), (25, 'A-'), (26, 'A'), (27, 'G##'), (28, 'B--'), (29, 'A#'), (30, 'B-'), (31, 'C--'), (32, 'B'), (33, 'A##'), (34, 'C-')]\n",
      "['D--', 'B##', 'C##', 'E--', 'F--', 'D##', 'G--', 'E##', 'F##', 'A--', 'G##', 'B--', 'C--', 'A##']\n",
      "[(0, 'P1'), (1, 'd2'), (2, 'A7'), (3, 'm2'), (4, 'A1'), (5, 'M2'), (6, 'd3'), (7, 'AA1'), (8, 'm3'), (9, 'A2'), (10, 'M3'), (11, 'd4'), (12, 'AA2'), (13, 'P4'), (14, 'A3'), (15, 'd5'), (16, 'A4'), (17, 'P5'), (18, 'd6'), (19, 'AA4'), (20, 'm6'), (21, 'A5'), (22, 'M6'), (23, 'd7'), (24, 'AA5'), (25, 'm7'), (26, 'A6'), (27, 'M7'), (28, 'd1'), (29, 'AA6')]\n",
      "[-7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "pitches_dict = {\n",
    "    0 : [\"C\",\"B#\",\"D--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    1 : [\"C#\",\"B##\",\"D-\"], # nn.Linear(input_size+context_size, 2)\n",
    "    2 : [\"D\",\"C##\",\"E--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    3 : [\"D#\",\"E-\",\"F--\"],\n",
    "    4 : [\"E\",\"D##\",\"F-\"],\n",
    "    5 : [\"F\",\"E#\",\"G--\"],\n",
    "    6 : [\"F#\",\"E##\",\"G-\"],\n",
    "    7 : [\"G\",\"F##\",\"A--\"],\n",
    "    8 : [\"G#\",\"A-\"],\n",
    "    9 : [\"A\",\"G##\",\"B--\"],\n",
    "    10 : [\"A#\",\"B-\",\"C--\"],\n",
    "    11 : [\"B\",\"A##\",\"C-\"]\n",
    "}\n",
    "\n",
    "accepted_pitches = [ii for i in pitches_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_pitches)])\n",
    "\n",
    "double_acc_pitches = [ii for i in pitches_dict.values() for ii in i if ii.endswith(\"##\") or  ii.endswith(\"--\") ]\n",
    "print(double_acc_pitches)\n",
    "\n",
    "def score2midi_numbers(score):\n",
    "    return [p.midi%12 for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "def score2pitches(score):\n",
    "    return [p.name for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "interval_dict = {\n",
    "    0 : [\"P1\",\"d2\",\"A7\"], \n",
    "    1 : [\"m2\",\"A1\"], \n",
    "    2 : [\"M2\",\"d3\",\"AA1\"], \n",
    "    3 : [\"m3\",\"A2\"],\n",
    "    4 : [\"M3\",\"d4\",\"AA2\"],\n",
    "    5 : [\"P4\",\"A3\"],\n",
    "    6 : [\"d5\",\"A4\"],\n",
    "    7 : [\"P5\",\"d6\",\"AA4\"],\n",
    "    8 : [\"m6\",\"A5\"],\n",
    "    9 : [\"M6\",\"d7\",\"AA5\"],\n",
    "    10 : [\"m7\",\"A6\"],\n",
    "    11 : [\"M7\",\"d1\",\"AA6\"]\n",
    "}\n",
    "\n",
    "accepted_intervals = [ii for i in interval_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_intervals)])\n",
    "\n",
    "def transp_score(score):\n",
    "    \"\"\" For each input return len(accepted_intervals) transposed scores\"\"\"\n",
    "    return [score.transpose(interval) for interval in accepted_intervals]\n",
    "\n",
    "def smart_transp_score(score):\n",
    "    \"\"\" For each chromatic interval chose the interval that lead to the smallest number of accidentals\"\"\"\n",
    "    scores = []\n",
    "    for chromatic_int in interval_dict.keys():\n",
    "        temp_scores = []\n",
    "        temp_acc_number = []\n",
    "        for diat_interval in interval_dict[chromatic_int]:\n",
    "            new_score = score.transpose(diat_interval)\n",
    "            temp_scores.append(new_score)\n",
    "            temp_acc_number.append(sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in score2pitches(new_score)]))\n",
    "            # print(\"choice:\", [note.name for note in temp_scores[-1].flat.notes][0:10],\"acc:\",temp_acc_number[-1] )\n",
    "        #keep only the one with the lowest number of accidentals\n",
    "        min_index = np.argmin(temp_acc_number)\n",
    "        # print(\"preferred the number\", min_index)\n",
    "        scores.append(temp_scores[min_index])\n",
    "    return scores\n",
    "\n",
    "def acc_simple_enough(score,accepted_ratio = 0.2 ):\n",
    "    pitches = score2pitches(score)\n",
    "    double_acc = sum(el in double_acc_pitches for el in pitches)\n",
    "    if double_acc/len(pitches) < accepted_ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "diatonic_pitches = [\"C\",\"D\", \"E\", \"F\", \"G\", \"A\", \"B\"]\n",
    "\n",
    "accepted_ks = list(range(-7,8))\n",
    "\n",
    "print(accepted_ks)\n",
    "\n",
    "# #test acc_simple_enough()\n",
    "# score = m21.converter.parse(paths[356])\n",
    "# scores = smart_transp_score(score)\n",
    "# #delete the pieces with non accepted pitches (e.g. triple sharps)\n",
    "# scores = [s for s in scores if all(pitch in accepted_pitches for pitch in score2pitches(s))]\n",
    "# for s in scores:\n",
    "#     print(s.parts[0].flat.getElementsByClass(m21.key.KeySignature)[0], \"simple enough:\", acc_simple_enough(s))\n",
    "#     print([n.name for n in s.flat.notes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw-SuL4ZB_2C"
   },
   "source": [
    "## Import ASAP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrZ0BwLEj2Gp",
    "outputId": "6b521f78-28db-4d4f-f4ef-9345c5d91db9"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/fosfrancesco/pitch-spelling.git\n",
    "\n",
    "basepath = \"./\" #to change if running locally or on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WaINjDS2kpxE"
   },
   "outputs": [],
   "source": [
    "# load the asap datasets with ks\n",
    "with open(Path('../asapks.pkl'), 'rb') as fid:\n",
    "     full_dict_dataset = pickle.load( fid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYQdkJAiTS6_",
    "outputId": "72835948-2884-40bb-e5b4-6ebbc8488895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 different pieces\n",
      "Average number of notes:  2410.253424657534\n"
     ]
    }
   ],
   "source": [
    "paths = list(set([e[\"original_path\"] for e in full_dict_dataset ]))\n",
    "\n",
    "# print(paths)\n",
    "print(len(paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_dict_dataset ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMdKkzNnCTrK"
   },
   "source": [
    "## Chose the convenient data augmentation\n",
    "Two possibilities:\n",
    "- for each chromatic interval, take only the diatonic transposition that produce the smallest number of accidentals (or the original if present)\n",
    "- take only a certain interval of time signatures\n",
    "\n",
    "The second is probably better for a smaller and simple dataset, but gives the problem of chosing between for example F# and G# that are both present in this bigger dataset. So we go for the first criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oign7EZ9BSX4",
    "outputId": "9aa3f694-289a-43fd-fd14-9cad3b8dd3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No options for Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml . Chromatic:  1\n",
      "No options for Liszt/Transcendental_Etudes/9/xml_score.musicxml . Chromatic:  6\n",
      "No options for Liszt/Transcendental_Etudes/9/xml_score.musicxml . Chromatic:  11\n",
      "No options for Liszt/Mephisto_Waltz/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  11\n",
      "No options for Liszt/Transcendental_Etudes/4/xml_score.musicxml . Chromatic:  2\n",
      "No options for Liszt/Transcendental_Etudes/4/xml_score.musicxml . Chromatic:  4\n",
      "No options for Liszt/Transcendental_Etudes/4/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  9\n",
      "No options for Liszt/Sonata/xml_score.musicxml . Chromatic:  4\n",
      "No options for Liszt/Sonata/xml_score.musicxml . Chromatic:  6\n",
      "No options for Liszt/Sonata/xml_score.musicxml . Chromatic:  11\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  1\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  4\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  6\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  9\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  11\n",
      "No options for Scriabin/Sonatas/5/xml_score.musicxml . Chromatic:  1\n",
      "No options for Scriabin/Sonatas/5/xml_score.musicxml . Chromatic:  6\n",
      "No options for Scriabin/Sonatas/5/xml_score.musicxml . Chromatic:  11\n",
      "No options for Liszt/Transcendental_Etudes/10/xml_score.musicxml . Chromatic:  1\n",
      "No options for Liszt/Transcendental_Etudes/10/xml_score.musicxml . Chromatic:  6\n",
      "No options for Ravel/Miroirs/4_Alborada_del_gracioso/xml_score.musicxml . Chromatic:  11\n",
      "No options for Debussy/Images_Book_1/1_Reflets_dans_lEau/xml_score.musicxml . Chromatic:  3\n",
      "No options for Debussy/Images_Book_1/1_Reflets_dans_lEau/xml_score.musicxml . Chromatic:  8\n",
      "No options for Liszt/Transcendental_Etudes/11/xml_score.musicxml . Chromatic:  1\n",
      "No options for Liszt/Transcendental_Etudes/11/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  1\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  3\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  8\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  10\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  11\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  1\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  4\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  6\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  9\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  9\n",
      "No options for Ravel/Gaspard_de_la_Nuit/1_Ondine/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Ballades/4/xml_score.musicxml . Chromatic:  6\n",
      "Before removing according to ks: 2618\n",
      "After removing according to ks: 2406\n"
     ]
    }
   ],
   "source": [
    "# choose only one enharmonic version for each chromatic interval for each piece\n",
    "dict_dataset = []\n",
    "for path in paths:\n",
    "    for c in range(12):\n",
    "        pieces_to_consider = [opus for opus in full_dict_dataset \n",
    "                              if (opus[\"original_path\"] == path and opus[\"transposed_of\"] in interval_dict[c])  ]\n",
    "        # if the original is in pieces_to_consider, go with the original\n",
    "        originals = [opus for opus in pieces_to_consider if opus[\"transposed_of\"] == \"P1\"]\n",
    "        if len(originals) == 1:\n",
    "            dict_dataset.append(originals[0])\n",
    "        else: #we go with the accidental minization criteria\n",
    "            n_accidentals = [sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in opus[\"pitches\"]]) \n",
    "                            for opus in pieces_to_consider]\n",
    "            if len(pieces_to_consider)>0:\n",
    "                dict_dataset.append(pieces_to_consider[np.argmin(n_accidentals)])\n",
    "            else:\n",
    "                print(\"No options for\", path, \". Chromatic: \",c )\n",
    "\n",
    "# for e in dict_dataset:\n",
    "#     for ks in e[\"key_signatures\"]:\n",
    "#         if not ks in accepted_ks:\n",
    "#             print(\"Problem ks:\", ks, e[\"original_path\"], e[\"transposed_of\"])\n",
    "                \n",
    "#also remove unaccepted ks\n",
    "print(\"Before removing according to ks:\", len(dict_dataset))\n",
    "dict_dataset = [e for e in dict_dataset if all([k in accepted_ks for k in e[\"key_signatures\"]])]\n",
    "print(\"After removing according to ks:\", len(dict_dataset))\n",
    "                                                    \n",
    "\n",
    "# #test if it worked\n",
    "# for i,e in enumerate(dict_dataset):\n",
    "#     print(e[\"original_path\"], e[\"transposed_of\"], e[\"key_signatures\"])\n",
    "#     print(e[\"pitches\"][:10])\n",
    "#     print(e[\"midi_number\"][:10])\n",
    "#     if i == 100:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgHkMeoJdb42",
    "outputId": "1f3d172f-3f93-47ce-aa1b-e37a2afba24e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2406\n",
      "Counter({'Bach': 59, 'Beethoven': 57, 'Chopin': 34, 'Liszt': 16, 'Schubert': 13, 'Haydn': 11, 'Schumann': 10, 'Mozart': 6, 'Rachmaninoff': 4, 'Ravel': 4, 'Scriabin': 2, 'Debussy': 2, 'Glinka': 1, 'Brahms': 1, 'Prokofiev': 1, 'Balakirev': 1})\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_dataset))\n",
    "\n",
    "c = Counter()\n",
    "for p in paths:\n",
    "    c[p.split(\"/\")[0]] +=1\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 initial pieces\n",
      "221 pieces after removing overlapping with musedata\n"
     ]
    }
   ],
   "source": [
    "# remove pieces from asap that are in Musedata\n",
    "print(len(paths), \"initial pieces\")\n",
    "paths = [p for p in paths if p!= \"Bach/Prelude/bwv_865/xml_score.musicxml\"]\n",
    "print(len(paths), \"pieces after removing overlapping with musedata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GRCM2W3qqeW",
    "outputId": "d53c8146-8b32-43df-cd69-b7423f1ceda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation lenghts:  164 29\n"
     ]
    }
   ],
   "source": [
    "# Temporary remove composer with only one piece, because they create problems with sklearn stratify\n",
    "one_piece_composers = ['Balakirev','Prokofiev','Brahms','Glinka', 'Debussy', 'Ravel', 'Scriabin','Liszt']\n",
    "paths = [p for p in paths if p.split(\"/\")[0] not in one_piece_composers]\n",
    "\n",
    "# Divide train and validation set\n",
    "path_train, path_validation = sklearn.model_selection.train_test_split(paths, test_size=0.15,stratify=[p.split(\"/\")[0] for p in paths ])\n",
    "print(\"Train and validation lenghts: \",len(path_train),len(path_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "KIZ2_bX1bom5",
    "outputId": "ae8d5b50-ed4d-4376-f9d6-e96c6aa73046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chopin', 'Beethoven', 'Bach', 'Rachmaninoff', 'Haydn', 'Mozart', 'Schumann', 'Schubert']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 379
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#need to find a better way to visualize this\n",
    "composers = list(set([p.split(\"/\")[0] for p in paths ]))\n",
    "print(composers)\n",
    "\n",
    "train_composer = [composers.index(p.split(\"/\")[0]) for p in path_train]\n",
    "val_composer = [composers.index(p.split(\"/\")[0]) for p in path_validation]\n",
    "\n",
    "_ = plt.hist([train_composer, val_composer], label=['train', 'validation'])\n",
    "_ = plt.legend(loc='upper left')\n",
    "_ = plt.xticks(list(range(len(composers))), composers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-qaT10ApkCY"
   },
   "source": [
    "## Transform the input into a convenient format for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEYec2TDOWvj",
    "outputId": "1b69573b-cfeb-4dc9-8882-da42f9c25537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n"
     ]
    }
   ],
   "source": [
    "# Helper functions to feed the correct input into the NN \n",
    "\n",
    "N_DURATION_CLASSES = 4\n",
    "PAD = \"<PAD>\"\n",
    "\n",
    "pitch_to_ix = {p: accepted_pitches.index(p) for p in accepted_pitches}\n",
    "ks_to_ix = {k: accepted_ks.index(k) for k in accepted_ks}\n",
    "#add PADDING TAD\n",
    "pitch_to_ix[PAD] = len(accepted_pitches)\n",
    "ks_to_ix[PAD] = len(accepted_ks)\n",
    "\n",
    "midi_to_ix = {m: m for m in range(12)}\n",
    "# #add PADDING TAD\n",
    "# midi_to_ix[PAD] = 12\n",
    "\n",
    "# print(midi_to_ix[1])\n",
    "# print(len(midi_to_ix))\n",
    "\n",
    "\n",
    "\n",
    "# class Pitch2Diatonic():\n",
    "#     def __call__(self, in_seq):\n",
    "#         return [p for p in in_seq]\n",
    "\n",
    "class Pitch2Int():\n",
    "    def __call__(self, in_seq):\n",
    "        idxs = [pitch_to_ix[w] for w in in_seq]\n",
    "        return idxs\n",
    "    \n",
    "class Ks2Int():\n",
    "    def __call__(self, in_seq):\n",
    "        idxs = [ks_to_ix[w] for w in in_seq]\n",
    "        return idxs\n",
    "\n",
    "class Int2Pitch():\n",
    "    def __call__(self, in_seq):\n",
    "        return [accepted_pitches[i] for i in in_seq]\n",
    "\n",
    "class OneHotEncoder():\n",
    "    def __init__(self, alphabet_len):\n",
    "        self.alphabet_len = alphabet_len\n",
    "        \n",
    "    def __call__(self, sample,weights = None):\n",
    "        onehot = np.zeros([len(sample), self.alphabet_len])\n",
    "        tot_chars = len(sample)\n",
    "        onehot[np.arange(tot_chars), sample] = 1\n",
    "        return onehot\n",
    "    \n",
    "# class DurationOneHotEncoder():\n",
    "#     def __init__(self, pitch_alphabet_len, n_dur_class = 4):\n",
    "#         self.pitch_alphabet_len = pitch_alphabet_len\n",
    "#         self.dur_alphabet_len = n_dur_class\n",
    "        \n",
    "#     def __call__(self, sample, durs):\n",
    "#         sample = torch.tensor(sample,dtype=torch.long)\n",
    "#         onehot_pitch = torch.nn.functional.one_hot(sample,self.pitch_alphabet_len)\n",
    "#         #compute breaks in duration list\n",
    "#         if len(set(durs)) > N_DURATION_CLASSES: \n",
    "#             breaks = jenkspy.jenks_breaks(list(set(durs)), nb_class=N_DURATION_CLASSES)\n",
    "#             #quantize according to the breaks selected\n",
    "#             quantized_durations = np.digitize(durs,breaks[1:-1])\n",
    "#         elif len(set(durs)) > 2 : # in this case jenks breaks would throw an exception \n",
    "#             temp_n_classes = len(set(durs)) -1\n",
    "#             breaks = jenkspy.jenks_breaks(list(set(durs)), nb_class=temp_n_classes)\n",
    "#             # add lower classes to have the same number for all dataset\n",
    "#             for __ in range(N_DURATION_CLASSES-temp_n_classes):\n",
    "#                 breaks = [breaks[0]/2] + breaks\n",
    "#             #quantize according to the breaks selected\n",
    "#             quantized_durations = np.digitize(durs,breaks[1:-1])\n",
    "#         else: # just use custom default\n",
    "#             #quantize according to the breaks selected\n",
    "#             quantized_durations = [1 for d in durs]        \n",
    "#         quantized_durations = torch.tensor(quantized_durations,dtype=torch.long)\n",
    "#         onehot_duration = torch.nn.functional.one_hot(quantized_durations,self.dur_alphabet_len)\n",
    "#         return torch.cat([onehot_pitch,onehot_duration],1)\n",
    "\n",
    "class DurationOneHotEncoder():\n",
    "    def __init__(self, pitch_alphabet_len, n_dur_class = 4):\n",
    "        self.pitch_alphabet_len = pitch_alphabet_len\n",
    "        self.dur_alphabet_len = n_dur_class\n",
    "        \n",
    "    def __call__(self, sample, durs):\n",
    "        sample = torch.tensor(sample,dtype=torch.long)\n",
    "        onehot_pitch = torch.nn.functional.one_hot(sample,self.pitch_alphabet_len)\n",
    "        #compute breaks in duration list\n",
    "        clusters, centroids = kmeans1d.cluster(durs, N_DURATION_CLASSES)   \n",
    "        quantized_durations = torch.tensor(clusters,dtype=torch.long)\n",
    "        onehot_duration = torch.nn.functional.one_hot(quantized_durations,self.dur_alphabet_len)\n",
    "        return torch.cat([onehot_pitch,onehot_duration],1)\n",
    "    \n",
    "        \n",
    "class ToTensorFloat():\n",
    "    def __call__(self, sample, durs = None):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.float()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.float)\n",
    "\n",
    "class ToTensorLong():\n",
    "    def __call__(self, sample):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.long()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.long)\n",
    "    \n",
    "class MultInputCompose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, sample, durs):\n",
    "        for t in self.transforms:\n",
    "            sample = t(sample, durs)\n",
    "        return sample\n",
    "\n",
    "\n",
    "### Define the preprocessing pipeline\n",
    "transform_diat = transforms.Compose([Pitch2Int(),ToTensorLong()])\n",
    "transform_chrom = MultInputCompose([DurationOneHotEncoder(len(midi_to_ix),N_DURATION_CLASSES),ToTensorFloat()])\n",
    "transform_key = transforms.Compose([Ks2Int(),ToTensorLong()])\n",
    "\n",
    "\n",
    "print(set([ks_to_ix[ks] for piece in dict_dataset for ks in piece[\"key_signatures\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV9boYaToUs2",
    "outputId": "92bcd8d3-87a2-4d2c-8e92-4a106139f59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1822 29\n",
      "torch.Size([1476, 16])\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "1476\n",
      "torch.Size([807, 16])\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "807\n",
      "torch.Size([576, 16])\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "576\n",
      "torch.Size([847, 16])\n",
      "[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "847\n",
      "torch.Size([3266, 16])\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "3266\n",
      "torch.Size([638, 16])\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "638\n",
      "torch.Size([3491, 16])\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "3491\n",
      "torch.Size([1378, 16])\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "1378\n",
      "torch.Size([1300, 16])\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "1300\n",
      "torch.Size([1475, 16])\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "1475\n",
      "torch.Size([2566, 16])\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "2566\n",
      "torch.Size([1746, 16])\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "1746\n",
      "torch.Size([1497, 16])\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "1497\n",
      "torch.Size([6311, 16])\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "6311\n",
      "torch.Size([5076, 16])\n",
      "[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "5076\n",
      "torch.Size([7797, 16])\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "7797\n",
      "torch.Size([1829, 16])\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "1829\n",
      "torch.Size([4546, 16])\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "4546\n",
      "torch.Size([1829, 16])\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "1829\n",
      "torch.Size([4964, 16])\n",
      "[13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "4964\n",
      "torch.Size([1960, 16])\n",
      "[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "1960\n",
      "torch.Size([1058, 16])\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "1058\n",
      "torch.Size([3141, 16])\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "3141\n",
      "torch.Size([2232, 16])\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "2232\n",
      "torch.Size([772, 16])\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "772\n",
      "torch.Size([1065, 16])\n",
      "[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "1065\n",
      "torch.Size([2292, 16])\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "2292\n",
      "torch.Size([1325, 16])\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "1325\n",
      "torch.Size([3015, 16])\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "3015\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "\n",
    "class PSDataset(Dataset):\n",
    "    def __init__(self, dict_dataset, paths, transf_c, transf_d, transf_k, augment_dataset, sort =False, truncate = None):\n",
    "        if sort:\n",
    "            dict_dataset = sorted(dict_dataset, key = lambda e: (len(e['midi_number'])),reverse=True)\n",
    "        if not augment_dataset: #remove the transposed pieces\n",
    "            dict_dataset = [e for e in dict_dataset if e[\"transposed_of\"]==\"P1\"]\n",
    "        #consider only pieces in paths\n",
    "        dict_dataset = [e for e in dict_dataset if e[\"original_path\"] in paths]\n",
    "        \n",
    "        #extract the useful data from dataset        \n",
    "        self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset]\n",
    "        self.diatonic_sequences = [e[\"pitches\"] for e in dict_dataset]\n",
    "        self.durations = [e[\"duration\"] for e in dict_dataset]\n",
    "        self.ks = [e[\"key_signatures\"] for e in dict_dataset]\n",
    "\n",
    "        #the transformations to apply to data\n",
    "        self.transf_c = transf_c\n",
    "        self.transf_d = transf_d\n",
    "        self.transf_ks = transf_k\n",
    "        self.truncate = truncate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chromatic_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chromatic_seq = self.chromatic_sequences[idx]\n",
    "        diatonic_seq = self.diatonic_sequences[idx]\n",
    "        duration_seq = self.durations[idx]    \n",
    "        ks_seq = self.ks[idx] \n",
    "\n",
    "        #transform\n",
    "        chromatic_seq = self.transf_c(chromatic_seq,duration_seq)\n",
    "        diatonic_seq = self.transf_d(diatonic_seq)\n",
    "        ks_seq = self.transf_ks(ks_seq)\n",
    "\n",
    "        if not self.truncate is None:\n",
    "            if len(diatonic_seq) > self.truncate:\n",
    "                chromatic_seq = chromatic_seq[0:self.truncate]\n",
    "                diatonic_seq = diatonic_seq[0:self.truncate]\n",
    "\n",
    "        #sanity check\n",
    "        assert len(chromatic_seq) == len(diatonic_seq) == len(ks_seq)\n",
    "        seq_len = len(diatonic_seq)\n",
    "        \n",
    "        return chromatic_seq, diatonic_seq, ks_seq, seq_len\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,transform_key,True, sort = True)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat,transform_key, False)\n",
    "\n",
    "print(len(train_dataset),len(validation_dataset))\n",
    "\n",
    "\n",
    "# test if it works\n",
    "for chrom,diat,ks,seq_len in validation_dataset:\n",
    "    print(chrom.shape)\n",
    "#     print(torch.argmax(chrom[0:30],1))\n",
    "#     # print([diatonic_pitches[p.item()] for p in diat[0:30]])\n",
    "#     print([accepted_pitches[p.item()] for p in diat[0:30]])\n",
    "    print([p.item() for p in ks[0:30]])\n",
    "    print(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAubyjw2LC8P",
    "outputId": "d6f8574f-8901-41e7-fd7a-9a0c6091eafa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4964, 4, 16]) torch.Size([4964, 4]) torch.Size([4964, 4])\n",
      "tensor([[ 3,  3, 15, 26],\n",
      "        [ 3, 12, 12,  0],\n",
      "        [24, 26, 15, 12],\n",
      "        ...,\n",
      "        [18, 35, 35, 35],\n",
      "        [18, 35, 35, 35],\n",
      "        [18, 35, 35, 35]])\n"
     ]
    }
   ],
   "source": [
    "def pad_collate(batch):\n",
    "    (xx, yy,zz, l) = zip(*batch)\n",
    "    \n",
    "    xx_pad = pad_sequence(xx)\n",
    "    yy_pad = pad_sequence(yy, padding_value=pitch_to_ix[PAD])\n",
    "    zz_pad = pad_sequence(zz, padding_value=ks_to_ix[PAD])\n",
    "\n",
    "    #sort the sequences by length\n",
    "    seq_lengths, perm_idx = torch.Tensor(l).sort(0, descending=True)\n",
    "    xx_pad = xx_pad[:,perm_idx,:]\n",
    "    yy_pad = yy_pad[:,perm_idx]\n",
    "    zz_pad = yy_pad[:,perm_idx]\n",
    "\n",
    "    return xx_pad, yy_pad,zz_pad, seq_lengths\n",
    "\n",
    "data_loader = DataLoader(dataset=validation_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "#test if it work\n",
    "for batch in data_loader:\n",
    "    print(batch[0].shape,batch[1].shape,batch[2].shape)\n",
    "    print(batch[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O1OA1AjGWO-"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QEkFBY5cUsmN"
   },
   "outputs": [],
   "source": [
    "class RNNTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, pitch_to_ix,ks_to_ix,n_layers =1):\n",
    "        super(RNNTagger,self).__init__()    \n",
    "        \n",
    "        self.n_out_pitch = len(pitch_to_ix)\n",
    "        self.n_out_ks = len(ks_to_ix)\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer_pitch = nn.Linear(hidden_dim, self.n_out_pitch)\n",
    "        self.top_layer_ks = nn.Linear(hidden_dim, self.n_out_ks)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss_pitch = torch.nn.CrossEntropyLoss(reduction='mean', ignore_index = pitch_to_ix[PAD])\n",
    "        self.loss_ks = torch.nn.CrossEntropyLoss(reduction='mean', ignore_index = ks_to_ix[PAD])\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out_pitch = self.top_layer_pitch(rnn_out)\n",
    "        out_ks = self.top_layer_ks(rnn_out)\n",
    "\n",
    "        return out_pitch,out_ks\n",
    "                \n",
    "    def forward(self, sentences, pitches, keysignatures, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores_pitch, scores_ks = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores_pitch = scores_pitch.view(-1, self.n_out_pitch)\n",
    "        scores_ks = scores_ks.view(-1, self.n_out_ks)\n",
    "        print(\"Printing shapes before losses\")\n",
    "        print(scores_pitch.shape)\n",
    "        print(scores_ks.shape)\n",
    "        pitches = pitches.view(-1)\n",
    "        keysignatures = keysignatures.view(-1)\n",
    "        print(\"printing losses\")\n",
    "        print(self.loss_pitch(scores_pitch, pitches))\n",
    "        print(self.loss_ks(scores_ks,keysignatures))\n",
    "        return self.loss_pitch(scores_pitch, pitches) + self.loss_ks(scores_ks,keysignatures)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores_pitch, scores_ks = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted_pitch = scores_pitch.argmax(dim=2)\n",
    "        predicted_ks = scores_ks.argmax(dim=2)\n",
    "        return [predicted_pitch[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)],[predicted_ks[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "QE7itQ88Qx17"
   },
   "outputs": [],
   "source": [
    "class RNNCRFTagger(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNCRFTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        self.crf = CRF(self.n_labels)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        ## should I initialize here??\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "      \n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # Compute the outputs of the lower layers, which will be used as emission\n",
    "        # scores for the CRF.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # We return the loss value. The CRF returns the log likelihood, but we return \n",
    "        # the *negative* log likelihood as the loss value.            \n",
    "        # PyTorch's optimizers *minimize* the loss, while we want to *maximize* the\n",
    "        # log likelihood.\n",
    "\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return -self.crf(scores, labels, mask = pad_mask )\n",
    "            \n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the emission scores, as above.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Apply the Viterbi algorithm to get the predictions. This implementation returns\n",
    "        # the result as a list of lists (not a tensor), corresponding to a matrix\n",
    "        # of shape (n_sentences, max_len).\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return self.crf.decode(scores,mask = pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNAttentionTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNAttentionTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='mean',ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "        # attention function\n",
    "        # TODO : set right parameters\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "        # use attention\n",
    "        attn_applied = self.attention(rnn_out,rnn_out,sentences_len)\n",
    "        \n",
    "        out = self.top_layer(attn_applied) #maybe remove this one?\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        return [predicted[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]\n",
    "    \n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention,self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W = torch.nn.Parameter(torch.FloatTensor(\n",
    "            hidden_dim, hidden_dim).uniform_(-0.1, 0.1))\n",
    "\n",
    "    def forward(self,\n",
    "                query, # [seq_len, batch, hidden_dim]\n",
    "                values, # [seq_len, batch, hidden_dim]\n",
    "                sentences_len\n",
    "               ):\n",
    "        weights = self._get_weights(query, values) # [batch,seq_length,hidden_dim]\n",
    "        # mask the weights\n",
    "        inverted_pad_mask = torch.arange(max(sentences_len))[None,:] > sentences_len[:,None]\n",
    "        inverted_pad_mask = (inverted_pad_mask.float()*(-10000)).unsqueeze(1).to(device)\n",
    "#         print(weights.shape,inverted_pad_mask.shape )\n",
    "        #apply the mask\n",
    "        weights = weights - inverted_pad_mask\n",
    "        \n",
    "        weights = torch.nn.functional.softmax(weights, dim=-1)\n",
    "        \n",
    "        out = torch.transpose((weights @ torch.transpose(values,0,1)),0,1)\n",
    "#         print(\"ATT out shape\", out.shape)\n",
    "        return out # [seq_len,batch,encoder_dim]\n",
    "\n",
    "    def _get_weights(self,\n",
    "        query: torch.Tensor,  # [decoder_dim]\n",
    "        values: torch.Tensor, # [seq_length, encoder_dim]\n",
    "    ):\n",
    "        #transpose to batch first to correctly handle batch multiplications\n",
    "#         print(\"shape\",query.shape,self.W.shape, values.shape)\n",
    "        query,values = torch.transpose(query,0,1),torch.transpose(values,0,1)\n",
    "#         print(\"shape\",query.shape,self.W.shape, values.shape)\n",
    "#         print(\"stape values.t\", torch.transpose(values,1,2).shape)\n",
    "        weights = query @ self.W @ torch.transpose(values,1,2)  # [seq_length]\n",
    "#         print(\"out att shape\", weights.shape)\n",
    "        return weights/np.sqrt(self.hidden_dim)  # [seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNMultAttentionTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNMultAttentionTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='mean',ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "        # attention function\n",
    "        self.attention = torch.nn.MultiheadAttention(hidden_dim,num_heads= 1)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "        # compute padding mask (True when padded, ignore True)\n",
    "        inverted_pad_mask = torch.arange(max(sentences_len))[None,:] > sentences_len[:,None]\n",
    "        \n",
    "        # use attention\n",
    "        attn_applied, _ = self.attention(rnn_out,rnn_out,rnn_out,key_padding_mask = inverted_pad_mask.to(device))\n",
    "        \n",
    "        out = self.top_layer(attn_applied)\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        return [predicted[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXixmVQfvw8T"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "3m_nj4HCuCe1"
   },
   "outputs": [],
   "source": [
    "# TODO: search over the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "uAMSIlw0AJb6"
   },
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, train_dataloader, val_dataloader, n_epochs):\n",
    "    history = defaultdict(list)  \n",
    "    for i_epoch in range(1,n_epochs +1):\n",
    "        t0 = time.time()\n",
    "        loss_sum = 0\n",
    "        accuracy_sum = 0\n",
    "        model.train()\n",
    "        for seqs, pitches,keysignatures, lens in train_dataloader: #seqs, pitches, keysignatures, lens are batches\n",
    "            seqs, pitches,keysignatures  = seqs.to(device), pitches.to(device),keysignatures.to(device)\n",
    "            optimizer.zero_grad()\n",
    "#             print(\"input seq shape:\",seqs.shape)\n",
    "\n",
    "#             loss = model(seqs,targets,lens) / sum(lens) #normalize for the number of symbol considered (without padding)\n",
    "            loss = model(seqs,pitches,keysignatures,lens)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            predicted = model.predict(seqs,lens)\n",
    "            for i,p in enumerate(predicted):\n",
    "                acc= accuracy_score(p,pitches[:,i][:len(p)].cpu()) #compute the accuracy without considering the padding\n",
    "                accuracy_sum += acc/len(lens) #normalize according to the number of sequences in the batch\n",
    "\n",
    "        train_loss = loss_sum/len(train_dataloader)\n",
    "        train_accuracy = accuracy_sum/len(train_dataloader) #normalize according to the number of batches\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_accuracy\"].append(train_accuracy)\n",
    "\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        all_predicted = []\n",
    "        all_pitches = []\n",
    "        with torch.no_grad():\n",
    "            for seqs,pitches,keysignatures, lens in val_dataloader:\n",
    "                # Predict the model's output on a batch\n",
    "                predicted = model.predict(seqs.to(device),lens)                   \n",
    "                # Update the lists that will be used to compute the accuracy\n",
    "                for i,p in enumerate(predicted):\n",
    "                    all_predicted.append(torch.Tensor(p))\n",
    "                    all_targets.append(targets[0:int(lens[i]),i])\n",
    "                \n",
    "        # Compute the overall accuracy for the validation set\n",
    "        val_accuracy = accuracy_score(torch.cat(all_predicted),torch.cat(all_pitches))\n",
    "        history[\"val_accuracy\"].append(val_accuracy)\n",
    "\n",
    "#         save the model\n",
    "        torch.save(model, \"./models/temp/model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "#         files.download(\"model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "\n",
    "    \n",
    "        t1 = time.time()\n",
    "        print(f'Epoch {i_epoch}: train loss = {train_loss:.4f}, train_accuracy: {train_accuracy:.4f},val_accuracy: {val_accuracy:.4f}, time = {t1-t0:.4f}')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del train_dataset\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(midi_to_ix)+N_DURATION_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "2g2st8znpGW_",
    "outputId": "fe232e42-e270-4f5d-9bd8-718bba5e7151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda\n",
      "Printing shapes before losses\n",
      "torch.Size([50920, 36])\n",
      "torch.Size([50920, 16])\n",
      "printing losses\n",
      "tensor(3.5564, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-dbe3fbecad3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_WEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMOMENTUM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWEIGHT_DECAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# After the final evaluation, we print more detailed evaluation statistics,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-3e63d73757d3>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, optimizer, train_dataloader, val_dataloader, n_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#             loss = model(seqs,targets,lens) / sum(lens) #normalize for the number of symbol considered (without padding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpitches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeysignatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-c7fc5b9db925>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences, pitches, keysignatures, sentences_len)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"printing losses\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_pitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_pitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpitches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_ks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_ks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeysignatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_pitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_pitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpitches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_ks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_ks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeysignatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 0.05\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 8\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,transform_key,True,sort=True, truncate = None)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat,transform_key, False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\n",
    "val_dataloader = DataLoader(validation_dataset, batch_size=1, shuffle=False,collate_fn=pad_collate)\n",
    "\n",
    "# model = torch.load(\"./models/temp/model_temp_epoch30-to_restart.pkl\")\n",
    "model = RNNTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,pitch_to_ix,ks_to_ix, n_layers =1)\n",
    "# model = RNNCRFTagger(len(midi_to_ix)+number_duration_classes,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "# model = RNNAttentionTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "# model = RNNMultAttentionTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_WEIGHT, momentum = MOMENTUM,weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "history = training_loop(model,optimizer,train_dataloader,val_dataloader, n_epochs)\n",
    "\n",
    "# After the final evaluation, we print more detailed evaluation statistics,\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.legend(['training loss', 'training accuracy', 'validation_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy:  0.9677076058399016 at epoch 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2c011c4780>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 372
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find the best working model on the accuracy\n",
    "max_accuracy = np.max(history['val_accuracy'])\n",
    "best_epoch = np.argmax(history['val_accuracy'])\n",
    "print(\"Best validation accuracy: \",max_accuracy, \"at epoch\",best_epoch)\n",
    "\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.legend(['training loss', 'training accuracy', 'validation_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tTv2BrGbvSHh",
    "outputId": "801ff32d-24dc-4434-a436-17d9ca832214"
   },
   "outputs": [],
   "source": [
    "# torch.save(model, \"./models/model_asap_crf200dur.pkl\")\n",
    "# files.download(\"model_asap_crf300.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXcmLpCKt28l"
   },
   "source": [
    "## Test on Mdata dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./models/temp/model_temp_epoch12.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "BacUqgD5usGL"
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "with open(Path(basepath,'./datasets/musedata_noisy.pkl'), 'rb') as fid:\n",
    "     full_mdata_dict_dataset = pickle.load( fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgaUwW2fuwg0",
    "outputId": "89fc5f7d-884a-4ee6-fc34-b3d512f0c4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 different pieces\n",
      "Average number of notes:  907.2777777777778\n"
     ]
    }
   ],
   "source": [
    "mdata_paths = list(set([e[\"original_path\"] for e in full_mdata_dict_dataset ]))\n",
    "\n",
    "# # remove the symbphony No.100 from Haydn because of the enharmonic transposition\n",
    "# paths.remove(\"datasets\\\\opnd\\\\haydndoversyms-10004m.opnd-m\")\n",
    "\n",
    "# print(paths)\n",
    "print(len(mdata_paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_mdata_dict_dataset ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "f-Fg6gJKvNLt"
   },
   "outputs": [],
   "source": [
    "mdata_dataset = PSDataset(full_mdata_dict_dataset,mdata_paths, transform_chrom,transform_diat,False)\n",
    "mdata_dataloader  = DataLoader(mdata_dataset,  batch_size=1, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ml905Mtdvj-T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "all_inputs = []\n",
    "all_outputs = []\n",
    "all_targets = []\n",
    "model.eval() # Evaluation mode (e.g. disable dropout)\n",
    "with torch.no_grad(): # Disable gradient tracking\n",
    "    for seqs, targets,lens in mdata_dataloader:\n",
    "        # Move data to device\n",
    "        seqs = seqs.to(device)\n",
    "\n",
    "        # Predict the model's output on a batch.\n",
    "        predicted = model.predict(seqs,lens)                   \n",
    "        # Update the evaluation statistics.\n",
    "        for i,p in enumerate(predicted):\n",
    "            all_inputs.append(torch.argmax(seqs[0:int(lens[i]),i,:].cpu(),1).numpy())\n",
    "            all_outputs.append(torch.Tensor(p))\n",
    "            all_targets.append(targets[0:int(lens[i]),i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsefdSHxvrWy",
    "outputId": "33785b90-5e03-4a6d-86dd-92b6b763a505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hay', 'bac', 'han', 'cor', 'moz', 'bee', 'tel', 'viv']\n"
     ]
    }
   ],
   "source": [
    "# Divide accuracy according to author\n",
    "authors = []\n",
    "\n",
    "for sequence in all_inputs:\n",
    "    author = [e[\"original_path\"].split(\"\\\\\")[-1][:3] for e in full_mdata_dict_dataset\n",
    "              if len(e[\"midi_number\"]) == len(sequence) and\n",
    "              list(e[\"midi_number\"]) ==list(sequence) ]\n",
    "    # assert len(author) == 1\n",
    "    authors.append(author[0])\n",
    "\n",
    "considered_authors = list(set(authors))\n",
    "print(considered_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgNt_yG7vrfd",
    "outputId": "8473393f-dac6-4930-9d9e-da9c1046f1ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hay': 485, 'bac': 111, 'han': 28, 'cor': 21, 'moz': 171, 'bee': 335, 'tel': 87, 'viv': 102}\n",
      "{'hay': 0.9801959983666803, 'bac': 0.9954703121811875, 'han': 0.9988571428571429, 'cor': 0.9991426121749071, 'moz': 0.9930186984567649, 'bee': 0.9863226227901849, 'tel': 0.9964489795918368, 'viv': 0.9958362248438585}\n",
      "{'hay': 24490, 'bac': 24505, 'han': 24500, 'cor': 24493, 'moz': 24494, 'bee': 24493, 'tel': 24500, 'viv': 24497}\n",
      "Total errors : 1340\n"
     ]
    }
   ],
   "source": [
    "errors_per_author = {}\n",
    "accuracy_per_author = {}\n",
    "notes_per_author = {}\n",
    "for ca in considered_authors:\n",
    "    # ca_inputs = torch.cat([all_inputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_outputs = torch.cat([all_outputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_targets = torch.cat([all_targets[i] for i,a in enumerate(authors) if a == ca])\n",
    "    # print(ca_inputs.shape,ca_outputs.shape,ca_targets.shape,ca_predicted_pitches.shape)\n",
    "    ca_acc = accuracy_score(ca_outputs,ca_targets)\n",
    "    accuracy_per_author[ca] = float(ca_acc)\n",
    "    errors_per_author[ca] = int(len(ca_targets) - sum(torch.eq(ca_outputs,ca_targets)))\n",
    "    notes_per_author[ca] = len(ca_targets)\n",
    "\n",
    "print(errors_per_author)\n",
    "print(accuracy_per_author)\n",
    "print(notes_per_author)\n",
    "print(\"Total errors :\", sum([e for e in errors_per_author.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5s0d56evrje"
   },
   "source": [
    "### Best accuracy for now\n",
    "for now best accuracy is with  no CRF (but considering durations) n_epochs = 20\n",
    "n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 0.05\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 8\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "duration_delimiter = automatic calculated\n",
    "\n",
    "Model available in: \"model_RNNTagger9736.pkl\"\n",
    "\n",
    "Epoch 16: train loss = 0.2798, train_accuracy: 0.9245,val_accuracy: 0.9736, time = 78.1199\n",
    "Trained on all dataset\n",
    "\n",
    "\n",
    "{'moz': 65, 'bac': 40, 'bee': 88, 'cor': 6, 'han': 8, 'viv': 63, 'tel': 21, 'hay': 262}\n",
    "{'moz': 0.9973462888870744, 'bac': 0.9983676800652928, 'bee': 0.9964071367329441, 'cor': 0.9997550320499735, 'han': 0.9996734693877551, 'viv': 0.9974282565212067, 'tel': 0.9991428571428571, 'hay': 0.9893017558187015}\n",
    "{'moz': 24494, 'bac': 24505, 'bee': 24493, 'cor': 24493, 'han': 24500, 'viv': 24497, 'tel': 24500, 'hay': 24490}\n",
    "Total errors : 553\n",
    "\n",
    "This win by far against ps13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVvP1eH8vrl3"
   },
   "source": [
    "### Best accuracy with CRF\n",
    "n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 1\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "model = RNNCRFTagger(len(midi_to_ix)+len(duration_delimiter)+2,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "\n",
    "Model available in: \"\"./models/model_temp_CRFacc9548.pkl\"\"\n",
    "accuracy on validation set 0.9548586557910835\n",
    "Trained on all asap dataset\n",
    "\n",
    "{'viv': 36, 'tel': 41, 'bee': 185, 'bac': 101, 'han': 44, 'cor': 14, 'moz': 131, 'hay': 376}\n",
    "{'viv': 0.9985304322978323, 'tel': 0.9983265306122449, 'bee': 0.9924468215408484, 'bac': 0.9958783921648643, 'han': 0.9982040816326531, 'cor': 0.9994284081166047, 'moz': 0.9946517514493345, 'hay': 0.9846467946100449}\n",
    "{'viv': 24497, 'tel': 24500, 'bee': 24493, 'bac': 24505, 'han': 24500, 'cor': 24493, 'moz': 24494, 'hay': 24490}\n",
    "Total errors : 928\n",
    "\n",
    "Still win against ps13"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOTDh55Hh2OWCo66dGc+SES",
   "include_colab_link": true,
   "name": "rnncrf_pitch_spelling",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
