{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fosfrancesco/pitch-spelling/blob/main/rnncrf_pitch_spelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fifMg_hxNSOg",
    "outputId": "a8b320f9-4231-40d9-8f10-a7b8acd1da37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-crf\n",
      "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hsciybUBNkur"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "import music21 as m21\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn\n",
    "import music21 as m21\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchcrf import CRF\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "# import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Naq6UG5jRbyK"
   },
   "source": [
    "# RNN-CRF for Pitch Spelling\n",
    "\n",
    "Dataset: different authors from ASAP collection\n",
    "Challenges:\n",
    "- extremely long sequences\n",
    "- small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mHJvrZ2Wo_e",
    "outputId": "1319f78b-cfb1-4e2a-937c-c47cf952757c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'C'), (1, 'B#'), (2, 'D--'), (3, 'C#'), (4, 'B##'), (5, 'D-'), (6, 'D'), (7, 'C##'), (8, 'E--'), (9, 'D#'), (10, 'E-'), (11, 'F--'), (12, 'E'), (13, 'D##'), (14, 'F-'), (15, 'F'), (16, 'E#'), (17, 'G--'), (18, 'F#'), (19, 'E##'), (20, 'G-'), (21, 'G'), (22, 'F##'), (23, 'A--'), (24, 'G#'), (25, 'A-'), (26, 'A'), (27, 'G##'), (28, 'B--'), (29, 'A#'), (30, 'B-'), (31, 'C--'), (32, 'B'), (33, 'A##'), (34, 'C-')]\n",
      "['D--', 'B##', 'C##', 'E--', 'F--', 'D##', 'G--', 'E##', 'F##', 'A--', 'G##', 'B--', 'C--', 'A##']\n",
      "[(0, 'P1'), (1, 'd2'), (2, 'A7'), (3, 'm2'), (4, 'A1'), (5, 'M2'), (6, 'd3'), (7, 'AA1'), (8, 'm3'), (9, 'A2'), (10, 'M3'), (11, 'd4'), (12, 'AA2'), (13, 'P4'), (14, 'A3'), (15, 'd5'), (16, 'A4'), (17, 'P5'), (18, 'd6'), (19, 'AA4'), (20, 'm6'), (21, 'A5'), (22, 'M6'), (23, 'd7'), (24, 'AA5'), (25, 'm7'), (26, 'A6'), (27, 'M7'), (28, 'd1'), (29, 'AA6')]\n"
     ]
    }
   ],
   "source": [
    "pitches_dict = {\n",
    "    0 : [\"C\",\"B#\",\"D--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    1 : [\"C#\",\"B##\",\"D-\"], # nn.Linear(input_size+context_size, 2)\n",
    "    2 : [\"D\",\"C##\",\"E--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    3 : [\"D#\",\"E-\",\"F--\"],\n",
    "    4 : [\"E\",\"D##\",\"F-\"],\n",
    "    5 : [\"F\",\"E#\",\"G--\"],\n",
    "    6 : [\"F#\",\"E##\",\"G-\"],\n",
    "    7 : [\"G\",\"F##\",\"A--\"],\n",
    "    8 : [\"G#\",\"A-\"],\n",
    "    9 : [\"A\",\"G##\",\"B--\"],\n",
    "    10 : [\"A#\",\"B-\",\"C--\"],\n",
    "    11 : [\"B\",\"A##\",\"C-\"]\n",
    "}\n",
    "\n",
    "accepted_pitches = [ii for i in pitches_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_pitches)])\n",
    "\n",
    "double_acc_pitches = [ii for i in pitches_dict.values() for ii in i if ii.endswith(\"##\") or  ii.endswith(\"--\") ]\n",
    "print(double_acc_pitches)\n",
    "\n",
    "def score2midi_numbers(score):\n",
    "    return [p.midi%12 for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "def score2pitches(score):\n",
    "    return [p.name for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "interval_dict = {\n",
    "    0 : [\"P1\",\"d2\",\"A7\"], \n",
    "    1 : [\"m2\",\"A1\"], \n",
    "    2 : [\"M2\",\"d3\",\"AA1\"], \n",
    "    3 : [\"m3\",\"A2\"],\n",
    "    4 : [\"M3\",\"d4\",\"AA2\"],\n",
    "    5 : [\"P4\",\"A3\"],\n",
    "    6 : [\"d5\",\"A4\"],\n",
    "    7 : [\"P5\",\"d6\",\"AA4\"],\n",
    "    8 : [\"m6\",\"A5\"],\n",
    "    9 : [\"M6\",\"d7\",\"AA5\"],\n",
    "    10 : [\"m7\",\"A6\"],\n",
    "    11 : [\"M7\",\"d1\",\"AA6\"]\n",
    "}\n",
    "\n",
    "accepted_intervals = [ii for i in interval_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_intervals)])\n",
    "\n",
    "def transp_score(score):\n",
    "    \"\"\" For each input return len(accepted_intervals) transposed scores\"\"\"\n",
    "    return [score.transpose(interval) for interval in accepted_intervals]\n",
    "\n",
    "def smart_transp_score(score):\n",
    "    \"\"\" For each chromatic interval chose the interval that lead to the smallest number of accidentals\"\"\"\n",
    "    scores = []\n",
    "    for chromatic_int in interval_dict.keys():\n",
    "        temp_scores = []\n",
    "        temp_acc_number = []\n",
    "        for diat_interval in interval_dict[chromatic_int]:\n",
    "            new_score = score.transpose(diat_interval)\n",
    "            temp_scores.append(new_score)\n",
    "            temp_acc_number.append(sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in score2pitches(new_score)]))\n",
    "            # print(\"choice:\", [note.name for note in temp_scores[-1].flat.notes][0:10],\"acc:\",temp_acc_number[-1] )\n",
    "        #keep only the one with the lowest number of accidentals\n",
    "        min_index = np.argmin(temp_acc_number)\n",
    "        # print(\"preferred the number\", min_index)\n",
    "        scores.append(temp_scores[min_index])\n",
    "    return scores\n",
    "\n",
    "def acc_simple_enough(score,accepted_ratio = 0.2 ):\n",
    "    pitches = score2pitches(score)\n",
    "    double_acc = sum(el in double_acc_pitches for el in pitches)\n",
    "    if double_acc/len(pitches) < accepted_ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "diatonic_pitches = [\"C\",\"D\", \"E\", \"F\", \"G\", \"A\", \"B\"]\n",
    "\n",
    "# #test acc_simple_enough()\n",
    "# score = m21.converter.parse(paths[356])\n",
    "# scores = smart_transp_score(score)\n",
    "# #delete the pieces with non accepted pitches (e.g. triple sharps)\n",
    "# scores = [s for s in scores if all(pitch in accepted_pitches for pitch in score2pitches(s))]\n",
    "# for s in scores:\n",
    "#     print(s.parts[0].flat.getElementsByClass(m21.key.KeySignature)[0], \"simple enough:\", acc_simple_enough(s))\n",
    "#     print([n.name for n in s.flat.notes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw-SuL4ZB_2C"
   },
   "source": [
    "## Import ASAP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrZ0BwLEj2Gp",
    "outputId": "6b521f78-28db-4d4f-f4ef-9345c5d91db9"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/fosfrancesco/pitch-spelling.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "WaINjDS2kpxE"
   },
   "outputs": [],
   "source": [
    "basepath = \"./\" #to change if running locally or on colab\n",
    "\n",
    "# load the asap datasets\n",
    "with open(Path(basepath,'datasets','baroque_asap.pkl'), 'rb') as fid:\n",
    "     dataset_baroque = pickle.load( fid)\n",
    "\n",
    "with open(Path(basepath,'datasets','classical_asap.pkl'), 'rb') as fid:\n",
    "     dataset_classical = pickle.load( fid)\n",
    "\n",
    "with open(Path(basepath,'datasets','romantic_asap.pkl'), 'rb') as fid:\n",
    "     dataset_romantic = pickle.load( fid)\n",
    "\n",
    "# merge the three files together\n",
    "full_dict_dataset = dataset_baroque + dataset_classical + dataset_romantic\n",
    "# full_dict_dataset = dataset_baroque + dataset_classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYQdkJAiTS6_",
    "outputId": "72835948-2884-40bb-e5b4-6ebbc8488895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 different pieces\n",
      "Average number of notes:  2219.6285387474977\n"
     ]
    }
   ],
   "source": [
    "paths = list(set([e[\"original_path\"] for e in full_dict_dataset ]))\n",
    "\n",
    "# print(paths)\n",
    "print(len(paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_dict_dataset ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMdKkzNnCTrK"
   },
   "source": [
    "## Chose the convenient data augmentation\n",
    "Two possibilities:\n",
    "- for each chromatic interval, take only the diatonic transposition that produce the smallest number of accidentals (or the original if present)\n",
    "- take only a certain interval of time signatures\n",
    "\n",
    "The second is probably better for a smaller and simple dataset, but gives the problem of chosing between for example F# and G# that are both present in this bigger dataset. So we go for the first criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oign7EZ9BSX4",
    "outputId": "9aa3f694-289a-43fd-fd14-9cad3b8dd3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No options for Chopin/Ballades/4/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  11\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  1\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  4\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  6\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  9\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml . Chromatic:  1\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  1\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  3\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  8\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  10\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  9\n",
      "Beethoven/Piano_Sonatas/14-3/xml_score.musicxml P1 4\n",
      "['C#', 'G#', 'C#', 'G#', 'E', 'G#', 'C#', 'C#', 'E', 'G#']\n",
      "[1, 8, 1, 8, 4, 8, 1, 1, 4, 8]\n",
      "Beethoven/Piano_Sonatas/14-3/xml_score.musicxml m2 -1\n",
      "['D', 'A', 'D', 'A', 'F', 'A', 'D', 'D', 'F', 'A']\n",
      "[2, 9, 2, 9, 5, 9, 2, 2, 5, 9]\n",
      "Beethoven/Piano_Sonatas/14-3/xml_score.musicxml d3 -6\n",
      "['E-', 'B-', 'E-', 'B-', 'G-', 'B-', 'E-', 'E-', 'G-', 'B-']\n",
      "[3, 10, 3, 10, 6, 10, 3, 3, 6, 10]\n",
      "Beethoven/Piano_Sonatas/14-3/xml_score.musicxml m3 1\n",
      "['E', 'B', 'E', 'B', 'G', 'B', 'E', 'E', 'G', 'B']\n",
      "[4, 11, 4, 11, 7, 11, 4, 4, 7, 11]\n",
      "Beethoven/Piano_Sonatas/14-3/xml_score.musicxml d4 -4\n",
      "['F', 'C', 'F', 'C', 'A-', 'C', 'F', 'F', 'A-', 'C']\n",
      "[5, 0, 5, 0, 8, 0, 5, 5, 8, 0]\n",
      "Beethoven/Piano_Sonatas/14-3/xml_score.musicxml P4 3\n",
      "['F#', 'C#', 'F#', 'C#', 'A', 'C#', 'F#', 'F#', 'A', 'C#']\n",
      "[6, 1, 6, 1, 9, 1, 6, 6, 9, 1]\n",
      "Beethoven/Piano_Sonatas/14-3/xml_score.musicxml d5 -2\n",
      "['G', 'D', 'G', 'D', 'B-', 'D', 'G', 'G', 'B-', 'D']\n",
      "[7, 2, 7, 2, 10, 2, 7, 7, 10, 2]\n",
      "Beethoven/Piano_Sonatas/14-3/xml_score.musicxml d6 -7\n",
      "['A-', 'E-', 'A-', 'E-', 'C-', 'E-', 'A-', 'A-', 'C-', 'E-']\n",
      "[8, 3, 8, 3, 11, 3, 8, 8, 11, 3]\n",
      "Beethoven/Piano_Sonatas/14-3/xml_score.musicxml m6 0\n",
      "['A', 'E', 'A', 'E', 'C', 'E', 'A', 'A', 'C', 'E']\n",
      "[9, 4, 9, 4, 0, 4, 9, 9, 0, 4]\n",
      "Beethoven/Piano_Sonatas/14-3/xml_score.musicxml d7 -5\n",
      "['B-', 'F', 'B-', 'F', 'D-', 'F', 'B-', 'B-', 'D-', 'F']\n",
      "[10, 5, 10, 5, 1, 5, 10, 10, 1, 5]\n",
      "Beethoven/Piano_Sonatas/14-3/xml_score.musicxml m7 2\n",
      "['B', 'F#', 'B', 'F#', 'D', 'F#', 'B', 'B', 'D', 'F#']\n",
      "[11, 6, 11, 6, 2, 6, 11, 11, 2, 6]\n",
      "Beethoven/Piano_Sonatas/14-3/xml_score.musicxml d1 -3\n",
      "['C', 'G', 'C', 'G', 'E-', 'G', 'C', 'C', 'E-', 'G']\n",
      "[0, 7, 0, 7, 3, 7, 0, 0, 3, 7]\n",
      "Beethoven/Piano_Sonatas/21-3/xml_score.musicxml P1 0\n",
      "['C', 'E', 'G', 'C', 'E', 'G', 'E', 'G', 'C', 'E']\n",
      "[0, 4, 7, 0, 4, 7, 4, 7, 0, 4]\n",
      "Beethoven/Piano_Sonatas/21-3/xml_score.musicxml m2 -5\n",
      "['D-', 'F', 'A-', 'D-', 'F', 'A-', 'F', 'A-', 'D-', 'F']\n",
      "[1, 5, 8, 1, 5, 8, 5, 8, 1, 5]\n",
      "Beethoven/Piano_Sonatas/21-3/xml_score.musicxml M2 2\n",
      "['D', 'F#', 'A', 'D', 'F#', 'A', 'F#', 'A', 'D', 'F#']\n",
      "[2, 6, 9, 2, 6, 9, 6, 9, 2, 6]\n",
      "Beethoven/Piano_Sonatas/21-3/xml_score.musicxml m3 -3\n",
      "['E-', 'G', 'B-', 'E-', 'G', 'B-', 'G', 'B-', 'E-', 'G']\n",
      "[3, 7, 10, 3, 7, 10, 7, 10, 3, 7]\n",
      "Beethoven/Piano_Sonatas/21-3/xml_score.musicxml M3 4\n",
      "['E', 'G#', 'B', 'E', 'G#', 'B', 'G#', 'B', 'E', 'G#']\n",
      "[4, 8, 11, 4, 8, 11, 8, 11, 4, 8]\n",
      "Beethoven/Piano_Sonatas/21-3/xml_score.musicxml P4 -1\n",
      "['F', 'A', 'C', 'F', 'A', 'C', 'A', 'C', 'F', 'A']\n",
      "[5, 9, 0, 5, 9, 0, 9, 0, 5, 9]\n",
      "Beethoven/Piano_Sonatas/21-3/xml_score.musicxml A4 6\n",
      "['F#', 'A#', 'C#', 'F#', 'A#', 'C#', 'A#', 'C#', 'F#', 'A#']\n",
      "[6, 10, 1, 6, 10, 1, 10, 1, 6, 10]\n",
      "Beethoven/Piano_Sonatas/21-3/xml_score.musicxml P5 1\n",
      "['G', 'B', 'D', 'G', 'B', 'D', 'B', 'D', 'G', 'B']\n",
      "[7, 11, 2, 7, 11, 2, 11, 2, 7, 11]\n",
      "Beethoven/Piano_Sonatas/21-3/xml_score.musicxml m6 -4\n",
      "['A-', 'C', 'E-', 'A-', 'C', 'E-', 'C', 'E-', 'A-', 'C']\n",
      "[8, 0, 3, 8, 0, 3, 0, 3, 8, 0]\n",
      "Beethoven/Piano_Sonatas/21-3/xml_score.musicxml M6 3\n",
      "['A', 'C#', 'E', 'A', 'C#', 'E', 'C#', 'E', 'A', 'C#']\n",
      "[9, 1, 4, 9, 1, 4, 1, 4, 9, 1]\n",
      "Beethoven/Piano_Sonatas/21-3/xml_score.musicxml m7 -2\n",
      "['B-', 'D', 'F', 'B-', 'D', 'F', 'D', 'F', 'B-', 'D']\n",
      "[10, 2, 5, 10, 2, 5, 2, 5, 10, 2]\n",
      "Beethoven/Piano_Sonatas/21-3/xml_score.musicxml M7 5\n",
      "['B', 'D#', 'F#', 'B', 'D#', 'F#', 'D#', 'F#', 'B', 'D#']\n",
      "[11, 3, 6, 11, 3, 6, 3, 6, 11, 3]\n",
      "Beethoven/Piano_Sonatas/28-2/xml_score.musicxml P1 -1\n",
      "['A', 'C', 'F', 'A', 'F', 'F', 'A', 'C', 'F', 'A']\n",
      "[9, 0, 5, 9, 5, 5, 9, 0, 5, 9]\n",
      "Beethoven/Piano_Sonatas/28-2/xml_score.musicxml A1 6\n",
      "['A#', 'C#', 'F#', 'A#', 'F#', 'F#', 'A#', 'C#', 'F#', 'A#']\n",
      "[10, 1, 6, 10, 6, 6, 10, 1, 6, 10]\n",
      "Beethoven/Piano_Sonatas/28-2/xml_score.musicxml M2 1\n",
      "['B', 'D', 'G', 'B', 'G', 'G', 'B', 'D', 'G', 'B']\n",
      "[11, 2, 7, 11, 7, 7, 11, 2, 7, 11]\n",
      "Beethoven/Piano_Sonatas/28-2/xml_score.musicxml m3 -4\n",
      "['C', 'E-', 'A-', 'C', 'A-', 'A-', 'C', 'E-', 'A-', 'C']\n",
      "[0, 3, 8, 0, 8, 8, 0, 3, 8, 0]\n",
      "Beethoven/Piano_Sonatas/28-2/xml_score.musicxml M3 3\n",
      "['C#', 'E', 'A', 'C#', 'A', 'A', 'C#', 'E', 'A', 'C#']\n",
      "[1, 4, 9, 1, 9, 9, 1, 4, 9, 1]\n",
      "Beethoven/Piano_Sonatas/28-2/xml_score.musicxml P4 -2\n",
      "['D', 'F', 'B-', 'D', 'B-', 'B-', 'D', 'F', 'B-', 'D']\n",
      "[2, 5, 10, 2, 10, 10, 2, 5, 10, 2]\n",
      "Beethoven/Piano_Sonatas/28-2/xml_score.musicxml A4 5\n",
      "['D#', 'F#', 'B', 'D#', 'B', 'B', 'D#', 'F#', 'B', 'D#']\n",
      "[3, 6, 11, 3, 11, 11, 3, 6, 11, 3]\n",
      "Beethoven/Piano_Sonatas/28-2/xml_score.musicxml P5 0\n",
      "['E', 'G', 'C', 'E', 'C', 'C', 'E', 'G', 'C', 'E']\n",
      "[4, 7, 0, 4, 0, 0, 4, 7, 0, 4]\n",
      "Beethoven/Piano_Sonatas/28-2/xml_score.musicxml m6 -5\n",
      "['F', 'A-', 'D-', 'F', 'D-', 'D-', 'F', 'A-', 'D-', 'F']\n",
      "[5, 8, 1, 5, 1, 1, 5, 8, 1, 5]\n",
      "Beethoven/Piano_Sonatas/28-2/xml_score.musicxml M6 2\n",
      "['F#', 'A', 'D', 'F#', 'D', 'D', 'F#', 'A', 'D', 'F#']\n",
      "[6, 9, 2, 6, 2, 2, 6, 9, 2, 6]\n",
      "Beethoven/Piano_Sonatas/28-2/xml_score.musicxml m7 -3\n",
      "['G', 'B-', 'E-', 'G', 'E-', 'E-', 'G', 'B-', 'E-', 'G']\n",
      "[7, 10, 3, 7, 3, 3, 7, 10, 3, 7]\n",
      "Beethoven/Piano_Sonatas/28-2/xml_score.musicxml M7 4\n",
      "['G#', 'B', 'E', 'G#', 'E', 'E', 'G#', 'B', 'E', 'G#']\n",
      "[8, 11, 4, 8, 4, 4, 8, 11, 4, 8]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml P1 -3\n",
      "['E-', 'C', 'G', 'G', 'E-', 'C', 'E-', 'C', 'G', 'G']\n",
      "[3, 0, 7, 7, 3, 0, 3, 0, 7, 7]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml A1 4\n",
      "['E', 'C#', 'G#', 'G#', 'E', 'C#', 'E', 'C#', 'G#', 'G#']\n",
      "[4, 1, 8, 8, 4, 1, 4, 1, 8, 8]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml M2 -1\n",
      "['F', 'D', 'A', 'A', 'F', 'D', 'F', 'D', 'A', 'A']\n",
      "[5, 2, 9, 9, 5, 2, 5, 2, 9, 9]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml m3 -6\n",
      "['G-', 'E-', 'B-', 'B-', 'G-', 'E-', 'G-', 'E-', 'B-', 'B-']\n",
      "[6, 3, 10, 10, 6, 3, 6, 3, 10, 10]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml M3 1\n",
      "['G', 'E', 'B', 'B', 'G', 'E', 'G', 'E', 'B', 'B']\n",
      "[7, 4, 11, 11, 7, 4, 7, 4, 11, 11]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml P4 -4\n",
      "['A-', 'F', 'C', 'C', 'A-', 'F', 'A-', 'F', 'C', 'C']\n",
      "[8, 5, 0, 0, 8, 5, 8, 5, 0, 0]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml A4 3\n",
      "['A', 'F#', 'C#', 'C#', 'A', 'F#', 'A', 'F#', 'C#', 'C#']\n",
      "[9, 6, 1, 1, 9, 6, 9, 6, 1, 1]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml P5 -2\n",
      "['B-', 'G', 'D', 'D', 'B-', 'G', 'B-', 'G', 'D', 'D']\n",
      "[10, 7, 2, 2, 10, 7, 10, 7, 2, 2]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml A5 5\n",
      "['B', 'G#', 'D#', 'D#', 'B', 'G#', 'B', 'G#', 'D#', 'D#']\n",
      "[11, 8, 3, 3, 11, 8, 11, 8, 3, 3]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml M6 0\n",
      "['C', 'A', 'E', 'E', 'C', 'A', 'C', 'A', 'E', 'E']\n",
      "[0, 9, 4, 4, 0, 9, 0, 9, 4, 4]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml m7 -5\n",
      "['D-', 'B-', 'F', 'F', 'D-', 'B-', 'D-', 'B-', 'F', 'F']\n",
      "[1, 10, 5, 5, 1, 10, 1, 10, 5, 5]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml M7 2\n",
      "['D', 'B', 'F#', 'F#', 'D', 'B', 'D', 'B', 'F#', 'F#']\n",
      "[2, 11, 6, 6, 2, 11, 2, 11, 6, 6]\n",
      "Beethoven/Piano_Sonatas/24-1_no_2_repeat/xml_score.musicxml P1 6\n",
      "['A#', 'C#', 'F#', 'F#', 'A#', 'C#', 'F#', 'B', 'E#', 'G#']\n",
      "[10, 1, 6, 6, 10, 1, 6, 11, 5, 8]\n",
      "Beethoven/Piano_Sonatas/24-1_no_2_repeat/xml_score.musicxml m2 1\n",
      "['B', 'D', 'G', 'G', 'B', 'D', 'G', 'C', 'F#', 'A']\n",
      "[11, 2, 7, 7, 11, 2, 7, 0, 6, 9]\n",
      "Beethoven/Piano_Sonatas/24-1_no_2_repeat/xml_score.musicxml d3 -4\n",
      "['C', 'E-', 'A-', 'A-', 'C', 'E-', 'A-', 'D-', 'G', 'B-']\n",
      "[0, 3, 8, 8, 0, 3, 8, 1, 7, 10]\n",
      "Beethoven/Piano_Sonatas/24-1_no_2_repeat/xml_score.musicxml m3 3\n",
      "['C#', 'E', 'A', 'A', 'C#', 'E', 'A', 'D', 'G#', 'B']\n",
      "[1, 4, 9, 9, 1, 4, 9, 2, 8, 11]\n",
      "Beethoven/Piano_Sonatas/24-1_no_2_repeat/xml_score.musicxml d4 -2\n",
      "['D', 'F', 'B-', 'B-', 'D', 'F', 'B-', 'E-', 'A', 'C']\n",
      "[2, 5, 10, 10, 2, 5, 10, 3, 9, 0]\n",
      "Beethoven/Piano_Sonatas/24-1_no_2_repeat/xml_score.musicxml P4 5\n",
      "['D#', 'F#', 'B', 'B', 'D#', 'F#', 'B', 'E', 'A#', 'C#']\n",
      "[3, 6, 11, 11, 3, 6, 11, 4, 10, 1]\n",
      "Beethoven/Piano_Sonatas/24-1_no_2_repeat/xml_score.musicxml d5 0\n",
      "['E', 'G', 'C', 'C', 'E', 'G', 'C', 'F', 'B', 'D']\n",
      "[4, 7, 0, 0, 4, 7, 0, 5, 11, 2]\n",
      "Beethoven/Piano_Sonatas/24-1_no_2_repeat/xml_score.musicxml d6 -5\n",
      "['F', 'A-', 'D-', 'D-', 'F', 'A-', 'D-', 'G-', 'C', 'E-']\n",
      "[5, 8, 1, 1, 5, 8, 1, 6, 0, 3]\n",
      "Beethoven/Piano_Sonatas/24-1_no_2_repeat/xml_score.musicxml m6 2\n",
      "['F#', 'A', 'D', 'D', 'F#', 'A', 'D', 'G', 'C#', 'E']\n",
      "[6, 9, 2, 2, 6, 9, 2, 7, 1, 4]\n",
      "Beethoven/Piano_Sonatas/24-1_no_2_repeat/xml_score.musicxml d7 -3\n",
      "['G', 'B-', 'E-', 'E-', 'G', 'B-', 'E-', 'A-', 'D', 'F']\n",
      "[7, 10, 3, 3, 7, 10, 3, 8, 2, 5]\n",
      "Beethoven/Piano_Sonatas/24-1_no_2_repeat/xml_score.musicxml m7 4\n",
      "['G#', 'B', 'E', 'E', 'G#', 'B', 'E', 'A', 'D#', 'F#']\n",
      "[8, 11, 4, 4, 8, 11, 4, 9, 3, 6]\n",
      "Beethoven/Piano_Sonatas/24-1_no_2_repeat/xml_score.musicxml d1 -1\n",
      "['A', 'C', 'F', 'F', 'A', 'C', 'F', 'B-', 'E', 'G']\n",
      "[9, 0, 5, 5, 9, 0, 5, 10, 4, 7]\n",
      "Bach/Fugue/bwv_873/xml_score.musicxml P1 4\n",
      "['C#', 'B#', 'C#', 'D#', 'C#', 'D#', 'G#', 'A#', 'B#', 'C#']\n",
      "[1, 0, 1, 3, 1, 3, 8, 10, 0, 1]\n",
      "Bach/Fugue/bwv_873/xml_score.musicxml m2 -1\n",
      "['D', 'C#', 'D', 'E', 'D', 'E', 'A', 'B', 'C#', 'D']\n",
      "[2, 1, 2, 4, 2, 4, 9, 11, 1, 2]\n",
      "Bach/Fugue/bwv_873/xml_score.musicxml d3 -6\n",
      "['E-', 'D', 'E-', 'F', 'E-', 'F', 'B-', 'C', 'D', 'E-']\n",
      "[3, 2, 3, 5, 3, 5, 10, 0, 2, 3]\n",
      "Bach/Fugue/bwv_873/xml_score.musicxml m3 1\n",
      "['E', 'D#', 'E', 'F#', 'E', 'F#', 'B', 'C#', 'D#', 'E']\n",
      "[4, 3, 4, 6, 4, 6, 11, 1, 3, 4]\n",
      "Bach/Fugue/bwv_873/xml_score.musicxml d4 -4\n",
      "['F', 'E', 'F', 'G', 'F', 'G', 'C', 'D', 'E', 'F']\n",
      "[5, 4, 5, 7, 5, 7, 0, 2, 4, 5]\n",
      "Bach/Fugue/bwv_873/xml_score.musicxml P4 3\n",
      "['F#', 'E#', 'F#', 'G#', 'F#', 'G#', 'C#', 'D#', 'E#', 'F#']\n",
      "[6, 5, 6, 8, 6, 8, 1, 3, 5, 6]\n",
      "Bach/Fugue/bwv_873/xml_score.musicxml d5 -2\n",
      "['G', 'F#', 'G', 'A', 'G', 'A', 'D', 'E', 'F#', 'G']\n",
      "[7, 6, 7, 9, 7, 9, 2, 4, 6, 7]\n",
      "Bach/Fugue/bwv_873/xml_score.musicxml P5 5\n",
      "['G#', 'F##', 'G#', 'A#', 'G#', 'A#', 'D#', 'E#', 'F##', 'G#']\n",
      "[8, 7, 8, 10, 8, 10, 3, 5, 7, 8]\n",
      "Bach/Fugue/bwv_873/xml_score.musicxml m6 0\n",
      "['A', 'G#', 'A', 'B', 'A', 'B', 'E', 'F#', 'G#', 'A']\n",
      "[9, 8, 9, 11, 9, 11, 4, 6, 8, 9]\n",
      "Bach/Fugue/bwv_873/xml_score.musicxml d7 -5\n",
      "['B-', 'A', 'B-', 'C', 'B-', 'C', 'F', 'G', 'A', 'B-']\n",
      "[10, 9, 10, 0, 10, 0, 5, 7, 9, 10]\n",
      "Bach/Fugue/bwv_873/xml_score.musicxml m7 2\n",
      "['B', 'A#', 'B', 'C#', 'B', 'C#', 'F#', 'G#', 'A#', 'B']\n",
      "[11, 10, 11, 1, 11, 1, 6, 8, 10, 11]\n",
      "Bach/Fugue/bwv_873/xml_score.musicxml d1 -3\n",
      "['C', 'B', 'C', 'D', 'C', 'D', 'G', 'A', 'B', 'C']\n",
      "[0, 11, 0, 2, 0, 2, 7, 9, 11, 0]\n",
      "Bach/Prelude/bwv_875/xml_score.musicxml P1 -1\n",
      "['D', 'D', 'C', 'B-', 'A', 'D', 'G', 'F', 'E', 'D']\n",
      "[2, 2, 0, 10, 9, 2, 7, 5, 4, 2]\n",
      "Bach/Prelude/bwv_875/xml_score.musicxml m2 -6\n",
      "['E-', 'E-', 'D-', 'C-', 'B-', 'E-', 'A-', 'G-', 'F', 'E-']\n",
      "[3, 3, 1, 11, 10, 3, 8, 6, 5, 3]\n",
      "Bach/Prelude/bwv_875/xml_score.musicxml M2 1\n",
      "['E', 'E', 'D', 'C', 'B', 'E', 'A', 'G', 'F#', 'E']\n",
      "[4, 4, 2, 0, 11, 4, 9, 7, 6, 4]\n",
      "Bach/Prelude/bwv_875/xml_score.musicxml m3 -4\n",
      "['F', 'F', 'E-', 'D-', 'C', 'F', 'B-', 'A-', 'G', 'F']\n",
      "[5, 5, 3, 1, 0, 5, 10, 8, 7, 5]\n",
      "Bach/Prelude/bwv_875/xml_score.musicxml M3 3\n",
      "['F#', 'F#', 'E', 'D', 'C#', 'F#', 'B', 'A', 'G#', 'F#']\n",
      "[6, 6, 4, 2, 1, 6, 11, 9, 8, 6]\n",
      "Bach/Prelude/bwv_875/xml_score.musicxml P4 -2\n",
      "['G', 'G', 'F', 'E-', 'D', 'G', 'C', 'B-', 'A', 'G']\n",
      "[7, 7, 5, 3, 2, 7, 0, 10, 9, 7]\n",
      "Bach/Prelude/bwv_875/xml_score.musicxml A4 5\n",
      "['G#', 'G#', 'F#', 'E', 'D#', 'G#', 'C#', 'B', 'A#', 'G#']\n",
      "[8, 8, 6, 4, 3, 8, 1, 11, 10, 8]\n",
      "Bach/Prelude/bwv_875/xml_score.musicxml P5 0\n",
      "['A', 'A', 'G', 'F', 'E', 'A', 'D', 'C', 'B', 'A']\n",
      "[9, 9, 7, 5, 4, 9, 2, 0, 11, 9]\n",
      "Bach/Prelude/bwv_875/xml_score.musicxml m6 -5\n",
      "['B-', 'B-', 'A-', 'G-', 'F', 'B-', 'E-', 'D-', 'C', 'B-']\n",
      "[10, 10, 8, 6, 5, 10, 3, 1, 0, 10]\n",
      "Bach/Prelude/bwv_875/xml_score.musicxml M6 2\n",
      "['B', 'B', 'A', 'G', 'F#', 'B', 'E', 'D', 'C#', 'B']\n",
      "[11, 11, 9, 7, 6, 11, 4, 2, 1, 11]\n",
      "Bach/Prelude/bwv_875/xml_score.musicxml m7 -3\n",
      "['C', 'C', 'B-', 'A-', 'G', 'C', 'F', 'E-', 'D', 'C']\n",
      "[0, 0, 10, 8, 7, 0, 5, 3, 2, 0]\n",
      "Bach/Prelude/bwv_875/xml_score.musicxml M7 4\n",
      "['C#', 'C#', 'B', 'A', 'G#', 'C#', 'F#', 'E', 'D#', 'C#']\n",
      "[1, 1, 11, 9, 8, 1, 6, 4, 3, 1]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml P1 -3\n",
      "['E-', 'G', 'B-', 'E-', 'G', 'B-', 'E-', 'G', 'B-', 'E-']\n",
      "[3, 7, 10, 3, 7, 10, 3, 7, 10, 3]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml A1 4\n",
      "['E', 'G#', 'B', 'E', 'G#', 'B', 'E', 'G#', 'B', 'E']\n",
      "[4, 8, 11, 4, 8, 11, 4, 8, 11, 4]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml M2 -1\n",
      "['F', 'A', 'C', 'F', 'A', 'C', 'F', 'A', 'C', 'F']\n",
      "[5, 9, 0, 5, 9, 0, 5, 9, 0, 5]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml m3 -6\n",
      "['G-', 'B-', 'D-', 'G-', 'B-', 'D-', 'G-', 'B-', 'D-', 'G-']\n",
      "[6, 10, 1, 6, 10, 1, 6, 10, 1, 6]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml M3 1\n",
      "['G', 'B', 'D', 'G', 'B', 'D', 'G', 'B', 'D', 'G']\n",
      "[7, 11, 2, 7, 11, 2, 7, 11, 2, 7]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml P4 -4\n",
      "['A-', 'C', 'E-', 'A-', 'C', 'E-', 'A-', 'C', 'E-', 'A-']\n",
      "[8, 0, 3, 8, 0, 3, 8, 0, 3, 8]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml A4 3\n",
      "['A', 'C#', 'E', 'A', 'C#', 'E', 'A', 'C#', 'E', 'A']\n",
      "[9, 1, 4, 9, 1, 4, 9, 1, 4, 9]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml P5 -2\n",
      "['B-', 'D', 'F', 'B-', 'D', 'F', 'B-', 'D', 'F', 'B-']\n",
      "[10, 2, 5, 10, 2, 5, 10, 2, 5, 10]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml A5 5\n",
      "['B', 'D#', 'F#', 'B', 'D#', 'F#', 'B', 'D#', 'F#', 'B']\n",
      "[11, 3, 6, 11, 3, 6, 11, 3, 6, 11]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml M6 0\n",
      "['C', 'E', 'G', 'C', 'E', 'G', 'C', 'E', 'G', 'C']\n",
      "[0, 4, 7, 0, 4, 7, 0, 4, 7, 0]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml m7 -5\n",
      "['D-', 'F', 'A-', 'D-', 'F', 'A-', 'D-', 'F', 'A-', 'D-']\n",
      "[1, 5, 8, 1, 5, 8, 1, 5, 8, 1]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml M7 2\n",
      "['D', 'F#', 'A', 'D', 'F#', 'A', 'D', 'F#', 'A', 'D']\n",
      "[2, 6, 9, 2, 6, 9, 2, 6, 9, 2]\n",
      "Beethoven/Piano_Sonatas/7-2/xml_score.musicxml P1 -1\n",
      "['D', 'F', 'A', 'D', 'F', 'A', 'D', 'C#', 'D', 'F']\n",
      "[2, 5, 9, 2, 5, 9, 2, 1, 2, 5]\n",
      "Beethoven/Piano_Sonatas/7-2/xml_score.musicxml m2 -6\n",
      "['E-', 'G-', 'B-', 'E-', 'G-', 'B-', 'E-', 'D', 'E-', 'G-']\n",
      "[3, 6, 10, 3, 6, 10, 3, 2, 3, 6]\n",
      "Beethoven/Piano_Sonatas/7-2/xml_score.musicxml M2 1\n",
      "['E', 'G', 'B', 'E', 'G', 'B', 'E', 'D#', 'E', 'G']\n",
      "[4, 7, 11, 4, 7, 11, 4, 3, 4, 7]\n",
      "Beethoven/Piano_Sonatas/7-2/xml_score.musicxml m3 -4\n",
      "['F', 'A-', 'C', 'F', 'A-', 'C', 'F', 'E', 'F', 'A-']\n",
      "[5, 8, 0, 5, 8, 0, 5, 4, 5, 8]\n",
      "Beethoven/Piano_Sonatas/7-2/xml_score.musicxml M3 3\n",
      "['F#', 'A', 'C#', 'F#', 'A', 'C#', 'F#', 'E#', 'F#', 'A']\n",
      "[6, 9, 1, 6, 9, 1, 6, 5, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "# choose only one enharmonic version for each chromatic interval for each piece\n",
    "dict_dataset = []\n",
    "for path in paths:\n",
    "    for c in range(12):\n",
    "        pieces_to_consider = [opus for opus in full_dict_dataset \n",
    "                              if (opus[\"original_path\"] == path and opus[\"transposed_of\"] in interval_dict[c])  ]\n",
    "        # if the original is in pieces_to_consider, go with the original\n",
    "        originals = [opus for opus in pieces_to_consider if opus[\"transposed_of\"] == \"P1\"]\n",
    "        if len(originals) == 1:\n",
    "            dict_dataset.append(originals[0])\n",
    "        else: #we go with the accidental minization criteria\n",
    "            n_accidentals = [sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in opus[\"pitches\"]]) \n",
    "                            for opus in pieces_to_consider]\n",
    "            if len(pieces_to_consider)>0:\n",
    "                dict_dataset.append(pieces_to_consider[np.argmin(n_accidentals)])\n",
    "            else:\n",
    "                print(\"No options for\", path, \". Chromatic: \",c )\n",
    "\n",
    "# accepted_ks = range(-5,6)\n",
    "# dict_dataset = [e for e in full_dict_dataset if e[\"key_signature\"] in accepted_ks]\n",
    "\n",
    "#test if it worked\n",
    "for i,e in enumerate(dict_dataset):\n",
    "    print(e[\"original_path\"], e[\"transposed_of\"], e[\"key_signature\"])\n",
    "    print(e[\"pitches\"][:10])\n",
    "    print(e[\"midi_number\"][:10])\n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgHkMeoJdb42",
    "outputId": "1f3d172f-3f93-47ce-aa1b-e37a2afba24e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2271\n",
      "Counter({'Bach': 59, 'Beethoven': 57, 'Chopin': 34, 'Schubert': 13, 'Haydn': 11, 'Schumann': 10, 'Mozart': 6, 'Brahms': 1})\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_dataset))\n",
    "\n",
    "c = Counter()\n",
    "for p in paths:\n",
    "    c[p.split(\"/\")[0]] +=1\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GRCM2W3qqeW",
    "outputId": "d53c8146-8b32-43df-cd69-b7423f1ceda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation lenghts:  161 29\n"
     ]
    }
   ],
   "source": [
    "# Ignore Brahms (only one piece)\n",
    "paths = [p for p in paths if p.split(\"/\")[0] !=\"Brahms\"]\n",
    "\n",
    "# Divide train and validation set\n",
    "path_train, path_validation = sklearn.model_selection.train_test_split(paths, test_size=0.15,stratify=[p.split(\"/\")[0] for p in paths ])\n",
    "print(\"Train and validation lenghts: \",len(path_train),len(path_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "KIZ2_bX1bom5",
    "outputId": "ae8d5b50-ed4d-4376-f9d6-e96c6aa73046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Haydn', 'Mozart', 'Bach', 'Chopin', 'Schubert', 'Schumann', 'Beethoven']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 383
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#need to find a better way to visualize this\n",
    "composers = list(set([p.split(\"/\")[0] for p in paths ]))\n",
    "print(composers)\n",
    "\n",
    "train_composer = [composers.index(p.split(\"/\")[0]) for p in path_train]\n",
    "val_composer = [composers.index(p.split(\"/\")[0]) for p in path_validation]\n",
    "\n",
    "_ = plt.hist([train_composer, val_composer], label=['train', 'validation'])\n",
    "_ = plt.legend(loc='upper left')\n",
    "_ = plt.xticks(list(range(7)), composers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-qaT10ApkCY"
   },
   "source": [
    "## Transform the input into a convenient format for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEYec2TDOWvj",
    "outputId": "1b69573b-cfeb-4dc9-8882-da42f9c25537"
   },
   "outputs": [],
   "source": [
    "# Helper functions to feed the correct input into the NN \n",
    "\n",
    "PAD = \"<PAD>\"\n",
    "\n",
    "tag_to_ix = {p: accepted_pitches.index(p) for p in accepted_pitches}\n",
    "#add PADDING TAD\n",
    "tag_to_ix[PAD] = len(accepted_pitches)\n",
    "\n",
    "midi_to_ix = {m: m for m in range(12)}\n",
    "# #add PADDING TAD\n",
    "# midi_to_ix[PAD] = 12\n",
    "\n",
    "# print(midi_to_ix[1])\n",
    "# print(len(midi_to_ix))\n",
    "\n",
    "duration_delimiter = [0.125,0.25,0.5,1,2,4]\n",
    "\n",
    "\n",
    "class Pitch2Diatonic():\n",
    "    def __call__(self, in_seq,weights = None):\n",
    "        return [p for p in in_seq]\n",
    "\n",
    "class Diatonic2Int():\n",
    "    def __call__(self, in_seq,weights = None):\n",
    "        idxs = [tag_to_ix[w] for w in in_seq]\n",
    "        return idxs\n",
    "\n",
    "class Int2Pitch():\n",
    "    def __call__(self, in_seq):\n",
    "        return [accepted_pitches[i] for i in in_seq]\n",
    "\n",
    "class OneHotEncoder():\n",
    "    def __init__(self, alphabet_len):\n",
    "        self.alphabet_len = alphabet_len\n",
    "        \n",
    "    def __call__(self, sample,weights = None):\n",
    "        onehot = np.zeros([len(sample), self.alphabet_len])\n",
    "        tot_chars = len(sample)\n",
    "        onehot[np.arange(tot_chars), sample] = 1\n",
    "        return onehot\n",
    "\n",
    "# class WeightedOneHotEncoder():\n",
    "#     def __init__(self, alphabet_len):\n",
    "#         self.alphabet_len = alphabet_len\n",
    "        \n",
    "#     def __call__(self, sample, weights=None):\n",
    "#         if weights == None:\n",
    "#             weights = np.ones(len(sample))\n",
    "#         onehot = torch.nn.functional.one_hot(sample,self.alphabet_len)\n",
    "#         return (onehot.t()*torch.Tensor(weights)).t() #transpositions to allow the broadcasting\n",
    "    \n",
    "class DurationOneHotEncoder():\n",
    "    def __init__(self, pitch_alphabet_len, duration_delimiter):\n",
    "        self.pitch_alphabet_len = pitch_alphabet_len\n",
    "        self.dur_alphabet_len = len(duration_delimiter)+2\n",
    "        self.duration_delimiter = duration_delimiter\n",
    "        \n",
    "    def __call__(self, sample, durs):\n",
    "        sample = torch.tensor(sample,dtype=torch.long)\n",
    "        onehot_pitch = torch.nn.functional.one_hot(sample,self.pitch_alphabet_len)\n",
    "        quantized_durations = np.digitize(durs,self.duration_delimiter)\n",
    "        quantized_durations = torch.tensor(quantized_durations,dtype=torch.long)\n",
    "        onehot_duration = torch.nn.functional.one_hot(quantized_durations,self.dur_alphabet_len)\n",
    "        return torch.cat([onehot_pitch,onehot_duration],1)\n",
    "        \n",
    "class ToTensorFloat():\n",
    "    def __call__(self, sample, weight = None):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.float()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.float)\n",
    "\n",
    "class ToTensorLong():\n",
    "    def __call__(self, sample, weights = None):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.long()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.long)\n",
    "    \n",
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, sample, weights):\n",
    "        for t in self.transforms:\n",
    "            sample = t(sample, weights)\n",
    "        return sample\n",
    "\n",
    "pitches_len = len(accepted_pitches)\n",
    "midinote_len = 12\n",
    "\n",
    "### Define the preprocessing pipeline\n",
    "transform_diat = Compose([Pitch2Diatonic(),Diatonic2Int(),ToTensorLong()])\n",
    "transform_chrom = Compose([DurationOneHotEncoder(len(midi_to_ix),duration_delimiter),ToTensorFloat()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =[list(range(10)) for e in range(4)]\n",
    "torch.Tensor(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV9boYaToUs2",
    "outputId": "92bcd8d3-87a2-4d2c-8e92-4a106139f59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1915 29\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n",
      "tensor([1, 8, 1, 8, 4, 8, 1, 1, 4, 8, 8, 1, 1, 4, 8, 8, 1, 4, 1, 8, 1, 8, 4, 8,\n",
      "        1, 1, 4, 8, 8, 1])\n",
      "['C#', 'G#', 'C#', 'G#', 'E', 'G#', 'C#', 'C#', 'E', 'G#', 'G#', 'C#', 'C#', 'E', 'G#', 'G#', 'C#', 'E', 'C#', 'G#', 'C#', 'G#', 'E', 'G#', 'C#', 'C#', 'E', 'G#', 'G#', 'C#']\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "\n",
    "class PSDataset(Dataset):\n",
    "    def __init__(self, dict_dataset, paths, transf_c, transf_d, augment_dataset, truncate = None):\n",
    "        if augment_dataset:\n",
    "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset if e[\"original_path\"] in paths]\n",
    "            self.diatonic_sequences = [e[\"pitches\"]\n",
    "                                       for e in dict_dataset \n",
    "                                       if e[\"original_path\"] in paths]\n",
    "            self.durations = [e[\"duration\"] for e in dict_dataset if e[\"original_path\"] in paths]\n",
    "        else: #consider only non transposed pieces\n",
    "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset \n",
    "                                        if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "            self.diatonic_sequences = [e[\"pitches\"]\n",
    "                                       for e in dict_dataset \n",
    "                                       if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "            self.durations = [e[\"duration\"] \n",
    "                              for e in dict_dataset \n",
    "                              if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "        #the transformations to apply to data\n",
    "        self.transf_c = transf_c\n",
    "        self.transf_d = transf_d\n",
    "        self.truncate = truncate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chromatic_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chromatic_seq = self.chromatic_sequences[idx]\n",
    "        diatonic_seq = self.diatonic_sequences[idx]\n",
    "        duration_seq = self.durations[idx]\n",
    "        weights = [dur/4  if dur<=4 else 1 for dur in duration_seq  ] # limit the weights to (0,4)       \n",
    "\n",
    "        #transform\n",
    "        chromatic_seq = self.transf_c(chromatic_seq,weights)\n",
    "        diatonic_seq = self.transf_d(diatonic_seq,None)\n",
    "\n",
    "        if not self.truncate is None:\n",
    "            if len(diatonic_seq) > self.truncate:\n",
    "                chromatic_seq = chromatic_seq[0:self.truncate]\n",
    "                diatonic_seq = diatonic_seq[0:self.truncate]\n",
    "\n",
    "        #sanity check\n",
    "        assert len(chromatic_seq) == len(diatonic_seq)\n",
    "        seq_len = len(diatonic_seq)\n",
    "        \n",
    "        return chromatic_seq, diatonic_seq, seq_len\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\n",
    "\n",
    "print(len(train_dataset),len(validation_dataset))\n",
    "\n",
    "\n",
    "\n",
    "# test if it works\n",
    "for chrom,diat,seq_len in train_dataset:\n",
    "    print(chrom[0:30])\n",
    "    print(torch.argmax(chrom[0:30],1))\n",
    "    # print([diatonic_pitches[p.item()] for p in diat[0:30]])\n",
    "    print([accepted_pitches[p.item()] for p in diat[0:30]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAubyjw2LC8P",
    "outputId": "d6f8574f-8901-41e7-fd7a-9a0c6091eafa"
   },
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (xx, yy, l) = zip(*batch)\n",
    "    \n",
    "    xx_pad = pad_sequence(xx)\n",
    "    yy_pad = pad_sequence(yy, padding_value=tag_to_ix[PAD])\n",
    "\n",
    "    #sort the sequences by length\n",
    "    seq_lengths, perm_idx = torch.Tensor(l).sort(0, descending=True)\n",
    "    xx_pad = xx_pad[:,perm_idx,:]\n",
    "    yy_pad = yy_pad[:,perm_idx]\n",
    "\n",
    "    return xx_pad, yy_pad, seq_lengths\n",
    "\n",
    "# data_loader = DataLoader(dataset=validation_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "\n",
    "\n",
    "# #test if it work\n",
    "# for batch in data_loader:\n",
    "#     print(batch[0].shape,batch[1].shape,batch[2])\n",
    "#     print(batch[1])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O1OA1AjGWO-"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "QEkFBY5cUsmN"
   },
   "outputs": [],
   "source": [
    "class RNNTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='sum',ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "       \n",
    "        # # Find the positions where the token is a dummy padding token.\n",
    "        # pad_mask = (sentences == self.pad_word_id).float()\n",
    "\n",
    "        # # For these positions, we add some large number in the column corresponding\n",
    "        # # to the dummy padding label.\n",
    "        # out[:, :, self.pad_label_id] += pad_mask*10000\n",
    "\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        return [predicted[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "QE7itQ88Qx17"
   },
   "outputs": [],
   "source": [
    "class RNNCRFTagger(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNCRFTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        self.crf = CRF(self.n_labels)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        ## should I initialize here??\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "      \n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # Compute the outputs of the lower layers, which will be used as emission\n",
    "        # scores for the CRF.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # We return the loss value. The CRF returns the log likelihood, but we return \n",
    "        # the *negative* log likelihood as the loss value.            \n",
    "        # PyTorch's optimizers *minimize* the loss, while we want to *maximize* the\n",
    "        # log likelihood.\n",
    "\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return -self.crf(scores, labels, mask = pad_mask )\n",
    "            \n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the emission scores, as above.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Apply the Viterbi algorithm to get the predictions. This implementation returns\n",
    "        # the result as a list of lists (not a tensor), corresponding to a matrix\n",
    "        # of shape (n_sentences, max_len).\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return self.crf.decode(scores,mask = pad_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXixmVQfvw8T"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "3m_nj4HCuCe1"
   },
   "outputs": [],
   "source": [
    "# TODO: search over the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "uAMSIlw0AJb6"
   },
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, train_dataloader, val_dataloader, n_epochs):\n",
    "    history = defaultdict(list)  \n",
    "    for i_epoch in range(1,n_epochs +1):\n",
    "        t0 = time.time()\n",
    "        loss_sum = 0\n",
    "        accuracy_sum = 0\n",
    "        model.train()\n",
    "        for seqs, targets, lens in train_dataloader: #seqs, targets, lens are batches\n",
    "            seqs, targets = seqs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = model(seqs,targets,lens) / sum(lens) #normalize for the number of symbol considered (without padding)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            predicted = model.predict(seqs,lens)\n",
    "            for i,p in enumerate(predicted):\n",
    "                acc= accuracy_score(p,targets[:,i][:len(p)].cpu()) #compute the accuracy without considering the padding\n",
    "                accuracy_sum += acc/len(lens) #normalize according to the number of sequences in the batch\n",
    "\n",
    "        train_loss = loss_sum/len(train_dataloader)\n",
    "        train_accuracy = accuracy_sum/len(train_dataloader) #normalize according to the number of batches\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_accuracy\"].append(train_accuracy)\n",
    "\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        all_predicted = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for seqs,targets, lens in val_dataloader:\n",
    "                # Predict the model's output on a batch\n",
    "                predicted = model.predict(seqs.to(device),lens)                   \n",
    "                # Update the lists that will be used to compute the accuracy\n",
    "                for i,p in enumerate(predicted):\n",
    "                    all_predicted.append(torch.Tensor(p))\n",
    "                    all_targets.append(targets[0:int(lens[i]),i])\n",
    "                \n",
    "        # Compute the overall accuracy for the validation set\n",
    "        val_accuracy = accuracy_score(torch.cat(all_predicted),torch.cat(all_targets))\n",
    "        history[\"val_accuracy\"].append(val_accuracy)\n",
    "\n",
    "#         save the model\n",
    "        torch.save(model, \"./models/temp/model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "#         files.download(\"model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "\n",
    "    \n",
    "        t1 = time.time()\n",
    "        print(f'Epoch {i_epoch}: train loss = {train_loss:.4f}, train_accuracy: {train_accuracy:.4f},val_accuracy: {val_accuracy:.4f}, time = {t1-t0:.4f}')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "2g2st8znpGW_",
    "outputId": "fe232e42-e270-4f5d-9bd8-718bba5e7151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 0.09\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True, truncate = None)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\n",
    "val_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\n",
    "\n",
    "# model = torch.load(\"./models/temp/model_temp_epoch30-to_restart.pkl\")\n",
    "model = RNNCRFTagger(len(midi_to_ix)+len(duration_delimiter)+2,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "# model = RNNTagger(len(midi_to_ix)+len(duration_delimiter)+2,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_WEIGHT, momentum = 0.9,weight_decay=WEIGHT_DECAY)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_WEIGHT, weight_decay=WEIGHT_DECAY)\n",
    "# otimizer = torch.optim.Adam(model.parameters(),lr = 0.05, weight_decay=1e-4)\n",
    "\n",
    "history = training_loop(model,optimizer,train_dataloader,val_dataloader, n_epochs)\n",
    "\n",
    "# After the final evaluation, we print more detailed evaluation statistics,\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.legend(['training loss', 'training accuracy', 'validation_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tTv2BrGbvSHh",
    "outputId": "801ff32d-24dc-4434-a436-17d9ca832214"
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"./models/model_asap_crf200dur.pkl\")\n",
    "# files.download(\"model_asap_crf300.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXcmLpCKt28l"
   },
   "source": [
    "## Test on Mdata dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./models/temp/model_temp_epoch12-noCRFacc9575.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "BacUqgD5usGL"
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "with open(Path(basepath,'./datasets/musedata.pkl'), 'rb') as fid:\n",
    "     full_mdata_dict_dataset = pickle.load( fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgaUwW2fuwg0",
    "outputId": "89fc5f7d-884a-4ee6-fc34-b3d512f0c4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 different pieces\n",
      "Average number of notes:  858.6319771007974\n"
     ]
    }
   ],
   "source": [
    "mdata_paths = list(set([e[\"original_path\"] for e in full_mdata_dict_dataset ]))\n",
    "\n",
    "# # remove the symbphony No.100 from Haydn because of the enharmonic transposition\n",
    "# paths.remove(\"datasets\\\\opnd\\\\haydndoversyms-10004m.opnd-m\")\n",
    "\n",
    "# print(paths)\n",
    "print(len(mdata_paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_mdata_dict_dataset ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "f-Fg6gJKvNLt"
   },
   "outputs": [],
   "source": [
    "mdata_dataset = PSDataset(full_mdata_dict_dataset,mdata_paths, transform_chrom,transform_diat,False)\n",
    "mdata_dataloader  = DataLoader(mdata_dataset,  batch_size=16, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "ml905Mtdvj-T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "all_inputs = []\n",
    "all_outputs = []\n",
    "all_targets = []\n",
    "model.eval() # Evaluation mode (e.g. disable dropout)\n",
    "with torch.no_grad(): # Disable gradient tracking\n",
    "    for seqs, targets,lens in mdata_dataloader:\n",
    "        # Move data to device\n",
    "        seqs = seqs.to(device)\n",
    "\n",
    "        # Predict the model's output on a batch.\n",
    "        predicted = model.predict(seqs,lens)                   \n",
    "        # Update the evaluation statistics.\n",
    "        for i,p in enumerate(predicted):\n",
    "            all_inputs.append(torch.argmax(seqs[0:int(lens[i]),i,:].cpu(),1).numpy())\n",
    "            all_outputs.append(torch.Tensor(p))\n",
    "            all_targets.append(targets[0:int(lens[i]),i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsefdSHxvrWy",
    "outputId": "33785b90-5e03-4a6d-86dd-92b6b763a505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moz', 'tel', 'bac', 'hay', 'cor', 'bee', 'viv', 'han']\n"
     ]
    }
   ],
   "source": [
    "# Divide accuracy according to author\n",
    "authors = []\n",
    "\n",
    "for sequence in all_inputs:\n",
    "    author = [e[\"original_path\"].split(\"\\\\\")[-1][:3] for e in full_mdata_dict_dataset\n",
    "              if len(e[\"midi_number\"]) == len(sequence) and\n",
    "              list(e[\"midi_number\"]) ==list(sequence) ]\n",
    "    # assert len(author) == 1\n",
    "    authors.append(author[0])\n",
    "\n",
    "considered_authors = list(set(authors))\n",
    "print(considered_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgNt_yG7vrfd",
    "outputId": "8473393f-dac6-4930-9d9e-da9c1046f1ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'moz': 98, 'tel': 116, 'bac': 93, 'hay': 200, 'cor': 25, 'bee': 127, 'viv': 45, 'han': 52}\n",
      "{'moz': 0.9959990201682044, 'tel': 0.995265306122449, 'bac': 0.9962048561518058, 'hay': 0.9918334013883218, 'cor': 0.9989793002082228, 'bee': 0.9948148450577716, 'viv': 0.9981630403722905, 'han': 0.9978775510204082}\n",
      "{'moz': 24494, 'tel': 24500, 'bac': 24505, 'hay': 24490, 'cor': 24493, 'bee': 24493, 'viv': 24497, 'han': 24500}\n",
      "Total errors : 756\n"
     ]
    }
   ],
   "source": [
    "errors_per_author = {}\n",
    "accuracy_per_author = {}\n",
    "notes_per_author = {}\n",
    "for ca in considered_authors:\n",
    "    # ca_inputs = torch.cat([all_inputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_outputs = torch.cat([all_outputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_targets = torch.cat([all_targets[i] for i,a in enumerate(authors) if a == ca])\n",
    "    # print(ca_inputs.shape,ca_outputs.shape,ca_targets.shape,ca_predicted_pitches.shape)\n",
    "    ca_acc = accuracy_score(ca_outputs,ca_targets)\n",
    "    accuracy_per_author[ca] = float(ca_acc)\n",
    "    errors_per_author[ca] = int(len(ca_targets) - sum(torch.eq(ca_outputs,ca_targets)))\n",
    "    notes_per_author[ca] = len(ca_targets)\n",
    "\n",
    "print(errors_per_author)\n",
    "print(accuracy_per_author)\n",
    "print(notes_per_author)\n",
    "print(\"Total errors :\", sum([e for e in errors_per_author.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5s0d56evrje"
   },
   "source": [
    "### Best accuracy for now\n",
    "for now best accuracy is with  no CRF (but considering durations) n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 0.09\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "duration_delimiter = [0.125,0.25,0.5,1,2,4]\n",
    "\n",
    "Model available in: \"model_temp_epoch12-noCRFacc9575.pkl\"\n",
    "accuracy on validation set 0.9575\n",
    "Trained on all dataset\n",
    "\n",
    "\n",
    "{'moz': 98, 'tel': 116, 'bac': 93, 'hay': 200, 'cor': 25, 'bee': 127, 'viv': 45, 'han': 52}\n",
    "{'moz': 0.9959990201682044, 'tel': 0.995265306122449, 'bac': 0.9962048561518058, 'hay': 0.9918334013883218, 'cor': 0.9989793002082228, 'bee': 0.9948148450577716, 'viv': 0.9981630403722905, 'han': 0.9978775510204082}\n",
    "{'moz': 24494, 'tel': 24500, 'bac': 24505, 'hay': 24490, 'cor': 24493, 'bee': 24493, 'viv': 24497, 'han': 24500}\n",
    "Total errors : 756\n",
    "\n",
    "This win by far against ps13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVvP1eH8vrl3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOTDh55Hh2OWCo66dGc+SES",
   "include_colab_link": true,
   "name": "rnncrf_pitch_spelling",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
