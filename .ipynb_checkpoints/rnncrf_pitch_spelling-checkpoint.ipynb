{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fosfrancesco/pitch-spelling/blob/main/rnncrf_pitch_spelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fifMg_hxNSOg",
    "outputId": "a8b320f9-4231-40d9-8f10-a7b8acd1da37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-crf\n",
      "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hsciybUBNkur"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "import music21 as m21\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn\n",
    "import music21 as m21\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchcrf import CRF\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "# import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Naq6UG5jRbyK"
   },
   "source": [
    "# RNN-CRF for Pitch Spelling\n",
    "\n",
    "Dataset: different authors from ASAP collection\n",
    "Challenges:\n",
    "- extremely long sequences\n",
    "- small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mHJvrZ2Wo_e",
    "outputId": "1319f78b-cfb1-4e2a-937c-c47cf952757c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'C'), (1, 'B#'), (2, 'D--'), (3, 'C#'), (4, 'B##'), (5, 'D-'), (6, 'D'), (7, 'C##'), (8, 'E--'), (9, 'D#'), (10, 'E-'), (11, 'F--'), (12, 'E'), (13, 'D##'), (14, 'F-'), (15, 'F'), (16, 'E#'), (17, 'G--'), (18, 'F#'), (19, 'E##'), (20, 'G-'), (21, 'G'), (22, 'F##'), (23, 'A--'), (24, 'G#'), (25, 'A-'), (26, 'A'), (27, 'G##'), (28, 'B--'), (29, 'A#'), (30, 'B-'), (31, 'C--'), (32, 'B'), (33, 'A##'), (34, 'C-')]\n",
      "['D--', 'B##', 'C##', 'E--', 'F--', 'D##', 'G--', 'E##', 'F##', 'A--', 'G##', 'B--', 'C--', 'A##']\n",
      "[(0, 'P1'), (1, 'd2'), (2, 'A7'), (3, 'm2'), (4, 'A1'), (5, 'M2'), (6, 'd3'), (7, 'AA1'), (8, 'm3'), (9, 'A2'), (10, 'M3'), (11, 'd4'), (12, 'AA2'), (13, 'P4'), (14, 'A3'), (15, 'd5'), (16, 'A4'), (17, 'P5'), (18, 'd6'), (19, 'AA4'), (20, 'm6'), (21, 'A5'), (22, 'M6'), (23, 'd7'), (24, 'AA5'), (25, 'm7'), (26, 'A6'), (27, 'M7'), (28, 'd1'), (29, 'AA6')]\n"
     ]
    }
   ],
   "source": [
    "pitches_dict = {\n",
    "    0 : [\"C\",\"B#\",\"D--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    1 : [\"C#\",\"B##\",\"D-\"], # nn.Linear(input_size+context_size, 2)\n",
    "    2 : [\"D\",\"C##\",\"E--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    3 : [\"D#\",\"E-\",\"F--\"],\n",
    "    4 : [\"E\",\"D##\",\"F-\"],\n",
    "    5 : [\"F\",\"E#\",\"G--\"],\n",
    "    6 : [\"F#\",\"E##\",\"G-\"],\n",
    "    7 : [\"G\",\"F##\",\"A--\"],\n",
    "    8 : [\"G#\",\"A-\"],\n",
    "    9 : [\"A\",\"G##\",\"B--\"],\n",
    "    10 : [\"A#\",\"B-\",\"C--\"],\n",
    "    11 : [\"B\",\"A##\",\"C-\"]\n",
    "}\n",
    "\n",
    "accepted_pitches = [ii for i in pitches_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_pitches)])\n",
    "\n",
    "double_acc_pitches = [ii for i in pitches_dict.values() for ii in i if ii.endswith(\"##\") or  ii.endswith(\"--\") ]\n",
    "print(double_acc_pitches)\n",
    "\n",
    "def score2midi_numbers(score):\n",
    "  return [p.midi%12 for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "def score2pitches(score):\n",
    "  return [p.name for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "interval_dict = {\n",
    "    0 : [\"P1\",\"d2\",\"A7\"], \n",
    "    1 : [\"m2\",\"A1\"], \n",
    "    2 : [\"M2\",\"d3\",\"AA1\"], \n",
    "    3 : [\"m3\",\"A2\"],\n",
    "    4 : [\"M3\",\"d4\",\"AA2\"],\n",
    "    5 : [\"P4\",\"A3\"],\n",
    "    6 : [\"d5\",\"A4\"],\n",
    "    7 : [\"P5\",\"d6\",\"AA4\"],\n",
    "    8 : [\"m6\",\"A5\"],\n",
    "    9 : [\"M6\",\"d7\",\"AA5\"],\n",
    "    10 : [\"m7\",\"A6\"],\n",
    "    11 : [\"M7\",\"d1\",\"AA6\"]\n",
    "}\n",
    "\n",
    "accepted_intervals = [ii for i in interval_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_intervals)])\n",
    "\n",
    "def transp_score(score):\n",
    "    \"\"\" For each input return len(accepted_intervals) transposed scores\"\"\"\n",
    "    return [score.transpose(interval) for interval in accepted_intervals]\n",
    "\n",
    "def smart_transp_score(score):\n",
    "    \"\"\" For each chromatic interval chose the interval that lead to the smallest number of accidentals\"\"\"\n",
    "    scores = []\n",
    "    for chromatic_int in interval_dict.keys():\n",
    "        temp_scores = []\n",
    "        temp_acc_number = []\n",
    "        for diat_interval in interval_dict[chromatic_int]:\n",
    "            new_score = score.transpose(diat_interval)\n",
    "            temp_scores.append(new_score)\n",
    "            temp_acc_number.append(sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in score2pitches(new_score)]))\n",
    "            # print(\"choice:\", [note.name for note in temp_scores[-1].flat.notes][0:10],\"acc:\",temp_acc_number[-1] )\n",
    "        #keep only the one with the lowest number of accidentals\n",
    "        min_index = np.argmin(temp_acc_number)\n",
    "        # print(\"preferred the number\", min_index)\n",
    "        scores.append(temp_scores[min_index])\n",
    "    return scores\n",
    "\n",
    "def acc_simple_enough(score,accepted_ratio = 0.2 ):\n",
    "    pitches = score2pitches(score)\n",
    "    double_acc = sum(el in double_acc_pitches for el in pitches)\n",
    "    if double_acc/len(pitches) < accepted_ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "\n",
    "diatonic_pitches = [\"C\",\"D\", \"E\", \"F\", \"G\", \"A\", \"B\"]\n",
    "\n",
    "# #test acc_simple_enough()\n",
    "# score = m21.converter.parse(paths[356])\n",
    "# scores = smart_transp_score(score)\n",
    "# #delete the pieces with non accepted pitches (e.g. triple sharps)\n",
    "# scores = [s for s in scores if all(pitch in accepted_pitches for pitch in score2pitches(s))]\n",
    "# for s in scores:\n",
    "#     print(s.parts[0].flat.getElementsByClass(m21.key.KeySignature)[0], \"simple enough:\", acc_simple_enough(s))\n",
    "#     print([n.name for n in s.flat.notes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw-SuL4ZB_2C"
   },
   "source": [
    "## Import ASAP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrZ0BwLEj2Gp",
    "outputId": "6b521f78-28db-4d4f-f4ef-9345c5d91db9"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/fosfrancesco/pitch-spelling.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WaINjDS2kpxE"
   },
   "outputs": [],
   "source": [
    "basepath = \"./\" #to change if running locally or on colab\n",
    "\n",
    "# load the asap datasets\n",
    "with open(Path(basepath,'datasets','baroque_asap.pkl'), 'rb') as fid:\n",
    "     dataset_baroque = pickle.load( fid)\n",
    "\n",
    "with open(Path(basepath,'datasets','classical_asap.pkl'), 'rb') as fid:\n",
    "     dataset_classical = pickle.load( fid)\n",
    "\n",
    "with open(Path(basepath,'datasets','romantic_asap.pkl'), 'rb') as fid:\n",
    "     dataset_romantic = pickle.load( fid)\n",
    "\n",
    "# merge the three files together\n",
    "full_dict_dataset = dataset_baroque + dataset_classical + dataset_romantic\n",
    "# full_dict_dataset = dataset_baroque + dataset_classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYQdkJAiTS6_",
    "outputId": "72835948-2884-40bb-e5b4-6ebbc8488895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 different pieces\n",
      "Average number of notes:  2219.6285387474977\n"
     ]
    }
   ],
   "source": [
    "paths = list(set([e[\"original_path\"] for e in full_dict_dataset ]))\n",
    "\n",
    "# print(paths)\n",
    "print(len(paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_dict_dataset ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMdKkzNnCTrK"
   },
   "source": [
    "## Chose the convenient data augmentation\n",
    "Two possibilities:\n",
    "- for each chromatic interval, take only the diatonic transposition that produce the smallest number of accidentals (or the original if present)\n",
    "- take only a certain interval of time signatures\n",
    "\n",
    "The second is probably better for a smaller and simple dataset, but gives the problem of chosing between for example F# and G# that are both present in this bigger dataset. So we go for the first criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oign7EZ9BSX4",
    "outputId": "9aa3f694-289a-43fd-fd14-9cad3b8dd3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  11\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  1\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  4\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  6\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  9\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml . Chromatic:  1\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  1\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  3\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  8\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  10\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Ballades/4/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  9\n",
      "Schumann/Kreisleriana/1/xml_score.musicxml P1 -1\n",
      "['A', 'B-', 'E', 'C#', 'E', 'A', 'A', 'G', 'A', 'B-']\n",
      "[9, 10, 4, 1, 4, 9, 9, 7, 9, 10]\n",
      "Schumann/Kreisleriana/1/xml_score.musicxml m2 -6\n",
      "['B-', 'C-', 'F', 'D', 'F', 'B-', 'B-', 'A-', 'B-', 'C-']\n",
      "[10, 11, 5, 2, 5, 10, 10, 8, 10, 11]\n",
      "Schumann/Kreisleriana/1/xml_score.musicxml M2 1\n",
      "['B', 'C', 'F#', 'D#', 'F#', 'B', 'B', 'A', 'B', 'C']\n",
      "[11, 0, 6, 3, 6, 11, 11, 9, 11, 0]\n",
      "Schumann/Kreisleriana/1/xml_score.musicxml m3 -4\n",
      "['C', 'D-', 'G', 'E', 'G', 'C', 'C', 'B-', 'C', 'D-']\n",
      "[0, 1, 7, 4, 7, 0, 0, 10, 0, 1]\n",
      "Schumann/Kreisleriana/1/xml_score.musicxml M3 3\n",
      "['C#', 'D', 'G#', 'E#', 'G#', 'C#', 'C#', 'B', 'C#', 'D']\n",
      "[1, 2, 8, 5, 8, 1, 1, 11, 1, 2]\n",
      "Schumann/Kreisleriana/1/xml_score.musicxml P4 -2\n",
      "['D', 'E-', 'A', 'F#', 'A', 'D', 'D', 'C', 'D', 'E-']\n",
      "[2, 3, 9, 6, 9, 2, 2, 0, 2, 3]\n",
      "Schumann/Kreisleriana/1/xml_score.musicxml A4 5\n",
      "['D#', 'E', 'A#', 'F##', 'A#', 'D#', 'D#', 'C#', 'D#', 'E']\n",
      "[3, 4, 10, 7, 10, 3, 3, 1, 3, 4]\n",
      "Schumann/Kreisleriana/1/xml_score.musicxml P5 0\n",
      "['E', 'F', 'B', 'G#', 'B', 'E', 'E', 'D', 'E', 'F']\n",
      "[4, 5, 11, 8, 11, 4, 4, 2, 4, 5]\n",
      "Schumann/Kreisleriana/1/xml_score.musicxml m6 -5\n",
      "['F', 'G-', 'C', 'A', 'C', 'F', 'F', 'E-', 'F', 'G-']\n",
      "[5, 6, 0, 9, 0, 5, 5, 3, 5, 6]\n",
      "Schumann/Kreisleriana/1/xml_score.musicxml M6 2\n",
      "['F#', 'G', 'C#', 'A#', 'C#', 'F#', 'F#', 'E', 'F#', 'G']\n",
      "[6, 7, 1, 10, 1, 6, 6, 4, 6, 7]\n",
      "Schumann/Kreisleriana/1/xml_score.musicxml m7 -3\n",
      "['G', 'A-', 'D', 'B', 'D', 'G', 'G', 'F', 'G', 'A-']\n",
      "[7, 8, 2, 11, 2, 7, 7, 5, 7, 8]\n",
      "Schumann/Kreisleriana/1/xml_score.musicxml M7 4\n",
      "['G#', 'A', 'D#', 'B#', 'D#', 'G#', 'G#', 'F#', 'G#', 'A']\n",
      "[8, 9, 3, 0, 3, 8, 8, 6, 8, 9]\n",
      "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml P1 3\n",
      "['A', 'A', 'A', 'C#', 'C#', 'C#', 'A', 'C#', 'C#', 'F#']\n",
      "[9, 9, 9, 1, 1, 1, 9, 1, 1, 6]\n",
      "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml m2 -2\n",
      "['B-', 'B-', 'B-', 'D', 'D', 'D', 'B-', 'D', 'D', 'G']\n",
      "[10, 10, 10, 2, 2, 2, 10, 2, 2, 7]\n",
      "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml M2 5\n",
      "['B', 'B', 'B', 'D#', 'D#', 'D#', 'B', 'D#', 'D#', 'G#']\n",
      "[11, 11, 11, 3, 3, 3, 11, 3, 3, 8]\n",
      "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml m3 0\n",
      "['C', 'C', 'C', 'E', 'E', 'E', 'C', 'E', 'E', 'A']\n",
      "[0, 0, 0, 4, 4, 4, 0, 4, 4, 9]\n",
      "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml d4 -5\n",
      "['D-', 'D-', 'D-', 'F', 'F', 'F', 'D-', 'F', 'F', 'B-']\n",
      "[1, 1, 1, 5, 5, 5, 1, 5, 5, 10]\n",
      "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml P4 2\n",
      "['D', 'D', 'D', 'F#', 'F#', 'F#', 'D', 'F#', 'F#', 'B']\n",
      "[2, 2, 2, 6, 6, 6, 2, 6, 6, 11]\n",
      "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml d5 -3\n",
      "['E-', 'E-', 'E-', 'G', 'G', 'G', 'E-', 'G', 'G', 'C']\n",
      "[3, 3, 3, 7, 7, 7, 3, 7, 7, 0]\n",
      "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml P5 4\n",
      "['E', 'E', 'E', 'G#', 'G#', 'G#', 'E', 'G#', 'G#', 'C#']\n",
      "[4, 4, 4, 8, 8, 8, 4, 8, 8, 1]\n",
      "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml m6 -1\n",
      "['F', 'F', 'F', 'A', 'A', 'A', 'F', 'A', 'A', 'D']\n",
      "[5, 5, 5, 9, 9, 9, 5, 9, 9, 2]\n",
      "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml M6 6\n",
      "['F#', 'F#', 'F#', 'A#', 'A#', 'A#', 'F#', 'A#', 'A#', 'D#']\n",
      "[6, 6, 6, 10, 10, 10, 6, 10, 10, 3]\n",
      "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml m7 1\n",
      "['G', 'G', 'G', 'B', 'B', 'B', 'G', 'B', 'B', 'E']\n",
      "[7, 7, 7, 11, 11, 11, 7, 11, 11, 4]\n",
      "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml d1 -4\n",
      "['A-', 'A-', 'A-', 'C', 'C', 'C', 'A-', 'C', 'C', 'F']\n",
      "[8, 8, 8, 0, 0, 0, 8, 0, 0, 5]\n",
      "Beethoven/Piano_Sonatas/31-1/xml_score.musicxml P1 -4\n",
      "['C', 'A-', 'A-', 'E-', 'A-', 'E-', 'C', 'E-', 'A-', 'E-']\n",
      "[0, 8, 8, 3, 8, 3, 0, 3, 8, 3]\n",
      "Beethoven/Piano_Sonatas/31-1/xml_score.musicxml A1 3\n",
      "['C#', 'A', 'A', 'E', 'A', 'E', 'C#', 'E', 'A', 'E']\n",
      "[1, 9, 9, 4, 9, 4, 1, 4, 9, 4]\n",
      "Beethoven/Piano_Sonatas/31-1/xml_score.musicxml M2 -2\n",
      "['D', 'B-', 'B-', 'F', 'B-', 'F', 'D', 'F', 'B-', 'F']\n",
      "[2, 10, 10, 5, 10, 5, 2, 5, 10, 5]\n",
      "Beethoven/Piano_Sonatas/31-1/xml_score.musicxml m3 -7\n",
      "['E-', 'C-', 'C-', 'G-', 'C-', 'G-', 'E-', 'G-', 'C-', 'G-']\n",
      "[3, 11, 11, 6, 11, 6, 3, 6, 11, 6]\n",
      "Beethoven/Piano_Sonatas/31-1/xml_score.musicxml M3 0\n",
      "['E', 'C', 'C', 'G', 'C', 'G', 'E', 'G', 'C', 'G']\n",
      "[4, 0, 0, 7, 0, 7, 4, 7, 0, 7]\n",
      "Beethoven/Piano_Sonatas/31-1/xml_score.musicxml P4 -5\n",
      "['F', 'D-', 'D-', 'A-', 'D-', 'A-', 'F', 'A-', 'D-', 'A-']\n",
      "[5, 1, 1, 8, 1, 8, 5, 8, 1, 8]\n",
      "Beethoven/Piano_Sonatas/31-1/xml_score.musicxml A4 2\n",
      "['F#', 'D', 'D', 'A', 'D', 'A', 'F#', 'A', 'D', 'A']\n",
      "[6, 2, 2, 9, 2, 9, 6, 9, 2, 9]\n",
      "Beethoven/Piano_Sonatas/31-1/xml_score.musicxml P5 -3\n",
      "['G', 'E-', 'E-', 'B-', 'E-', 'B-', 'G', 'B-', 'E-', 'B-']\n",
      "[7, 3, 3, 10, 3, 10, 7, 10, 3, 10]\n",
      "Beethoven/Piano_Sonatas/31-1/xml_score.musicxml m6 -8\n",
      "['A-', 'F-', 'F-', 'C-', 'F-', 'C-', 'A-', 'C-', 'F-', 'C-']\n",
      "[8, 4, 4, 11, 4, 11, 8, 11, 4, 11]\n",
      "Beethoven/Piano_Sonatas/31-1/xml_score.musicxml M6 -1\n",
      "['A', 'F', 'F', 'C', 'F', 'C', 'A', 'C', 'F', 'C']\n",
      "[9, 5, 5, 0, 5, 0, 9, 0, 5, 0]\n",
      "Beethoven/Piano_Sonatas/31-1/xml_score.musicxml m7 -6\n",
      "['B-', 'G-', 'G-', 'D-', 'G-', 'D-', 'B-', 'D-', 'G-', 'D-']\n",
      "[10, 6, 6, 1, 6, 1, 10, 1, 6, 1]\n",
      "Beethoven/Piano_Sonatas/31-1/xml_score.musicxml M7 1\n",
      "['B', 'G', 'G', 'D', 'G', 'D', 'B', 'D', 'G', 'D']\n",
      "[11, 7, 7, 2, 7, 2, 11, 2, 7, 2]\n",
      "Chopin/Etudes_op_10/7/xml_score.musicxml P1 0\n",
      "['G', 'E', 'G', 'C', 'C', 'E', 'C', 'F', 'A-', 'F']\n",
      "[7, 4, 7, 0, 0, 4, 0, 5, 8, 5]\n",
      "Chopin/Etudes_op_10/7/xml_score.musicxml m2 -5\n",
      "['A-', 'F', 'A-', 'D-', 'D-', 'F', 'D-', 'G-', 'B--', 'G-']\n",
      "[8, 5, 8, 1, 1, 5, 1, 6, 9, 6]\n",
      "Chopin/Etudes_op_10/7/xml_score.musicxml M2 2\n",
      "['A', 'F#', 'A', 'D', 'D', 'F#', 'D', 'G', 'B-', 'G']\n",
      "[9, 6, 9, 2, 2, 6, 2, 7, 10, 7]\n",
      "Chopin/Etudes_op_10/7/xml_score.musicxml m3 -3\n",
      "['B-', 'G', 'B-', 'E-', 'E-', 'G', 'E-', 'A-', 'C-', 'A-']\n",
      "[10, 7, 10, 3, 3, 7, 3, 8, 11, 8]\n",
      "Chopin/Etudes_op_10/7/xml_score.musicxml M3 4\n",
      "['B', 'G#', 'B', 'E', 'E', 'G#', 'E', 'A', 'C', 'A']\n",
      "[11, 8, 11, 4, 4, 8, 4, 9, 0, 9]\n",
      "Chopin/Etudes_op_10/7/xml_score.musicxml P4 -1\n",
      "['C', 'A', 'C', 'F', 'F', 'A', 'F', 'B-', 'D-', 'B-']\n",
      "[0, 9, 0, 5, 5, 9, 5, 10, 1, 10]\n",
      "Chopin/Etudes_op_10/7/xml_score.musicxml A4 6\n",
      "['C#', 'A#', 'C#', 'F#', 'F#', 'A#', 'F#', 'B', 'D', 'B']\n",
      "[1, 10, 1, 6, 6, 10, 6, 11, 2, 11]\n",
      "Chopin/Etudes_op_10/7/xml_score.musicxml P5 1\n",
      "['D', 'B', 'D', 'G', 'G', 'B', 'G', 'C', 'E-', 'C']\n",
      "[2, 11, 2, 7, 7, 11, 7, 0, 3, 0]\n",
      "Chopin/Etudes_op_10/7/xml_score.musicxml m6 -4\n",
      "['E-', 'C', 'E-', 'A-', 'A-', 'C', 'A-', 'D-', 'F-', 'D-']\n",
      "[3, 0, 3, 8, 8, 0, 8, 1, 4, 1]\n",
      "Chopin/Etudes_op_10/7/xml_score.musicxml M6 3\n",
      "['E', 'C#', 'E', 'A', 'A', 'C#', 'A', 'D', 'F', 'D']\n",
      "[4, 1, 4, 9, 9, 1, 9, 2, 5, 2]\n",
      "Chopin/Etudes_op_10/7/xml_score.musicxml m7 -2\n",
      "['F', 'D', 'F', 'B-', 'B-', 'D', 'B-', 'E-', 'G-', 'E-']\n",
      "[5, 2, 5, 10, 10, 2, 10, 3, 6, 3]\n",
      "Chopin/Etudes_op_10/7/xml_score.musicxml M7 5\n",
      "['F#', 'D#', 'F#', 'B', 'B', 'D#', 'B', 'E', 'G', 'E']\n",
      "[6, 3, 6, 11, 11, 3, 11, 4, 7, 4]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml P1 -3\n",
      "['E-', 'G', 'B-', 'E-', 'G', 'B-', 'E-', 'G', 'B-', 'E-']\n",
      "[3, 7, 10, 3, 7, 10, 3, 7, 10, 3]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml A1 4\n",
      "['E', 'G#', 'B', 'E', 'G#', 'B', 'E', 'G#', 'B', 'E']\n",
      "[4, 8, 11, 4, 8, 11, 4, 8, 11, 4]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml M2 -1\n",
      "['F', 'A', 'C', 'F', 'A', 'C', 'F', 'A', 'C', 'F']\n",
      "[5, 9, 0, 5, 9, 0, 5, 9, 0, 5]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml m3 -6\n",
      "['G-', 'B-', 'D-', 'G-', 'B-', 'D-', 'G-', 'B-', 'D-', 'G-']\n",
      "[6, 10, 1, 6, 10, 1, 6, 10, 1, 6]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml M3 1\n",
      "['G', 'B', 'D', 'G', 'B', 'D', 'G', 'B', 'D', 'G']\n",
      "[7, 11, 2, 7, 11, 2, 7, 11, 2, 7]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml P4 -4\n",
      "['A-', 'C', 'E-', 'A-', 'C', 'E-', 'A-', 'C', 'E-', 'A-']\n",
      "[8, 0, 3, 8, 0, 3, 8, 0, 3, 8]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml A4 3\n",
      "['A', 'C#', 'E', 'A', 'C#', 'E', 'A', 'C#', 'E', 'A']\n",
      "[9, 1, 4, 9, 1, 4, 9, 1, 4, 9]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml P5 -2\n",
      "['B-', 'D', 'F', 'B-', 'D', 'F', 'B-', 'D', 'F', 'B-']\n",
      "[10, 2, 5, 10, 2, 5, 10, 2, 5, 10]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml A5 5\n",
      "['B', 'D#', 'F#', 'B', 'D#', 'F#', 'B', 'D#', 'F#', 'B']\n",
      "[11, 3, 6, 11, 3, 6, 11, 3, 6, 11]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml M6 0\n",
      "['C', 'E', 'G', 'C', 'E', 'G', 'C', 'E', 'G', 'C']\n",
      "[0, 4, 7, 0, 4, 7, 0, 4, 7, 0]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml m7 -5\n",
      "['D-', 'F', 'A-', 'D-', 'F', 'A-', 'D-', 'F', 'A-', 'D-']\n",
      "[1, 5, 8, 1, 5, 8, 1, 5, 8, 1]\n",
      "Beethoven/Piano_Sonatas/11-2/xml_score.musicxml M7 2\n",
      "['D', 'F#', 'A', 'D', 'F#', 'A', 'D', 'F#', 'A', 'D']\n",
      "[2, 6, 9, 2, 6, 9, 2, 6, 9, 2]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml P1 -2\n",
      "['D', 'B-', 'D', 'D', 'F', 'B-', 'D', 'D', 'B-', 'D']\n",
      "[2, 10, 2, 2, 5, 10, 2, 2, 10, 2]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml A1 5\n",
      "['D#', 'B', 'D#', 'D#', 'F#', 'B', 'D#', 'D#', 'B', 'D#']\n",
      "[3, 11, 3, 3, 6, 11, 3, 3, 11, 3]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml M2 0\n",
      "['E', 'C', 'E', 'E', 'G', 'C', 'E', 'E', 'C', 'E']\n",
      "[4, 0, 4, 4, 7, 0, 4, 4, 0, 4]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml m3 -5\n",
      "['F', 'D-', 'F', 'F', 'A-', 'D-', 'F', 'F', 'D-', 'F']\n",
      "[5, 1, 5, 5, 8, 1, 5, 5, 1, 5]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml M3 2\n",
      "['F#', 'D', 'F#', 'F#', 'A', 'D', 'F#', 'F#', 'D', 'F#']\n",
      "[6, 2, 6, 6, 9, 2, 6, 6, 2, 6]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml P4 -3\n",
      "['G', 'E-', 'G', 'G', 'B-', 'E-', 'G', 'G', 'E-', 'G']\n",
      "[7, 3, 7, 7, 10, 3, 7, 7, 3, 7]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml A4 4\n",
      "['G#', 'E', 'G#', 'G#', 'B', 'E', 'G#', 'G#', 'E', 'G#']\n",
      "[8, 4, 8, 8, 11, 4, 8, 8, 4, 8]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml P5 -1\n",
      "['A', 'F', 'A', 'A', 'C', 'F', 'A', 'A', 'F', 'A']\n",
      "[9, 5, 9, 9, 0, 5, 9, 9, 5, 9]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml A5 6\n",
      "['A#', 'F#', 'A#', 'A#', 'C#', 'F#', 'A#', 'A#', 'F#', 'A#']\n",
      "[10, 6, 10, 10, 1, 6, 10, 10, 6, 10]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml M6 1\n",
      "['B', 'G', 'B', 'B', 'D', 'G', 'B', 'B', 'G', 'B']\n",
      "[11, 7, 11, 11, 2, 7, 11, 11, 7, 11]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml m7 -4\n",
      "['C', 'A-', 'C', 'C', 'E-', 'A-', 'C', 'C', 'A-', 'C']\n",
      "[0, 8, 0, 0, 3, 8, 0, 0, 8, 0]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml M7 3\n",
      "['C#', 'A', 'C#', 'C#', 'E', 'A', 'C#', 'C#', 'A', 'C#']\n",
      "[1, 9, 1, 1, 4, 9, 1, 1, 9, 1]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml P1 -1\n",
      "['F', 'F', 'C', 'A', 'A', 'G', 'A', 'C', 'C', 'F']\n",
      "[5, 5, 0, 9, 9, 7, 9, 0, 0, 5]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml m2 -6\n",
      "['G-', 'G-', 'D-', 'B-', 'B-', 'A-', 'B-', 'D-', 'D-', 'G-']\n",
      "[6, 6, 1, 10, 10, 8, 10, 1, 1, 6]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml M2 1\n",
      "['G', 'G', 'D', 'B', 'B', 'A', 'B', 'D', 'D', 'G']\n",
      "[7, 7, 2, 11, 11, 9, 11, 2, 2, 7]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml m3 -4\n",
      "['A-', 'A-', 'E-', 'C', 'C', 'B-', 'C', 'E-', 'E-', 'A-']\n",
      "[8, 8, 3, 0, 0, 10, 0, 3, 3, 8]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml M3 3\n",
      "['A', 'A', 'E', 'C#', 'C#', 'B', 'C#', 'E', 'E', 'A']\n",
      "[9, 9, 4, 1, 1, 11, 1, 4, 4, 9]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml P4 -2\n",
      "['B-', 'B-', 'F', 'D', 'D', 'C', 'D', 'F', 'F', 'B-']\n",
      "[10, 10, 5, 2, 2, 0, 2, 5, 5, 10]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml A4 5\n",
      "['B', 'B', 'F#', 'D#', 'D#', 'C#', 'D#', 'F#', 'F#', 'B']\n",
      "[11, 11, 6, 3, 3, 1, 3, 6, 6, 11]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml P5 0\n",
      "['C', 'C', 'G', 'E', 'E', 'D', 'E', 'G', 'G', 'C']\n",
      "[0, 0, 7, 4, 4, 2, 4, 7, 7, 0]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml m6 -5\n",
      "['D-', 'D-', 'A-', 'F', 'F', 'E-', 'F', 'A-', 'A-', 'D-']\n",
      "[1, 1, 8, 5, 5, 3, 5, 8, 8, 1]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml M6 2\n",
      "['D', 'D', 'A', 'F#', 'F#', 'E', 'F#', 'A', 'A', 'D']\n",
      "[2, 2, 9, 6, 6, 4, 6, 9, 9, 2]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml m7 -3\n",
      "['E-', 'E-', 'B-', 'G', 'G', 'F', 'G', 'B-', 'B-', 'E-']\n",
      "[3, 3, 10, 7, 7, 5, 7, 10, 10, 3]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml M7 4\n",
      "['E', 'E', 'B', 'G#', 'G#', 'F#', 'G#', 'B', 'B', 'E']\n",
      "[4, 4, 11, 8, 8, 6, 8, 11, 11, 4]\n",
      "Chopin/Etudes_op_10/12/xml_score.musicxml P1 -3\n",
      "['B', 'D', 'F', 'G', 'B', 'A-', 'G', 'F', 'D', 'E-']\n",
      "[11, 2, 5, 7, 11, 8, 7, 5, 2, 3]\n",
      "Chopin/Etudes_op_10/12/xml_score.musicxml m2 -8\n",
      "['C', 'E-', 'G-', 'A-', 'C', 'B--', 'A-', 'G-', 'E-', 'F-']\n",
      "[0, 3, 6, 8, 0, 9, 8, 6, 3, 4]\n",
      "Chopin/Etudes_op_10/12/xml_score.musicxml M2 -1\n",
      "['C#', 'E', 'G', 'A', 'C#', 'B-', 'A', 'G', 'E', 'F']\n",
      "[1, 4, 7, 9, 1, 10, 9, 7, 4, 5]\n",
      "Chopin/Etudes_op_10/12/xml_score.musicxml m3 -6\n",
      "['D', 'F', 'A-', 'B-', 'D', 'C-', 'B-', 'A-', 'F', 'G-']\n",
      "[2, 5, 8, 10, 2, 11, 10, 8, 5, 6]\n",
      "Chopin/Etudes_op_10/12/xml_score.musicxml M3 1\n",
      "['D#', 'F#', 'A', 'B', 'D#', 'C', 'B', 'A', 'F#', 'G']\n",
      "[3, 6, 9, 11, 3, 0, 11, 9, 6, 7]\n",
      "Chopin/Etudes_op_10/12/xml_score.musicxml P4 -4\n",
      "['E', 'G', 'B-', 'C', 'E', 'D-', 'C', 'B-', 'G', 'A-']\n",
      "[4, 7, 10, 0, 4, 1, 0, 10, 7, 8]\n",
      "Chopin/Etudes_op_10/12/xml_score.musicxml d5 -9\n",
      "['F', 'A-', 'C-', 'D-', 'F', 'E--', 'D-', 'C-', 'A-', 'B--']\n",
      "[5, 8, 11, 1, 5, 2, 1, 11, 8, 9]\n",
      "Chopin/Etudes_op_10/12/xml_score.musicxml P5 -2\n",
      "['F#', 'A', 'C', 'D', 'F#', 'E-', 'D', 'C', 'A', 'B-']\n",
      "[6, 9, 0, 2, 6, 3, 2, 0, 9, 10]\n",
      "Chopin/Etudes_op_10/12/xml_score.musicxml m6 -7\n",
      "['G', 'B-', 'D-', 'E-', 'G', 'F-', 'E-', 'D-', 'B-', 'C-']\n",
      "[7, 10, 1, 3, 7, 4, 3, 1, 10, 11]\n",
      "Chopin/Etudes_op_10/12/xml_score.musicxml M6 0\n",
      "['G#', 'B', 'D', 'E', 'G#', 'F', 'E', 'D', 'B', 'C']\n",
      "[8, 11, 2, 4, 8, 5, 4, 2, 11, 0]\n",
      "Chopin/Etudes_op_10/12/xml_score.musicxml m7 -5\n",
      "['A', 'C', 'E-', 'F', 'A', 'G-', 'F', 'E-', 'C', 'D-']\n",
      "[9, 0, 3, 5, 9, 6, 5, 3, 0, 1]\n",
      "Chopin/Etudes_op_10/12/xml_score.musicxml d1 -10\n",
      "['B-', 'D-', 'F-', 'G-', 'B-', 'A--', 'G-', 'F-', 'D-', 'E--']\n",
      "[10, 1, 4, 6, 10, 7, 6, 4, 1, 2]\n",
      "Bach/Prelude/bwv_889/xml_score.musicxml P1 0\n",
      "['A', 'C', 'D', 'E', 'F', 'A', 'C', 'B', 'G#', 'D#']\n",
      "[9, 0, 2, 4, 5, 9, 0, 11, 8, 3]\n",
      "Bach/Prelude/bwv_889/xml_score.musicxml m2 -5\n",
      "['B-', 'D-', 'E-', 'F', 'G-', 'B-', 'D-', 'C', 'A', 'E']\n",
      "[10, 1, 3, 5, 6, 10, 1, 0, 9, 4]\n",
      "Bach/Prelude/bwv_889/xml_score.musicxml M2 2\n",
      "['B', 'D', 'E', 'F#', 'G', 'B', 'D', 'C#', 'A#', 'E#']\n",
      "[11, 2, 4, 6, 7, 11, 2, 1, 10, 5]\n",
      "Bach/Prelude/bwv_889/xml_score.musicxml m3 -3\n",
      "['C', 'E-', 'F', 'G', 'A-', 'C', 'E-', 'D', 'B', 'F#']\n",
      "[0, 3, 5, 7, 8, 0, 3, 2, 11, 6]\n",
      "Bach/Prelude/bwv_889/xml_score.musicxml M3 4\n",
      "['C#', 'E', 'F#', 'G#', 'A', 'C#', 'E', 'D#', 'B#', 'F##']\n",
      "[1, 4, 6, 8, 9, 1, 4, 3, 0, 7]\n"
     ]
    }
   ],
   "source": [
    "# choose only one enharmonic version for each chromatic interval for each piece\n",
    "dict_dataset = []\n",
    "for path in paths:\n",
    "    for c in range(12):\n",
    "        pieces_to_consider = [opus for opus in full_dict_dataset \n",
    "                              if (opus[\"original_path\"] == path and opus[\"transposed_of\"] in interval_dict[c])  ]\n",
    "        # if the original is in pieces_to_consider, go with the original\n",
    "        originals = [opus for opus in pieces_to_consider if opus[\"transposed_of\"] == \"P1\"]\n",
    "        if len(originals) == 1:\n",
    "            dict_dataset.append(originals[0])\n",
    "        else: #we go with the accidental minization criteria\n",
    "            n_accidentals = [sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in opus[\"pitches\"]]) \n",
    "                            for opus in pieces_to_consider]\n",
    "            if len(pieces_to_consider)>0:\n",
    "                dict_dataset.append(pieces_to_consider[np.argmin(n_accidentals)])\n",
    "            else:\n",
    "                print(\"No options for\", path, \". Chromatic: \",c )\n",
    "\n",
    "# accepted_ks = range(-5,6)\n",
    "# dict_dataset = [e for e in full_dict_dataset if e[\"key_signature\"] in accepted_ks]\n",
    "\n",
    "#test if it worked\n",
    "for i,e in enumerate(dict_dataset):\n",
    "    print(e[\"original_path\"], e[\"transposed_of\"], e[\"key_signature\"])\n",
    "    print(e[\"pitches\"][:10])\n",
    "    print(e[\"midi_number\"][:10])\n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgHkMeoJdb42",
    "outputId": "1f3d172f-3f93-47ce-aa1b-e37a2afba24e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2271\n",
      "Counter({'Bach': 59, 'Beethoven': 57, 'Chopin': 34, 'Schubert': 13, 'Haydn': 11, 'Schumann': 10, 'Mozart': 6, 'Brahms': 1})\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_dataset))\n",
    "\n",
    "c = Counter()\n",
    "for p in paths:\n",
    "    c[p.split(\"/\")[0]] +=1\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GRCM2W3qqeW",
    "outputId": "d53c8146-8b32-43df-cd69-b7423f1ceda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation lenghts:  152 38\n"
     ]
    }
   ],
   "source": [
    "# Ignore Brahms (only one piece)\n",
    "paths = [p for p in paths if p.split(\"/\")[0] !=\"Brahms\"]\n",
    "\n",
    "# Divide train and validation set\n",
    "path_train, path_validation = sklearn.model_selection.train_test_split(paths, test_size=0.2,stratify=[p.split(\"/\")[0] for p in paths ])\n",
    "print(\"Train and validation lenghts: \",len(path_train),len(path_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "KIZ2_bX1bom5",
    "outputId": "ae8d5b50-ed4d-4376-f9d6-e96c6aa73046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Schumann', 'Beethoven', 'Mozart', 'Haydn', 'Schubert', 'Chopin', 'Bach']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 369
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#need to find a better way to visualize this\n",
    "composers = list(set([p.split(\"/\")[0] for p in paths ]))\n",
    "print(composers)\n",
    "\n",
    "train_composer = [composers.index(p.split(\"/\")[0]) for p in path_train]\n",
    "val_composer = [composers.index(p.split(\"/\")[0]) for p in path_validation]\n",
    "\n",
    "_ = plt.hist([train_composer, val_composer], label=['train', 'validation'])\n",
    "_ = plt.legend(loc='upper left')\n",
    "_ = plt.xticks(list(range(7)), composers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-qaT10ApkCY"
   },
   "source": [
    "## Transform the input into a convenient format for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEYec2TDOWvj",
    "outputId": "1b69573b-cfeb-4dc9-8882-da42f9c25537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Helper functions to feed the correct input into the NN \n",
    "\n",
    "PAD = \"<PAD>\"\n",
    "\n",
    "tag_to_ix = {p: accepted_pitches.index(p) for p in accepted_pitches}\n",
    "#add PADDING TAD\n",
    "tag_to_ix[PAD] = len(accepted_pitches)\n",
    "\n",
    "midi_to_ix = {m: m for m in range(12)}\n",
    "# #add PADDING TAD\n",
    "# midi_to_ix[PAD] = 12\n",
    "\n",
    "print(midi_to_ix[1])\n",
    "print(len(midi_to_ix))\n",
    "\n",
    "\n",
    "class Pitch2Diatonic():\n",
    "    def __call__(self, in_seq):\n",
    "        return [p for p in in_seq]\n",
    "\n",
    "class Diatonic2Int():\n",
    "    def __call__(self, in_seq):\n",
    "        idxs = [tag_to_ix[w] for w in in_seq]\n",
    "        return idxs\n",
    "\n",
    "class Int2Pitch():\n",
    "    def __call__(self, in_seq):\n",
    "        return [accepted_pitches[i] for i in in_seq]\n",
    "\n",
    "class OneHotEncoder():\n",
    "    def __init__(self, alphabet_len):\n",
    "        self.alphabet_len = alphabet_len\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        onehot = np.zeros([len(sample), self.alphabet_len])\n",
    "        tot_chars = len(sample)\n",
    "        onehot[np.arange(tot_chars), sample] = 1\n",
    "        return onehot\n",
    "        \n",
    "class ToTensorFloat():\n",
    "    def __call__(self, sample):\n",
    "        return torch.tensor(sample,dtype=torch.float)\n",
    "\n",
    "class ToTensorLong():\n",
    "    def __call__(self, sample):\n",
    "        return torch.tensor(sample,dtype=torch.long)\n",
    "\n",
    "\n",
    "pitches_len = len(accepted_pitches)\n",
    "midinote_len = 12\n",
    "\n",
    "### Define the preprocessing pipeline\n",
    "transform_diat = transforms.Compose([\n",
    "                                     Pitch2Diatonic(),\n",
    "                                     Diatonic2Int(),\n",
    "                                     ToTensorLong()])\n",
    "transform_chrom = transforms.Compose([\n",
    "                                      OneHotEncoder(len(midi_to_ix)),\n",
    "                                      ToTensorFloat()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV9boYaToUs2",
    "outputId": "92bcd8d3-87a2-4d2c-8e92-4a106139f59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1804 38\n",
      "[9, 10, 4, 1, 4, 9, 9, 7, 9, 10, 5, 2, 5, 2, 2, 9, 0, 1, 2, 2, 7, 4, 7, 4, 4, 10, 2, 3, 9, 9]\n",
      "['A', 'B-', 'E', 'C#', 'E', 'A', 'A', 'G', 'A', 'B-', 'F', 'D', 'F', 'D', 'D', 'A', 'B#', 'C#', 'D', 'D', 'G', 'E', 'G', 'E', 'E', 'B-', 'D', 'E-', 'A', 'A']\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "\n",
    "class PSDataset(Dataset):\n",
    "    def __init__(self, dict_dataset, paths, transf_c, transf_d, augment_dataset, truncate = None):\n",
    "        if augment_dataset:\n",
    "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset if e[\"original_path\"] in paths]\n",
    "            self.diatonic_sequences = [e[\"pitches\"]\n",
    "                                       for e in dict_dataset \n",
    "                                       if e[\"original_path\"] in paths]\n",
    "        else: #consider only non transposed pieces\n",
    "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset \n",
    "                                        if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "            self.diatonic_sequences = [e[\"pitches\"]\n",
    "                                       for e in dict_dataset \n",
    "                                       if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "        #the transformations to apply to data\n",
    "        self.transf_c = transf_c\n",
    "        self.transf_d = transf_d\n",
    "        self.truncate = truncate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chromatic_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chromatic_seq = self.chromatic_sequences[idx]\n",
    "        diatonic_seq = self.diatonic_sequences[idx]\n",
    "        \n",
    "\n",
    "        #transform\n",
    "        chromatic_seq = self.transf_c(chromatic_seq)\n",
    "        diatonic_seq = self.transf_d(diatonic_seq)\n",
    "\n",
    "        if not self.truncate is None:\n",
    "            if len(diatonic_seq) > self.truncate:\n",
    "                chromatic_seq = chromatic_seq[0:self.truncate]\n",
    "                diatonic_seq = diatonic_seq[0:self.truncate]\n",
    "\n",
    "        #sanity check\n",
    "        assert len(chromatic_seq) == len(diatonic_seq)\n",
    "        seq_len = len(diatonic_seq)\n",
    "        \n",
    "        return chromatic_seq, diatonic_seq, seq_len\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\n",
    "\n",
    "print(len(train_dataset),len(validation_dataset))\n",
    "\n",
    "\n",
    "\n",
    "# test if it works\n",
    "chrom, diat, l = next(iter(train_dataset))\n",
    "print([[i for i, j in enumerate(m) if j == 1][0] for m in chrom[0:30]])\n",
    "# print([diatonic_pitches[p.item()] for p in diat[0:30]])\n",
    "print([accepted_pitches[p.item()] for p in diat[0:30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAubyjw2LC8P",
    "outputId": "d6f8574f-8901-41e7-fd7a-9a0c6091eafa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6365, 4, 12]) torch.Size([6365, 4]) tensor([6365., 5076., 4654., 2566.])\n",
      "tensor([[10,  3, 34, 21],\n",
      "        [10, 24, 25, 21],\n",
      "        [10,  3, 10, 26],\n",
      "        ...,\n",
      "        [25, 35, 35, 35],\n",
      "        [25, 35, 35, 35],\n",
      "        [25, 35, 35, 35]])\n"
     ]
    }
   ],
   "source": [
    "def pad_collate(batch):\n",
    "    (xx, yy, l) = zip(*batch)\n",
    "    \n",
    "    xx_pad = pad_sequence(xx)\n",
    "    yy_pad = pad_sequence(yy, padding_value=tag_to_ix[PAD])\n",
    "\n",
    "    #sort the sequences by length\n",
    "    seq_lengths, perm_idx = torch.Tensor(l).sort(0, descending=True)\n",
    "    xx_pad = xx_pad[:,perm_idx,:]\n",
    "    yy_pad = yy_pad[:,perm_idx]\n",
    "\n",
    "    return xx_pad, yy_pad, seq_lengths\n",
    "\n",
    "data_loader = DataLoader(dataset=validation_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "\n",
    "\n",
    "#test if it work\n",
    "for batch in data_loader:\n",
    "    print(batch[0].shape,batch[1].shape,batch[2])\n",
    "    print(batch[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O1OA1AjGWO-"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QEkFBY5cUsmN"
   },
   "outputs": [],
   "source": [
    "class RNNTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='sum',ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "       \n",
    "        # # Find the positions where the token is a dummy padding token.\n",
    "        # pad_mask = (sentences == self.pad_word_id).float()\n",
    "\n",
    "        # # For these positions, we add some large number in the column corresponding\n",
    "        # # to the dummy padding label.\n",
    "        # out[:, :, self.pad_label_id] += pad_mask*10000\n",
    "\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        # We transpose the prediction to (n_sentences, max_len), and convert it\n",
    "        # to a NumPy matrix.\n",
    "        return predicted.t().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QE7itQ88Qx17"
   },
   "outputs": [],
   "source": [
    "class RNNCRFTagger(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNCRFTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        self.crf = CRF(self.n_labels)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        ## should I initialize here??\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "      \n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # Compute the outputs of the lower layers, which will be used as emission\n",
    "        # scores for the CRF.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # We return the loss value. The CRF returns the log likelihood, but we return \n",
    "        # the *negative* log likelihood as the loss value.            \n",
    "        # PyTorch's optimizers *minimize* the loss, while we want to *maximize* the\n",
    "        # log likelihood.\n",
    "\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return -self.crf(scores, labels, mask = pad_mask )\n",
    "            \n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the emission scores, as above.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Apply the Viterbi algorithm to get the predictions. This implementation returns\n",
    "        # the result as a list of lists (not a tensor), corresponding to a matrix\n",
    "        # of shape (n_sentences, max_len).\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return self.crf.decode(scores,mask = pad_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXixmVQfvw8T"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3m_nj4HCuCe1"
   },
   "outputs": [],
   "source": [
    "# TODO: search over the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uAMSIlw0AJb6"
   },
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, train_dataloader, val_dataloader, n_epochs):\n",
    "    history = defaultdict(list)  \n",
    "    for i_epoch in range(1,n_epochs +1):\n",
    "        t0 = time.time()\n",
    "        loss_sum = 0\n",
    "        accuracy_sum = 0\n",
    "        model.train()\n",
    "        for seqs, targets, lens in train_dataloader: #seqs, targets, lens are batches\n",
    "            seqs, targets = seqs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = model(seqs,targets,lens) / sum(lens) #normalize for the number of symbol considered (without padding)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            predicted = model.predict(seqs,lens)\n",
    "            for i,p in enumerate(predicted):\n",
    "                acc= accuracy_score(p,targets[:,i][:len(p)].cpu()) #compute the accuracy without considering the padding\n",
    "                accuracy_sum += acc/len(lens) #normalize according to the number of sequences in the batch\n",
    "\n",
    "        train_loss = loss_sum/len(train_dataloader)\n",
    "        train_accuracy = accuracy_sum/len(train_dataloader) #normalize according to the number of batches\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_accuracy\"].append(train_accuracy)\n",
    "\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        all_predicted = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for seqs,targets, lens in val_dataloader:\n",
    "                # Predict the model's output on a batch\n",
    "                predicted = model.predict(seqs.to(device),lens)                   \n",
    "                # Update the lists that will be used to compute the accuracy\n",
    "                for i,p in enumerate(predicted):\n",
    "                    all_predicted.append(torch.Tensor(p))\n",
    "                    all_targets.append(targets[0:int(lens[i]),i])\n",
    "                \n",
    "        # Compute the overall accuracy for the validation set\n",
    "        val_accuracy = accuracy_score(torch.cat(all_predicted),torch.cat(all_targets))\n",
    "        history[\"val_accuracy\"].append(val_accuracy)\n",
    "\n",
    "        #save the model\n",
    "        torch.save(model, \"./models/temp/model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "#         files.download(\"model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "\n",
    "    \n",
    "        t1 = time.time()\n",
    "        print(f'Epoch {i_epoch}: train loss = {train_loss:.4f}, train_accuracy: {train_accuracy:.4f},val_accuracy: {val_accuracy:.4f}, time = {t1-t0:.4f}')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "2g2st8znpGW_",
    "outputId": "fe232e42-e270-4f5d-9bd8-718bba5e7151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda\n",
      "Epoch 1: train loss = 3.3197, train_accuracy: 0.0731,val_accuracy: 0.1529, time = 711.8035\n",
      "Epoch 2: train loss = 2.9160, train_accuracy: 0.3023,val_accuracy: 0.4987, time = 717.3231\n",
      "Epoch 3: train loss = 2.7270, train_accuracy: 0.5133,val_accuracy: 0.5876, time = 718.5597\n",
      "Epoch 4: train loss = 2.5562, train_accuracy: 0.6048,val_accuracy: 0.6681, time = 712.9922\n",
      "Epoch 5: train loss = 2.3244, train_accuracy: 0.6753,val_accuracy: 0.7373, time = 742.2230\n",
      "Epoch 6: train loss = 2.0046, train_accuracy: 0.7395,val_accuracy: 0.7900, time = 717.8578\n",
      "Epoch 7: train loss = 1.6323, train_accuracy: 0.7840,val_accuracy: 0.8344, time = 712.3407\n",
      "Epoch 8: train loss = 1.2850, train_accuracy: 0.8182,val_accuracy: 0.8593, time = 719.6853\n",
      "Epoch 9: train loss = 1.0255, train_accuracy: 0.8301,val_accuracy: 0.8640, time = 708.9008\n",
      "Epoch 10: train loss = 0.8555, train_accuracy: 0.8341,val_accuracy: 0.8697, time = 721.0234\n",
      "Epoch 11: train loss = 0.7434, train_accuracy: 0.8400,val_accuracy: 0.8744, time = 723.3992\n",
      "Epoch 12: train loss = 0.6635, train_accuracy: 0.8455,val_accuracy: 0.8750, time = 706.3158\n",
      "Epoch 13: train loss = 0.6079, train_accuracy: 0.8481,val_accuracy: 0.8820, time = 710.9923\n",
      "Epoch 14: train loss = 0.5748, train_accuracy: 0.8514,val_accuracy: 0.8820, time = 697.2036\n",
      "Epoch 15: train loss = 0.5347, train_accuracy: 0.8540,val_accuracy: 0.8853, time = 710.1234\n",
      "Epoch 16: train loss = 0.5075, train_accuracy: 0.8560,val_accuracy: 0.8840, time = 711.6479\n",
      "Epoch 17: train loss = 0.4880, train_accuracy: 0.8583,val_accuracy: 0.8849, time = 712.9411\n",
      "Epoch 18: train loss = 0.4698, train_accuracy: 0.8603,val_accuracy: 0.8898, time = 725.8706\n",
      "Epoch 19: train loss = 0.4541, train_accuracy: 0.8621,val_accuracy: 0.8891, time = 721.5331\n",
      "Epoch 20: train loss = 0.4413, train_accuracy: 0.8641,val_accuracy: 0.8943, time = 720.9610\n",
      "Epoch 21: train loss = 0.4266, train_accuracy: 0.8654,val_accuracy: 0.8924, time = 712.4487\n",
      "Epoch 22: train loss = 0.4166, train_accuracy: 0.8674,val_accuracy: 0.8942, time = 712.3691\n",
      "Epoch 23: train loss = 0.4040, train_accuracy: 0.8684,val_accuracy: 0.8914, time = 701.7486\n",
      "Epoch 24: train loss = 0.3967, train_accuracy: 0.8695,val_accuracy: 0.8937, time = 725.8464\n",
      "Epoch 25: train loss = 0.3905, train_accuracy: 0.8714,val_accuracy: 0.8929, time = 713.0453\n",
      "Epoch 26: train loss = 0.3815, train_accuracy: 0.8719,val_accuracy: 0.8973, time = 722.5785\n",
      "Epoch 27: train loss = 0.3759, train_accuracy: 0.8733,val_accuracy: 0.8983, time = 689.2104\n",
      "Epoch 28: train loss = 0.3713, train_accuracy: 0.8743,val_accuracy: 0.8971, time = 706.8821\n",
      "Epoch 29: train loss = 0.3660, train_accuracy: 0.8750,val_accuracy: 0.8985, time = 705.2721\n",
      "Epoch 30: train loss = 0.3595, train_accuracy: 0.8758,val_accuracy: 0.9022, time = 695.5366\n",
      "Epoch 31: train loss = 0.3551, train_accuracy: 0.8768,val_accuracy: 0.8998, time = 716.8738\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "n_epochs = 50\n",
    "HIDDEN_DIM = 72\n",
    "LEARNING_WEIGHT = 0.05\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True, truncate = None)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\n",
    "val_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\n",
    "\n",
    "model = RNNCRFTagger(12,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "# model = RNNTagger(12,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_WEIGHT, weight_decay=WEIGHT_DECAY)\n",
    "# otimizer = torch.optim.Adam(model.parameters(),lr = 0.05, weight_decay=1e-4)\n",
    "\n",
    "history = training_loop(model,optimizer,train_dataloader,val_dataloader, n_epochs)\n",
    "\n",
    "# After the final evaluation, we print more detailed evaluation statistics,\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.legend(['training loss', 'training accuracy', 'validation_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tTv2BrGbvSHh",
    "outputId": "801ff32d-24dc-4434-a436-17d9ca832214"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_2becd0ee-42f6-49a2-a019-3deadfab3a8b\", \"model_asap_crf300.pkl\", 63501)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# torch.save(model, \"./models/model_asap_crf300.pkl\")\n",
    "# files.download(\"model_asap_crf300.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXcmLpCKt28l"
   },
   "source": [
    "## Test on Mdata dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BacUqgD5usGL"
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "with open('/content/pitch-spelling/datasets/musedata.pkl', 'rb') as fid:\n",
    "     full_mdata_dict_dataset = pickle.load( fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgaUwW2fuwg0",
    "outputId": "89fc5f7d-884a-4ee6-fc34-b3d512f0c4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 different pieces\n",
      "Average number of notes:  858.6319771007974\n"
     ]
    }
   ],
   "source": [
    "mdata_paths = list(set([e[\"original_path\"] for e in full_mdata_dict_dataset ]))\n",
    "\n",
    "# # remove the symbphony No.100 from Haydn because of the enharmonic transposition\n",
    "# paths.remove(\"datasets\\\\opnd\\\\haydndoversyms-10004m.opnd-m\")\n",
    "\n",
    "# print(paths)\n",
    "print(len(mdata_paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_mdata_dict_dataset ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-Fg6gJKvNLt"
   },
   "outputs": [],
   "source": [
    "mdata_dataset = PSDataset(full_mdata_dict_dataset,mdata_paths, transform_chrom,transform_diat,False)\n",
    "mdata_dataloader  = DataLoader(mdata_dataset,  batch_size=64, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml905Mtdvj-T"
   },
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "all_outputs = []\n",
    "all_targets = []\n",
    "model.eval() # Evaluation mode (e.g. disable dropout)\n",
    "with torch.no_grad(): # Disable gradient tracking\n",
    "  for seqs, targets,lens in mdata_dataloader:\n",
    "    # Move data to device\n",
    "    seqs = seqs.to(device)\n",
    "\n",
    "    # Predict the model's output on a batch.\n",
    "    predicted = model.predict(seqs,lens)                   \n",
    "    # Update the evaluation statistics.\n",
    "    for i,p in enumerate(predicted):\n",
    "        all_inputs.append(torch.argmax(seqs[0:int(lens[i]),i,:].cpu(),1).numpy())\n",
    "        all_outputs.append(torch.Tensor(p))\n",
    "        all_targets.append(targets[0:int(lens[i]),i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsefdSHxvrWy",
    "outputId": "33785b90-5e03-4a6d-86dd-92b6b763a505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bac', 'hay', 'viv', 'cor', 'han', 'moz', 'tel', 'bee']\n"
     ]
    }
   ],
   "source": [
    "# Divide accuracy according to author\n",
    "authors = []\n",
    "\n",
    "for sequence in all_inputs:\n",
    "    author = [e[\"original_path\"].split(\"\\\\\")[-1][:3] for e in full_mdata_dict_dataset\n",
    "              if len(e[\"midi_number\"]) == len(sequence) and\n",
    "              list(e[\"midi_number\"]) ==list(sequence) ]\n",
    "    # assert len(author) == 1\n",
    "    authors.append(author[0])\n",
    "\n",
    "considered_authors = list(set(authors))\n",
    "print(considered_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgNt_yG7vrfd",
    "outputId": "8473393f-dac6-4930-9d9e-da9c1046f1ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bac': 124, 'hay': 371, 'viv': 110, 'cor': 22, 'han': 67, 'moz': 184, 'tel': 64, 'bee': 270}\n",
      "{'bac': 0.9949398082024077, 'hay': 0.9848509595753369, 'viv': 0.9955096542433768, 'cor': 0.999101784183236, 'han': 0.997265306122449, 'moz': 0.9924879562341798, 'tel': 0.9973877551020408, 'bee': 0.9889764422488058}\n"
     ]
    }
   ],
   "source": [
    "errors_per_author = {}\n",
    "accuracy_per_author = {}\n",
    "for ca in considered_authors:\n",
    "    # ca_inputs = torch.cat([all_inputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_outputs = torch.cat([all_outputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_targets = torch.cat([all_targets[i] for i,a in enumerate(authors) if a == ca])\n",
    "    # print(ca_inputs.shape,ca_outputs.shape,ca_targets.shape,ca_predicted_pitches.shape)\n",
    "    ca_acc = accuracy_score(ca_outputs,ca_targets)\n",
    "    accuracy_per_author[ca] = float(ca_acc)\n",
    "    errors_per_author[ca] = int(len(ca_targets) - sum(torch.eq(ca_outputs,ca_targets)))\n",
    "\n",
    "print(errors_per_author)\n",
    "print(accuracy_per_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5s0d56evrje"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVvP1eH8vrl3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOTDh55Hh2OWCo66dGc+SES",
   "include_colab_link": true,
   "name": "rnncrf_pitch_spelling",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
