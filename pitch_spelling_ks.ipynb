{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fosfrancesco/pitch-spelling/blob/main/rnncrf_pitch_spelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fifMg_hxNSOg",
    "outputId": "a8b320f9-4231-40d9-8f10-a7b8acd1da37"
   },
   "outputs": [],
   "source": [
    "#! pip install --upgrade pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hsciybUBNkur"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "import music21 as m21\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn\n",
    "import music21 as m21\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torch.nn.functional as F\n",
    "#from torchcrf import CRF\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "\n",
    "import kmeans1d\n",
    "import jenkspy\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "# import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Naq6UG5jRbyK"
   },
   "source": [
    "# Pitch Spelling and ks Prediction\n",
    "\n",
    "Dataset: different authors from ASAP collection\n",
    "Challenges:\n",
    "- extremely long sequences\n",
    "- small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw-SuL4ZB_2C"
   },
   "source": [
    "## Import ASAP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrZ0BwLEj2Gp",
    "outputId": "6b521f78-28db-4d4f-f4ef-9345c5d91db9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "222 different pieces\nAverage number of notes:  2410.253424657534\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/fosfrancesco/pitch-spelling.git\n",
    "\n",
    "basepath = \"./\" #to change if running locally or on colab\n",
    "# load the asap datasets with ks\n",
    "with open(Path('./asapks.pkl'), 'rb') as fid:\n",
    "     full_dict_dataset = pickle.load( fid)\n",
    "\n",
    "######## Note for Nicolas: I called it \"dict_dataset\", but it is a list of dictionaries\n",
    "paths = list(set([e[\"original_path\"] for e in full_dict_dataset ]))\n",
    "\n",
    "# print(paths)\n",
    "print(len(paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_dict_dataset ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMdKkzNnCTrK"
   },
   "source": [
    "## Chose the convenient data augmentation\n",
    "For each chromatic interval, take only the diatonic transposition that produce the smallest number of accidentals (or the original if present).\n",
    "\n",
    "Then remove the pieces with ks that have more than 7 sharps or 7 flats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oign7EZ9BSX4",
    "outputId": "9aa3f694-289a-43fd-fd14-9cad3b8dd3b7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No options for Liszt/Transcendental_Etudes/10/xml_score.musicxml . Chromatic:  1\n",
      "No options for Liszt/Transcendental_Etudes/10/xml_score.musicxml . Chromatic:  6\n",
      "No options for Liszt/Transcendental_Etudes/4/xml_score.musicxml . Chromatic:  2\n",
      "No options for Liszt/Transcendental_Etudes/4/xml_score.musicxml . Chromatic:  4\n",
      "No options for Liszt/Transcendental_Etudes/4/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  11\n",
      "No options for Ravel/Gaspard_de_la_Nuit/1_Ondine/xml_score.musicxml . Chromatic:  4\n",
      "No options for Liszt/Transcendental_Etudes/11/xml_score.musicxml . Chromatic:  1\n",
      "No options for Liszt/Transcendental_Etudes/11/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml . Chromatic:  1\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  1\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  4\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  6\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  9\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  9\n",
      "No options for Ravel/Miroirs/4_Alborada_del_gracioso/xml_score.musicxml . Chromatic:  11\n",
      "No options for Liszt/Sonata/xml_score.musicxml . Chromatic:  4\n",
      "No options for Liszt/Sonata/xml_score.musicxml . Chromatic:  6\n",
      "No options for Liszt/Sonata/xml_score.musicxml . Chromatic:  11\n",
      "No options for Debussy/Images_Book_1/1_Reflets_dans_lEau/xml_score.musicxml . Chromatic:  3\n",
      "No options for Debussy/Images_Book_1/1_Reflets_dans_lEau/xml_score.musicxml . Chromatic:  8\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  1\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  3\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  8\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  10\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  11\n",
      "No options for Scriabin/Sonatas/5/xml_score.musicxml . Chromatic:  1\n",
      "No options for Scriabin/Sonatas/5/xml_score.musicxml . Chromatic:  6\n",
      "No options for Scriabin/Sonatas/5/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Ballades/4/xml_score.musicxml . Chromatic:  6\n",
      "No options for Liszt/Mephisto_Waltz/xml_score.musicxml . Chromatic:  11\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  1\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  4\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  6\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  9\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  11\n",
      "No options for Liszt/Transcendental_Etudes/9/xml_score.musicxml . Chromatic:  6\n",
      "No options for Liszt/Transcendental_Etudes/9/xml_score.musicxml . Chromatic:  11\n",
      "Before removing according to ks: 2618\n",
      "After removing according to ks: 2406\n",
      "Dataset has 2406 pieces.\n",
      "By composer: Beethoven: 57, Chopin: 34, Liszt: 16, Bach: 59, Prokofiev: 1, Schubert: 13, Rachmaninoff: 4, Haydn: 11, Schumann: 10, Glinka: 1, Ravel: 4, Debussy: 2, Mozart: 6, Balakirev: 1, Scriabin: 2, Brahms: 1\n"
     ]
    }
   ],
   "source": [
    "from pitches import keep_best_transpositions\n",
    "from utils import root_folder\n",
    "                                                    \n",
    "dict_dataset = keep_best_transpositions(full_dict_dataset)\n",
    "# #test if it worked\n",
    "# for i,e in enumerate(dict_dataset):\n",
    "#     print(e[\"original_path\"], e[\"transposed_of\"], e[\"key_signatures\"])\n",
    "#     print(e[\"pitches\"][:10])\n",
    "#     print(e[\"midi_number\"][:10])\n",
    "#     if i == 100:\n",
    "#         break\n",
    "\n",
    "composer_per_piece = [root_folder(p) for p in paths]\n",
    "c = Counter(composer_per_piece)\n",
    "\n",
    "print(f\"Dataset has {len(dict_dataset)} pieces.\")\n",
    "print(f\"By composer: {', '.join(map(lambda item: item[0] + ': ' + str(item[1]), c.items()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "222 initial pieces\n220 pieces after removing overlapping with musedata and Mozart Fantasie\n"
     ]
    }
   ],
   "source": [
    "# remove pieces from asap that are in Musedata\n",
    "print(len(paths), \"initial pieces\")\n",
    "paths = [p for p in paths if p!= \"Bach/Prelude/bwv_865/xml_score.musicxml\"]\n",
    "\n",
    "#remove mozart Fantasie because of incoherent key signature\n",
    "paths = [p for p in paths if p!= 'Mozart/Fantasie_475/xml_score.musicxml']\n",
    "\n",
    "print(len(paths), \"pieces after removing overlapping with musedata and Mozart Fantasie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GRCM2W3qqeW",
    "outputId": "d53c8146-8b32-43df-cd69-b7423f1ceda2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train and validation lenghts:  163 29\nRemaining composers: ['Schumann', 'Rachmaninoff', 'Chopin', 'Mozart', 'Bach', 'Schubert', 'Beethoven', 'Haydn']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 373,
       "height": 248
      },
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Temporary remove composer with only one piece, because they create problems with sklearn stratify\n",
    "one_piece_composers = ['Balakirev','Prokofiev','Brahms','Glinka', 'Debussy', 'Ravel', 'Scriabin','Liszt']\n",
    "paths = [p for p in paths if root_folder(p) not in one_piece_composers]\n",
    "\n",
    "# Divide train and validation set\n",
    "path_train, path_validation = sklearn.model_selection.train_test_split(paths, test_size=0.15, stratify=[root_folder(p) for p in paths ])\n",
    "print(\"Train and validation lenghts: \",len(path_train),len(path_validation))\n",
    "\n",
    "#need to find a better way to visualize this\n",
    "composers = list(set([root_folder(p) for p in paths ]))\n",
    "print(f\"Remaining composers: {composers}\")\n",
    "\n",
    "train_composer = [composers.index(root_folder(p)) for p in path_train]\n",
    "val_composer = [composers.index(root_folder(p)) for p in path_validation]\n",
    "\n",
    "_ = plt.hist([train_composer, val_composer], label=['train', 'validation'])\n",
    "_ = plt.legend(loc='upper left')\n",
    "_ = plt.xticks(list(range(len(composers))), composers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-qaT10ApkCY"
   },
   "source": [
    "## Transform the input into a convenient format for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEYec2TDOWvj",
    "outputId": "1b69573b-cfeb-4dc9-8882-da42f9c25537"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n15\n"
     ]
    }
   ],
   "source": [
    "from pitches import PITCHES\n",
    "from pitches import KEY_SIGNATURES\n",
    "from utils import PAD\n",
    "# Helper functions to feed the correct input into the NN \n",
    "\n",
    "N_DURATION_CLASSES = 4\n",
    "\n",
    "accepted_pitches = [ii for i in PITCHES.values() for ii in i]\n",
    "pitch_to_ix = {p: accepted_pitches.index(p) for p in accepted_pitches}\n",
    "ks_to_ix = {k: KEY_SIGNATURES.index(k) for k in KEY_SIGNATURES}\n",
    "#add PADDING TAD\n",
    "pitch_to_ix[PAD] = len(accepted_pitches)\n",
    "ks_to_ix[PAD] = len(KEY_SIGNATURES)\n",
    "\n",
    "midi_to_ix = {m: m for m in range(12)}\n",
    "#add PADDING TAD\n",
    "midi_to_ix[PAD] = 12\n",
    "\n",
    "# print(midi_to_ix[1])\n",
    "# print(len(midi_to_ix))\n",
    "\n",
    "\n",
    "\n",
    "# class Pitch2Diatonic():\n",
    "#     def __call__(self, in_seq):\n",
    "#         return [p for p in in_seq]\n",
    "\n",
    "class Pitch2Int():\n",
    "    def __call__(self, in_seq):\n",
    "        idxs = [pitch_to_ix[w] for w in in_seq]\n",
    "        return idxs\n",
    "    \n",
    "class Ks2Int():\n",
    "    def __call__(self, in_seq):\n",
    "        idxs = [ks_to_ix[w] for w in in_seq]\n",
    "        return idxs\n",
    "\n",
    "class Int2Pitch():\n",
    "    def __call__(self, in_seq):\n",
    "        return [accepted_pitches[i] for i in in_seq]\n",
    "\n",
    "class OneHotEncoder():\n",
    "    def __init__(self, alphabet_len):\n",
    "        self.alphabet_len = alphabet_len\n",
    "        \n",
    "    def __call__(self, sample,weights = None):\n",
    "        onehot = np.zeros([len(sample), self.alphabet_len])\n",
    "        tot_chars = len(sample)\n",
    "        onehot[np.arange(tot_chars), sample] = 1\n",
    "        return onehot\n",
    "    \n",
    "class DurationOneHotEncoder():\n",
    "    def __init__(self, pitch_alphabet_len, n_dur_class = 4):\n",
    "        self.pitch_alphabet_len = pitch_alphabet_len\n",
    "        self.dur_alphabet_len = n_dur_class\n",
    "        \n",
    "    def __call__(self, sample, durs):\n",
    "        sample = torch.tensor(sample,dtype=torch.long)\n",
    "        onehot_pitch = torch.nn.functional.one_hot(sample,self.pitch_alphabet_len)\n",
    "        #compute breaks in duration list\n",
    "        clusters, centroids = kmeans1d.cluster(durs, N_DURATION_CLASSES)   \n",
    "        quantized_durations = torch.tensor(clusters,dtype=torch.long)\n",
    "        onehot_duration = torch.nn.functional.one_hot(quantized_durations,self.dur_alphabet_len)\n",
    "        return torch.cat([onehot_pitch,onehot_duration],1)\n",
    "    \n",
    "        \n",
    "class ToTensorFloat():\n",
    "    def __call__(self, sample, durs = None):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.float()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.float)\n",
    "\n",
    "class ToTensorLong():\n",
    "    def __call__(self, sample):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.long()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.long)\n",
    "    \n",
    "class MultInputCompose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, sample, durs):\n",
    "        for t in self.transforms:\n",
    "            sample = t(sample, durs)\n",
    "        return sample\n",
    "\n",
    "\n",
    "### Define the preprocessing pipeline\n",
    "transform_diat = transforms.Compose([Pitch2Int(),ToTensorLong()])\n",
    "transform_chrom = MultInputCompose([DurationOneHotEncoder(len(midi_to_ix),N_DURATION_CLASSES),ToTensorFloat()])\n",
    "transform_key = transforms.Compose([Ks2Int(),ToTensorLong()])\n",
    "\n",
    "\n",
    "print(set([ks_to_ix[ks] for piece in dict_dataset for ks in piece[\"key_signatures\"]]))\n",
    "print(ks_to_ix[PAD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV9boYaToUs2",
    "outputId": "92bcd8d3-87a2-4d2c-8e92-4a106139f59f",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "462\n",
      "torch.Size([462, 17])\n",
      "torch.Size([462])\n",
      "Division 7.107692307692307\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "462\n",
      "torch.Size([462, 17])\n",
      "torch.Size([462])\n",
      "Division 7.107692307692307\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "[tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])]\n",
      "462\n",
      "torch.Size([462, 17])\n",
      "torch.Size([462])\n",
      "Division 7.107692307692307\n",
      "[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "[tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.])]\n",
      "462\n",
      "torch.Size([462, 17])\n",
      "torch.Size([462])\n",
      "Division 7.107692307692307\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "[tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "462\n",
      "torch.Size([462, 17])\n",
      "torch.Size([462])\n",
      "Division 7.107692307692307\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "462\n",
      "torch.Size([462, 17])\n",
      "torch.Size([462])\n",
      "Division 7.107692307692307\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "[tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "462\n",
      "torch.Size([462, 17])\n",
      "torch.Size([462])\n",
      "Division 7.107692307692307\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "[tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "462\n",
      "torch.Size([462, 17])\n",
      "torch.Size([462])\n",
      "Division 7.107692307692307\n",
      "[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "[tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "462\n",
      "torch.Size([462, 17])\n",
      "torch.Size([462])\n",
      "Division 7.107692307692307\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "[tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "462\n",
      "torch.Size([440, 17])\n",
      "torch.Size([440])\n",
      "Division 6.769230769230769\n",
      "[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "[tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.])]\n",
      "440\n",
      "torch.Size([440, 17])\n",
      "torch.Size([440])\n",
      "Division 6.769230769230769\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "[tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "440\n",
      "torch.Size([440, 17])\n",
      "torch.Size([440])\n",
      "Division 6.769230769230769\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "440\n",
      "torch.Size([440, 17])\n",
      "torch.Size([440])\n",
      "Division 6.769230769230769\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "[tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "440\n",
      "torch.Size([440, 17])\n",
      "torch.Size([440])\n",
      "Division 6.769230769230769\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "[tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "440\n",
      "torch.Size([440, 17])\n",
      "torch.Size([440])\n",
      "Division 6.769230769230769\n",
      "[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "[tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "440\n",
      "torch.Size([440, 17])\n",
      "torch.Size([440])\n",
      "Division 6.769230769230769\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "[tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "440\n",
      "torch.Size([440, 17])\n",
      "torch.Size([440])\n",
      "Division 6.769230769230769\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "440\n",
      "torch.Size([440, 17])\n",
      "torch.Size([440])\n",
      "Division 6.769230769230769\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "[tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "440\n",
      "torch.Size([440, 17])\n",
      "torch.Size([440])\n",
      "Division 6.769230769230769\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "440\n",
      "torch.Size([440, 17])\n",
      "torch.Size([440])\n",
      "Division 6.769230769230769\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])]\n",
      "440\n",
      "torch.Size([440, 17])\n",
      "torch.Size([440])\n",
      "Division 6.769230769230769\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "[tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])]\n",
      "440\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "from datasets import PSDataset\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,transform_key,True, sort = True)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat,transform_key, False)\n",
    "\n",
    "print(len(train_dataset),len(validation_dataset))\n",
    "\n",
    "\n",
    "# test if it works\n",
    "for chrom,diat,ks,seq_len in train_dataset:\n",
    "    print(chrom.shape)\n",
    "    print(ks.shape)\n",
    "    print(\"Division\", diat.shape[0]/65)\n",
    "#     print(torch.argmax(chrom[0:30],1))\n",
    "#     # print([diatonic_pitches[p.item()] for p in diat[0:30]])\n",
    "#     print([accepted_pitches[p.item()] for p in diat[0:30]])\n",
    "    print([p.item() for p in ks[-20:]])\n",
    "    print([p for p in chrom[-10:,:]])\n",
    "    print(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAubyjw2LC8P",
    "outputId": "d6f8574f-8901-41e7-fd7a-9a0c6091eafa"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2776, 4, 17]) torch.Size([2776, 4]) torch.Size([2776, 4])\ntensor([[[ 0.,  0.,  0.,  ...,  1.,  0.,  0.],\n         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n         [ 0.,  0.,  1.,  ...,  0.,  1.,  0.],\n         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n\n        [[ 0.,  0.,  0.,  ...,  1.,  0.,  0.],\n         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n         [ 0.,  0.,  0.,  ...,  1.,  0.,  0.],\n         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n\n        [[ 0.,  0.,  0.,  ...,  1.,  0.,  0.],\n         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n         [ 0.,  0.,  0.,  ...,  0.,  1.,  0.],\n         [ 1.,  0.,  0.,  ...,  0.,  0.,  0.]],\n\n        ...,\n\n        [[ 0.,  0.,  0.,  ...,  1.,  0.,  0.],\n         [12., 12., 12.,  ..., 12., 12., 12.],\n         [12., 12., 12.,  ..., 12., 12., 12.],\n         [12., 12., 12.,  ..., 12., 12., 12.]],\n\n        [[ 0.,  0.,  0.,  ...,  1.,  0.,  0.],\n         [12., 12., 12.,  ..., 12., 12., 12.],\n         [12., 12., 12.,  ..., 12., 12., 12.],\n         [12., 12., 12.,  ..., 12., 12., 12.]],\n\n        [[ 0.,  0.,  0.,  ...,  1.,  0.,  0.],\n         [12., 12., 12.,  ..., 12., 12., 12.],\n         [12., 12., 12.,  ..., 12., 12., 12.],\n         [12., 12., 12.,  ..., 12., 12., 12.]]])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def pad_collate(batch):\n",
    "    (chromatic_seq, diatonic_seq,ks_seq, l) = zip(*batch)\n",
    "    \n",
    "    chromatic_seq_pad = pad_sequence(chromatic_seq, padding_value=midi_to_ix[PAD])\n",
    "    diatonic_seq_pad = pad_sequence(diatonic_seq, padding_value=pitch_to_ix[PAD])\n",
    "    ks_seq_pad = pad_sequence(ks_seq, padding_value=ks_to_ix[PAD])\n",
    "\n",
    "    #sort the sequences by length\n",
    "    seq_lengths, perm_idx = torch.Tensor(l).sort(0, descending=True)\n",
    "    chromatic_seq_pad = chromatic_seq_pad[:,perm_idx,:]\n",
    "    diatonic_seq_pad = diatonic_seq_pad[:,perm_idx]\n",
    "    ks_seq_pad = ks_seq_pad[:,perm_idx]\n",
    "\n",
    "    return chromatic_seq_pad, diatonic_seq_pad,ks_seq_pad, seq_lengths\n",
    "\n",
    "data_loader = DataLoader(dataset=validation_dataset,  num_workers =1, batch_size=4, shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "#test if it work\n",
    "for batch in data_loader:\n",
    "    print(batch[0].shape,batch[1].shape,batch[2].shape)\n",
    "    print(batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O1OA1AjGWO-"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3m_nj4HCuCe1"
   },
   "outputs": [],
   "source": [
    "# TODO: search over the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "2g2st8znpGW_",
    "outputId": "fe232e42-e270-4f5d-9bd8-718bba5e7151"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training device: cuda\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f9c8a5fd639a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_WEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMOMENTUM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWEIGHT_DECAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# After the final evaluation, we print more detailed evaluation statistics,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/Altay/Développements/pitch-spelling/train.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, optimizer, train_dataloader, val_dataloader, n_epochs, device)\u001b[0m\n\u001b[1;32m     33\u001b[0m             )\n\u001b[1;32m     34\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpitches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeysignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/research/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/Altay/Développements/pitch-spelling/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences, pitches, keysignatures, sentences_len)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m# Compute the outputs. The shape is (max_len, n_sentences, n_labels).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mscores_pitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_ks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;31m# Flatten the outputs and the gold-standard labels, to compute the loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/Altay/Développements/pitch-spelling/models.py\u001b[0m in \u001b[0;36mcompute_outputs\u001b[0;34m(self, sentences, sentences_len)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0mrnn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0mrnn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/research/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/research/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    822\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    823\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[1;32m    825\u001b[0m                              self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[1;32m    826\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "HIDDEN_DIM = 96 #as it is implemented now, this is double the hidden_dim\n",
    "LEARNING_RATE = 0.05\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 8\n",
    "MOMENTUM = 0.9\n",
    "RNN_LAYERS = 1\n",
    "\n",
    "#ks rnn hyperparameter\n",
    "HIDDEN_DIM2= 48\n",
    "\n",
    "#attention hyperparameter\n",
    "NUM_HEAD = 2\n",
    "NUM_LANDMARKS = 64 #should we make this depending on the seq length for each batch? \n",
    "\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,transform_key,True,sort=True, truncate = None)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat,transform_key, False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\n",
    "val_dataloader = DataLoader(validation_dataset, batch_size=1, shuffle=False,collate_fn=pad_collate)\n",
    "\n",
    "# model = torch.load(\"./models/temp/model_temp_epoch30-to_restart.pkl\")\n",
    "\n",
    "from models import RNNTagger\n",
    "from models import RNNMultiTagger\n",
    "from models import RNNNystromAttentionTagger\n",
    "from models import RNNMultNystromAttentionTagger\n",
    "\n",
    "# model = RNNTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,pitch_to_ix,ks_to_ix, n_layers =RNN_LAYERS)\n",
    "# model = RNNMultiTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,pitch_to_ix,ks_to_ix, n_layers =RNN_LAYERS)\n",
    "# model = RNNNystromAttentionTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,pitch_to_ix,ks_to_ix, n_layers =RNN_LAYERS,num_head=NUM_HEAD,num_landmarks=NUM_LANDMARKS)\n",
    "model = RNNMultNystromAttentionTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,pitch_to_ix,ks_to_ix, n_layers =RNN_LAYERS,hidden_dim2=HIDDEN_DIM2,num_head=NUM_HEAD,num_landmarks=NUM_LANDMARKS)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum = MOMENTUM,weight_decay=WEIGHT_DECAY)\n",
    "from train import training_loop\n",
    "history = training_loop(model,optimizer,train_dataloader,val_dataloader, 1)\n",
    "\n",
    "# After the final evaluation, we print more detailed evaluation statistics,\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy_pitch'])\n",
    "plt.plot(history['val_accuracy_ks'])\n",
    "plt.legend(['training loss', 'training accuracy', 'validation_accuracy_pitch','validation_accuracy_ks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best working model on the accuracy\n",
    "max_accuracy = np.max(history['val_accuracy_pitch'])\n",
    "best_epoch = np.argmax(history['val_accuracy_pitch'])\n",
    "print(\"Best validation accuracy: \",max_accuracy, \"at epoch\",best_epoch)\n",
    "\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy_pitch'])\n",
    "plt.plot(history['val_accuracy_ks'])\n",
    "plt.legend(['training loss', 'training accuracy', 'validation_accuracy_pitch','validation_accuracy_ks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tTv2BrGbvSHh",
    "outputId": "801ff32d-24dc-4434-a436-17d9ca832214"
   },
   "outputs": [],
   "source": [
    "# torch.save(model, \"./models/model_asap_crf200dur.pkl\")\n",
    "# files.download(\"model_asap_crf300.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXcmLpCKt28l"
   },
   "source": [
    "## Test on Mdata dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load(\"./models/model_RNNks.pkl\")\n",
    "model = torch.load(\"./models/temp/model_temp_epoch6.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset_path, device=None):\n",
    "    # load the dataset\n",
    "    with open(dataset_path, 'rb') as fid:\n",
    "        full_mdata_dict_dataset = pickle.load( fid)\n",
    "            \n",
    "    # add dummy ks to have the same format as asap\n",
    "    for e in full_mdata_dict_dataset:\n",
    "        e[\"key_signatures\"] = np.zeros(len(e[\"pitches\"]))\n",
    "    mdata_paths = list(set([e[\"original_path\"] for e in full_mdata_dict_dataset ]))\n",
    "\n",
    "    # # remove the symbphony No.100 from Haydn because of the enharmonic transposition\n",
    "    # paths.remove(\"datasets\\\\opnd\\\\haydndoversyms-10004m.opnd-m\")\n",
    "\n",
    "    # print(paths)\n",
    "    print(len(mdata_paths), \"different pieces\")\n",
    "    print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_mdata_dict_dataset ]))\n",
    "    \n",
    "    mdata_dataset = PSDataset(full_mdata_dict_dataset,mdata_paths, transform_chrom,transform_diat,transform_key,sort=False, augment_dataset=False)\n",
    "    mdata_dataloader = DataLoader(mdata_dataset,  batch_size=2, shuffle=False, collate_fn=pad_collate)\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    all_inputs = []\n",
    "    all_predicted_pitch = []\n",
    "    all_predicted_ks = []\n",
    "    all_pitches = []\n",
    "    all_ks = []\n",
    "    model.eval() # Evaluation mode (e.g. disable dropout)\n",
    "    with torch.no_grad(): # Disable gradient tracking\n",
    "        for seqs, pitches,ks,lens in mdata_dataloader:\n",
    "            # Move data to device\n",
    "            seqs = seqs.to(device)\n",
    "\n",
    "            # Predict the model's output on a batch.\n",
    "            predicted_pitch,predicted_ks = model.predict(seqs,lens)                   \n",
    "            # Update the evaluation statistics.\n",
    "            for i,p in enumerate(predicted_pitch):\n",
    "                all_inputs.append(torch.argmax(seqs[0:int(lens[i]),i,:].cpu(),1).numpy())\n",
    "                all_predicted_pitch.append(p)\n",
    "                all_predicted_ks.append(predicted_ks[i])\n",
    "                all_pitches.append(pitches[0:int(lens[i]),i])\n",
    "                all_ks.append(ks[0:int(lens[i]),i])\n",
    "\n",
    "    # Divide accuracy according to author\n",
    "    authors = []\n",
    "\n",
    "    for sequence in all_inputs:\n",
    "    #     print(sequence)\n",
    "        author = [e[\"original_path\"].split(\"\\\\\")[-1][:3] for e in full_mdata_dict_dataset\n",
    "                if len(e[\"midi_number\"]) == len(sequence) and\n",
    "                list(e[\"midi_number\"]) ==list(sequence) ]\n",
    "        assert len(author) == 1\n",
    "        authors.append(author[0])\n",
    "\n",
    "    considered_authors = list(set(authors))\n",
    "    print(considered_authors)\n",
    "\n",
    "    errors_per_author_pitch = {}\n",
    "    accuracy_per_author_pitch = {}\n",
    "    notes_per_author = {}\n",
    "    for ca in considered_authors:\n",
    "        ca_predicted_pitch = np.concatenate([all_predicted_pitch[i] for i,a in enumerate(authors) if a == ca])\n",
    "        ca_predicted_ks = np.concatenate([all_predicted_ks[i] for i,a in enumerate(authors) if a == ca])\n",
    "        ca_pitches = np.concatenate([all_pitches[i] for i,a in enumerate(authors) if a == ca])\n",
    "        ca_ks = np.concatenate([all_ks[i] for i,a in enumerate(authors) if a == ca])\n",
    "\n",
    "        ca_acc_pitch = accuracy_score(ca_predicted_pitch,ca_pitches)\n",
    "        \n",
    "        accuracy_per_author_pitch[ca] = float(ca_acc_pitch)\n",
    "        errors_per_author_pitch[ca] = int(len(ca_pitches) - sum(np.equal(ca_predicted_pitch,ca_pitches)))\n",
    "        notes_per_author[ca] = len(ca_pitches)\n",
    "\n",
    "    print(\"Pitch Statistics----------------\")\n",
    "    print(errors_per_author_pitch)\n",
    "    print(accuracy_per_author_pitch)\n",
    "    print(notes_per_author)\n",
    "    print(\"Total errors :\", sum([e for e in errors_per_author_pitch.values()]))\n",
    "    print(\"Error rate:\")\n",
    "    print({k:(1-accuracy_per_author_pitch[k])*100 for k in accuracy_per_author_pitch.keys() })\n",
    "\n",
    "    print(\"Total error rate:\", sum(errors_per_author_pitch.values())/sum(notes_per_author.values())*100 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "BacUqgD5usGL"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "216 different pieces\n",
      "Average number of notes:  907.2777777777778\n",
      "Using device: cuda\n",
      "['bee', 'hay', 'han', 'cor', 'moz', 'tel', 'viv', 'bac']\n",
      "Pitch Statistics----------------\n",
      "{'bee': 18817, 'hay': 19754, 'han': 20260, 'cor': 20139, 'moz': 19525, 'tel': 20154, 'viv': 20000, 'bac': 20699}\n",
      "{'bee': 0.23173968072510512, 'hay': 0.19338505512454063, 'han': 0.1730612244897959, 'cor': 0.17776507573592454, 'moz': 0.20286600800195967, 'tel': 0.17738775510204083, 'viv': 0.18357349879577092, 'bac': 0.15531524178739034}\n",
      "{'bee': 24493, 'hay': 24490, 'han': 24500, 'cor': 24493, 'moz': 24494, 'tel': 24500, 'viv': 24497, 'bac': 24505}\n",
      "Total errors : 159348\n",
      "Error rate:\n",
      "{'bee': 76.8260319274895, 'hay': 80.66149448754594, 'han': 82.6938775510204, 'cor': 82.22349242640755, 'moz': 79.71339919980403, 'tel': 82.26122448979592, 'viv': 81.64265012042291, 'bac': 84.46847582126097}\n",
      "Total error rate: 81.31161594513502\n"
     ]
    }
   ],
   "source": [
    "musedata_noisy_path = Path(basepath,'./datasets/musedata_noisy.pkl')\n",
    "evaluate(model, musedata_noisy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgNt_yG7vrfd",
    "outputId": "8473393f-dac6-4930-9d9e-da9c1046f1ab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5s0d56evrje"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVvP1eH8vrl3"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEst accuracy with ks\n",
    "n_epochs = 30\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 0.05\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 8\n",
    "MOMENTUM = 0.9\n",
    "RNN_LAYERS = 1\n",
    "\n",
    "model = RNNMultiTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,pitch_to_ix,ks_to_ix, n_layers =RNN_LAYERS)\n",
    "\n",
    "Model available in: \"\"./models/model_RNNks.pkl\"\"\n",
    "accuracy on validation set 0.9424\n",
    "Trained on all asap dataset\n",
    "\n",
    "{'cor': 4, 'viv': 29, 'moz': 70, 'bac': 13, 'han': 15, 'bee': 99, 'hay': 273, 'tel': 8}\n",
    "{'cor': 0.9998366880333156, 'viv': 0.9988161815732539, 'moz': 0.9971421572630031, 'bac': 0.9994694960212201, 'han': 0.9993877551020408, 'bee': 0.9959580288245621, 'hay': 0.9888525928950592, 'tel': 0.9996734693877551}\n",
    "{'cor': 24493, 'viv': 24497, 'moz': 24494, 'bac': 24505, 'han': 24500, 'bee': 24493, 'hay': 24490, 'tel': 24500}\n",
    "Total errors : 511\n",
    "\n",
    "\n",
    "Epoch 22: train loss = 0.4723, train_accuracy: 0.9533,val_accuracy_pitch: 0.9424,val_accuracy_ks: 0.7938, time = 106.7093\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOTDh55Hh2OWCo66dGc+SES",
   "include_colab_link": true,
   "name": "rnncrf_pitch_spelling",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('dl': venv)",
   "language": "python",
   "name": "python38364bitdlvenv228eca0427fb4ce49e2cb1133db5536b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}