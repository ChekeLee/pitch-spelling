{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fosfrancesco/pitch-spelling/blob/main/rnncrf_pitch_spelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fifMg_hxNSOg",
    "outputId": "a8b320f9-4231-40d9-8f10-a7b8acd1da37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-crf\n",
      "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hsciybUBNkur"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "import music21 as m21\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn\n",
    "import music21 as m21\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchcrf import CRF\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "# import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Naq6UG5jRbyK"
   },
   "source": [
    "# RNN-CRF for Pitch Spelling\n",
    "\n",
    "Dataset: different authors from ASAP collection\n",
    "Challenges:\n",
    "- extremely long sequences\n",
    "- small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mHJvrZ2Wo_e",
    "outputId": "1319f78b-cfb1-4e2a-937c-c47cf952757c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'C'), (1, 'B#'), (2, 'D--'), (3, 'C#'), (4, 'B##'), (5, 'D-'), (6, 'D'), (7, 'C##'), (8, 'E--'), (9, 'D#'), (10, 'E-'), (11, 'F--'), (12, 'E'), (13, 'D##'), (14, 'F-'), (15, 'F'), (16, 'E#'), (17, 'G--'), (18, 'F#'), (19, 'E##'), (20, 'G-'), (21, 'G'), (22, 'F##'), (23, 'A--'), (24, 'G#'), (25, 'A-'), (26, 'A'), (27, 'G##'), (28, 'B--'), (29, 'A#'), (30, 'B-'), (31, 'C--'), (32, 'B'), (33, 'A##'), (34, 'C-')]\n",
      "['D--', 'B##', 'C##', 'E--', 'F--', 'D##', 'G--', 'E##', 'F##', 'A--', 'G##', 'B--', 'C--', 'A##']\n",
      "[(0, 'P1'), (1, 'd2'), (2, 'A7'), (3, 'm2'), (4, 'A1'), (5, 'M2'), (6, 'd3'), (7, 'AA1'), (8, 'm3'), (9, 'A2'), (10, 'M3'), (11, 'd4'), (12, 'AA2'), (13, 'P4'), (14, 'A3'), (15, 'd5'), (16, 'A4'), (17, 'P5'), (18, 'd6'), (19, 'AA4'), (20, 'm6'), (21, 'A5'), (22, 'M6'), (23, 'd7'), (24, 'AA5'), (25, 'm7'), (26, 'A6'), (27, 'M7'), (28, 'd1'), (29, 'AA6')]\n"
     ]
    }
   ],
   "source": [
    "pitches_dict = {\n",
    "    0 : [\"C\",\"B#\",\"D--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    1 : [\"C#\",\"B##\",\"D-\"], # nn.Linear(input_size+context_size, 2)\n",
    "    2 : [\"D\",\"C##\",\"E--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    3 : [\"D#\",\"E-\",\"F--\"],\n",
    "    4 : [\"E\",\"D##\",\"F-\"],\n",
    "    5 : [\"F\",\"E#\",\"G--\"],\n",
    "    6 : [\"F#\",\"E##\",\"G-\"],\n",
    "    7 : [\"G\",\"F##\",\"A--\"],\n",
    "    8 : [\"G#\",\"A-\"],\n",
    "    9 : [\"A\",\"G##\",\"B--\"],\n",
    "    10 : [\"A#\",\"B-\",\"C--\"],\n",
    "    11 : [\"B\",\"A##\",\"C-\"]\n",
    "}\n",
    "\n",
    "accepted_pitches = [ii for i in pitches_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_pitches)])\n",
    "\n",
    "double_acc_pitches = [ii for i in pitches_dict.values() for ii in i if ii.endswith(\"##\") or  ii.endswith(\"--\") ]\n",
    "print(double_acc_pitches)\n",
    "\n",
    "def score2midi_numbers(score):\n",
    "    return [p.midi%12 for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "def score2pitches(score):\n",
    "    return [p.name for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "interval_dict = {\n",
    "    0 : [\"P1\",\"d2\",\"A7\"], \n",
    "    1 : [\"m2\",\"A1\"], \n",
    "    2 : [\"M2\",\"d3\",\"AA1\"], \n",
    "    3 : [\"m3\",\"A2\"],\n",
    "    4 : [\"M3\",\"d4\",\"AA2\"],\n",
    "    5 : [\"P4\",\"A3\"],\n",
    "    6 : [\"d5\",\"A4\"],\n",
    "    7 : [\"P5\",\"d6\",\"AA4\"],\n",
    "    8 : [\"m6\",\"A5\"],\n",
    "    9 : [\"M6\",\"d7\",\"AA5\"],\n",
    "    10 : [\"m7\",\"A6\"],\n",
    "    11 : [\"M7\",\"d1\",\"AA6\"]\n",
    "}\n",
    "\n",
    "accepted_intervals = [ii for i in interval_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_intervals)])\n",
    "\n",
    "def transp_score(score):\n",
    "    \"\"\" For each input return len(accepted_intervals) transposed scores\"\"\"\n",
    "    return [score.transpose(interval) for interval in accepted_intervals]\n",
    "\n",
    "def smart_transp_score(score):\n",
    "    \"\"\" For each chromatic interval chose the interval that lead to the smallest number of accidentals\"\"\"\n",
    "    scores = []\n",
    "    for chromatic_int in interval_dict.keys():\n",
    "        temp_scores = []\n",
    "        temp_acc_number = []\n",
    "        for diat_interval in interval_dict[chromatic_int]:\n",
    "            new_score = score.transpose(diat_interval)\n",
    "            temp_scores.append(new_score)\n",
    "            temp_acc_number.append(sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in score2pitches(new_score)]))\n",
    "            # print(\"choice:\", [note.name for note in temp_scores[-1].flat.notes][0:10],\"acc:\",temp_acc_number[-1] )\n",
    "        #keep only the one with the lowest number of accidentals\n",
    "        min_index = np.argmin(temp_acc_number)\n",
    "        # print(\"preferred the number\", min_index)\n",
    "        scores.append(temp_scores[min_index])\n",
    "    return scores\n",
    "\n",
    "def acc_simple_enough(score,accepted_ratio = 0.2 ):\n",
    "    pitches = score2pitches(score)\n",
    "    double_acc = sum(el in double_acc_pitches for el in pitches)\n",
    "    if double_acc/len(pitches) < accepted_ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "diatonic_pitches = [\"C\",\"D\", \"E\", \"F\", \"G\", \"A\", \"B\"]\n",
    "\n",
    "# #test acc_simple_enough()\n",
    "# score = m21.converter.parse(paths[356])\n",
    "# scores = smart_transp_score(score)\n",
    "# #delete the pieces with non accepted pitches (e.g. triple sharps)\n",
    "# scores = [s for s in scores if all(pitch in accepted_pitches for pitch in score2pitches(s))]\n",
    "# for s in scores:\n",
    "#     print(s.parts[0].flat.getElementsByClass(m21.key.KeySignature)[0], \"simple enough:\", acc_simple_enough(s))\n",
    "#     print([n.name for n in s.flat.notes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw-SuL4ZB_2C"
   },
   "source": [
    "## Import ASAP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrZ0BwLEj2Gp",
    "outputId": "6b521f78-28db-4d4f-f4ef-9345c5d91db9"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/fosfrancesco/pitch-spelling.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WaINjDS2kpxE"
   },
   "outputs": [],
   "source": [
    "basepath = \"./\" #to change if running locally or on colab\n",
    "\n",
    "# load the asap datasets\n",
    "with open(Path(basepath,'datasets','baroque_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_baroque = pickle.load( fid)\n",
    "\n",
    "with open(Path(basepath,'datasets','classical_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_classical = pickle.load( fid)\n",
    "\n",
    "with open(Path(basepath,'datasets','romantic_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_romantic = pickle.load( fid)\n",
    "        \n",
    "with open(Path(basepath,'datasets','remaining_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_remaining = pickle.load( fid)\n",
    "\n",
    "# merge the three files together\n",
    "full_dict_dataset = dataset_baroque + dataset_classical + dataset_romantic + dataset_remaining\n",
    "# full_dict_dataset = dataset_baroque + dataset_classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYQdkJAiTS6_",
    "outputId": "72835948-2884-40bb-e5b4-6ebbc8488895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 different pieces\n",
      "Average number of notes:  2410.253424657534\n"
     ]
    }
   ],
   "source": [
    "paths = list(set([e[\"original_path\"] for e in full_dict_dataset ]))\n",
    "\n",
    "# print(paths)\n",
    "print(len(paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_dict_dataset ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMdKkzNnCTrK"
   },
   "source": [
    "## Chose the convenient data augmentation\n",
    "Two possibilities:\n",
    "- for each chromatic interval, take only the diatonic transposition that produce the smallest number of accidentals (or the original if present)\n",
    "- take only a certain interval of time signatures\n",
    "\n",
    "The second is probably better for a smaller and simple dataset, but gives the problem of chosing between for example F# and G# that are both present in this bigger dataset. So we go for the first criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oign7EZ9BSX4",
    "outputId": "9aa3f694-289a-43fd-fd14-9cad3b8dd3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No options for Scriabin/Sonatas/5/xml_score.musicxml . Chromatic:  1\n",
      "No options for Scriabin/Sonatas/5/xml_score.musicxml . Chromatic:  6\n",
      "No options for Scriabin/Sonatas/5/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Ballades/4/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  1\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  3\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  8\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  10\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml . Chromatic:  1\n",
      "No options for Liszt/Transcendental_Etudes/9/xml_score.musicxml . Chromatic:  6\n",
      "No options for Liszt/Transcendental_Etudes/9/xml_score.musicxml . Chromatic:  11\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  1\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  4\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  6\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  9\n",
      "No options for Balakirev/Islamey/xml_score.musicxml . Chromatic:  11\n",
      "No options for Liszt/Transcendental_Etudes/4/xml_score.musicxml . Chromatic:  2\n",
      "No options for Liszt/Transcendental_Etudes/4/xml_score.musicxml . Chromatic:  4\n",
      "No options for Liszt/Transcendental_Etudes/4/xml_score.musicxml . Chromatic:  9\n",
      "No options for Ravel/Miroirs/4_Alborada_del_gracioso/xml_score.musicxml . Chromatic:  11\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  1\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  4\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  6\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  9\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  11\n",
      "No options for Liszt/Transcendental_Etudes/10/xml_score.musicxml . Chromatic:  1\n",
      "No options for Liszt/Transcendental_Etudes/10/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  9\n",
      "No options for Debussy/Images_Book_1/1_Reflets_dans_lEau/xml_score.musicxml . Chromatic:  3\n",
      "No options for Debussy/Images_Book_1/1_Reflets_dans_lEau/xml_score.musicxml . Chromatic:  8\n",
      "No options for Ravel/Gaspard_de_la_Nuit/1_Ondine/xml_score.musicxml . Chromatic:  4\n",
      "No options for Liszt/Transcendental_Etudes/11/xml_score.musicxml . Chromatic:  1\n",
      "No options for Liszt/Transcendental_Etudes/11/xml_score.musicxml . Chromatic:  6\n",
      "No options for Liszt/Sonata/xml_score.musicxml . Chromatic:  4\n",
      "No options for Liszt/Sonata/xml_score.musicxml . Chromatic:  6\n",
      "No options for Liszt/Sonata/xml_score.musicxml . Chromatic:  11\n",
      "No options for Liszt/Mephisto_Waltz/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  9\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml P1 -1\n",
      "['F', 'F', 'C', 'A', 'A', 'G', 'A', 'C', 'C', 'F']\n",
      "[5, 5, 0, 9, 9, 7, 9, 0, 0, 5]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml m2 -6\n",
      "['G-', 'G-', 'D-', 'B-', 'B-', 'A-', 'B-', 'D-', 'D-', 'G-']\n",
      "[6, 6, 1, 10, 10, 8, 10, 1, 1, 6]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml M2 1\n",
      "['G', 'G', 'D', 'B', 'B', 'A', 'B', 'D', 'D', 'G']\n",
      "[7, 7, 2, 11, 11, 9, 11, 2, 2, 7]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml m3 -4\n",
      "['A-', 'A-', 'E-', 'C', 'C', 'B-', 'C', 'E-', 'E-', 'A-']\n",
      "[8, 8, 3, 0, 0, 10, 0, 3, 3, 8]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml M3 3\n",
      "['A', 'A', 'E', 'C#', 'C#', 'B', 'C#', 'E', 'E', 'A']\n",
      "[9, 9, 4, 1, 1, 11, 1, 4, 4, 9]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml P4 -2\n",
      "['B-', 'B-', 'F', 'D', 'D', 'C', 'D', 'F', 'F', 'B-']\n",
      "[10, 10, 5, 2, 2, 0, 2, 5, 5, 10]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml A4 5\n",
      "['B', 'B', 'F#', 'D#', 'D#', 'C#', 'D#', 'F#', 'F#', 'B']\n",
      "[11, 11, 6, 3, 3, 1, 3, 6, 6, 11]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml P5 0\n",
      "['C', 'C', 'G', 'E', 'E', 'D', 'E', 'G', 'G', 'C']\n",
      "[0, 0, 7, 4, 4, 2, 4, 7, 7, 0]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml m6 -5\n",
      "['D-', 'D-', 'A-', 'F', 'F', 'E-', 'F', 'A-', 'A-', 'D-']\n",
      "[1, 1, 8, 5, 5, 3, 5, 8, 8, 1]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml M6 2\n",
      "['D', 'D', 'A', 'F#', 'F#', 'E', 'F#', 'A', 'A', 'D']\n",
      "[2, 2, 9, 6, 6, 4, 6, 9, 9, 2]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml m7 -3\n",
      "['E-', 'E-', 'B-', 'G', 'G', 'F', 'G', 'B-', 'B-', 'E-']\n",
      "[3, 3, 10, 7, 7, 5, 7, 10, 10, 3]\n",
      "Bach/Prelude/bwv_856/xml_score.musicxml M7 4\n",
      "['E', 'E', 'B', 'G#', 'G#', 'F#', 'G#', 'B', 'B', 'E']\n",
      "[4, 4, 11, 8, 8, 6, 8, 11, 11, 4]\n",
      "Bach/Fugue/bwv_893/xml_score.musicxml P1 2\n",
      "['F#', 'D', 'B', 'A#', 'B', 'C#', 'D', 'E', 'F#', 'G']\n",
      "[6, 2, 11, 10, 11, 1, 2, 4, 6, 7]\n",
      "Bach/Fugue/bwv_893/xml_score.musicxml m2 -3\n",
      "['G', 'E-', 'C', 'B', 'C', 'D', 'E-', 'F', 'G', 'A-']\n",
      "[7, 3, 0, 11, 0, 2, 3, 5, 7, 8]\n",
      "Bach/Fugue/bwv_893/xml_score.musicxml M2 4\n",
      "['G#', 'E', 'C#', 'B#', 'C#', 'D#', 'E', 'F#', 'G#', 'A']\n",
      "[8, 4, 1, 0, 1, 3, 4, 6, 8, 9]\n",
      "Bach/Fugue/bwv_893/xml_score.musicxml m3 -1\n",
      "['A', 'F', 'D', 'C#', 'D', 'E', 'F', 'G', 'A', 'B-']\n",
      "[9, 5, 2, 1, 2, 4, 5, 7, 9, 10]\n",
      "Bach/Fugue/bwv_893/xml_score.musicxml d4 -6\n",
      "['B-', 'G-', 'E-', 'D', 'E-', 'F', 'G-', 'A-', 'B-', 'C-']\n",
      "[10, 6, 3, 2, 3, 5, 6, 8, 10, 11]\n",
      "Bach/Fugue/bwv_893/xml_score.musicxml P4 1\n",
      "['B', 'G', 'E', 'D#', 'E', 'F#', 'G', 'A', 'B', 'C']\n",
      "[11, 7, 4, 3, 4, 6, 7, 9, 11, 0]\n",
      "Bach/Fugue/bwv_893/xml_score.musicxml d5 -4\n",
      "['C', 'A-', 'F', 'E', 'F', 'G', 'A-', 'B-', 'C', 'D-']\n",
      "[0, 8, 5, 4, 5, 7, 8, 10, 0, 1]\n",
      "Bach/Fugue/bwv_893/xml_score.musicxml P5 3\n",
      "['C#', 'A', 'F#', 'E#', 'F#', 'G#', 'A', 'B', 'C#', 'D']\n",
      "[1, 9, 6, 5, 6, 8, 9, 11, 1, 2]\n",
      "Bach/Fugue/bwv_893/xml_score.musicxml m6 -2\n",
      "['D', 'B-', 'G', 'F#', 'G', 'A', 'B-', 'C', 'D', 'E-']\n",
      "[2, 10, 7, 6, 7, 9, 10, 0, 2, 3]\n",
      "Bach/Fugue/bwv_893/xml_score.musicxml M6 5\n",
      "['D#', 'B', 'G#', 'F##', 'G#', 'A#', 'B', 'C#', 'D#', 'E']\n",
      "[3, 11, 8, 7, 8, 10, 11, 1, 3, 4]\n",
      "Bach/Fugue/bwv_893/xml_score.musicxml m7 0\n",
      "['E', 'C', 'A', 'G#', 'A', 'B', 'C', 'D', 'E', 'F']\n",
      "[4, 0, 9, 8, 9, 11, 0, 2, 4, 5]\n",
      "Bach/Fugue/bwv_893/xml_score.musicxml d1 -5\n",
      "['F', 'D-', 'B-', 'A', 'B-', 'C', 'D-', 'E-', 'F', 'G-']\n",
      "[5, 1, 10, 9, 10, 0, 1, 3, 5, 6]\n",
      "Debussy/Pour_le_Piano/1/xml_score.musicxml P1 0\n",
      "['A', 'A', 'C', 'E', 'C', 'A', 'A', 'C', 'E', 'A']\n",
      "[9, 9, 0, 4, 0, 9, 9, 0, 4, 9]\n",
      "Debussy/Pour_le_Piano/1/xml_score.musicxml m2 -5\n",
      "['B-', 'B-', 'D-', 'F', 'D-', 'B-', 'B-', 'D-', 'F', 'B-']\n",
      "[10, 10, 1, 5, 1, 10, 10, 1, 5, 10]\n",
      "Debussy/Pour_le_Piano/1/xml_score.musicxml M2 2\n",
      "['B', 'B', 'D', 'F#', 'D', 'B', 'B', 'D', 'F#', 'B']\n",
      "[11, 11, 2, 6, 2, 11, 11, 2, 6, 11]\n",
      "Debussy/Pour_le_Piano/1/xml_score.musicxml m3 -3\n",
      "['C', 'C', 'E-', 'G', 'E-', 'C', 'C', 'E-', 'G', 'C']\n",
      "[0, 0, 3, 7, 3, 0, 0, 3, 7, 0]\n",
      "Debussy/Pour_le_Piano/1/xml_score.musicxml M3 4\n",
      "['C#', 'C#', 'E', 'G#', 'E', 'C#', 'C#', 'E', 'G#', 'C#']\n",
      "[1, 1, 4, 8, 4, 1, 1, 4, 8, 1]\n",
      "Debussy/Pour_le_Piano/1/xml_score.musicxml P4 -1\n",
      "['D', 'D', 'F', 'A', 'F', 'D', 'D', 'F', 'A', 'D']\n",
      "[2, 2, 5, 9, 5, 2, 2, 5, 9, 2]\n",
      "Debussy/Pour_le_Piano/1/xml_score.musicxml A4 6\n",
      "['D#', 'D#', 'F#', 'A#', 'F#', 'D#', 'D#', 'F#', 'A#', 'D#']\n",
      "[3, 3, 6, 10, 6, 3, 3, 6, 10, 3]\n",
      "Debussy/Pour_le_Piano/1/xml_score.musicxml P5 1\n",
      "['E', 'E', 'G', 'B', 'G', 'E', 'E', 'G', 'B', 'E']\n",
      "[4, 4, 7, 11, 7, 4, 4, 7, 11, 4]\n",
      "Debussy/Pour_le_Piano/1/xml_score.musicxml m6 -4\n",
      "['F', 'F', 'A-', 'C', 'A-', 'F', 'F', 'A-', 'C', 'F']\n",
      "[5, 5, 8, 0, 8, 5, 5, 8, 0, 5]\n",
      "Debussy/Pour_le_Piano/1/xml_score.musicxml M6 3\n",
      "['F#', 'F#', 'A', 'C#', 'A', 'F#', 'F#', 'A', 'C#', 'F#']\n",
      "[6, 6, 9, 1, 9, 6, 6, 9, 1, 6]\n",
      "Debussy/Pour_le_Piano/1/xml_score.musicxml m7 -2\n",
      "['G', 'G', 'B-', 'D', 'B-', 'G', 'G', 'B-', 'D', 'G']\n",
      "[7, 7, 10, 2, 10, 7, 7, 10, 2, 7]\n",
      "Debussy/Pour_le_Piano/1/xml_score.musicxml M7 5\n",
      "['G#', 'G#', 'B', 'D#', 'B', 'G#', 'G#', 'B', 'D#', 'G#']\n",
      "[8, 8, 11, 3, 11, 8, 8, 11, 3, 8]\n",
      "Schubert/Impromptu_op.90_D.899/1/xml_score.musicxml P1 -3\n",
      "['G', 'G', 'G', 'G', 'B', 'C', 'D', 'D', 'D', 'C']\n",
      "[7, 7, 7, 7, 11, 0, 2, 2, 2, 0]\n",
      "Schubert/Impromptu_op.90_D.899/1/xml_score.musicxml A1 4\n",
      "['G#', 'G#', 'G#', 'G#', 'B#', 'C#', 'D#', 'D#', 'D#', 'C#']\n",
      "[8, 8, 8, 8, 0, 1, 3, 3, 3, 1]\n",
      "Schubert/Impromptu_op.90_D.899/1/xml_score.musicxml M2 -1\n",
      "['A', 'A', 'A', 'A', 'C#', 'D', 'E', 'E', 'E', 'D']\n",
      "[9, 9, 9, 9, 1, 2, 4, 4, 4, 2]\n",
      "Schubert/Impromptu_op.90_D.899/1/xml_score.musicxml m3 -6\n",
      "['B-', 'B-', 'B-', 'B-', 'D', 'E-', 'F', 'F', 'F', 'E-']\n",
      "[10, 10, 10, 10, 2, 3, 5, 5, 5, 3]\n",
      "Schubert/Impromptu_op.90_D.899/1/xml_score.musicxml M3 1\n",
      "['B', 'B', 'B', 'B', 'D#', 'E', 'F#', 'F#', 'F#', 'E']\n",
      "[11, 11, 11, 11, 3, 4, 6, 6, 6, 4]\n",
      "Schubert/Impromptu_op.90_D.899/1/xml_score.musicxml P4 -4\n",
      "['C', 'C', 'C', 'C', 'E', 'F', 'G', 'G', 'G', 'F']\n",
      "[0, 0, 0, 0, 4, 5, 7, 7, 7, 5]\n",
      "Schubert/Impromptu_op.90_D.899/1/xml_score.musicxml A4 3\n",
      "['C#', 'C#', 'C#', 'C#', 'E#', 'F#', 'G#', 'G#', 'G#', 'F#']\n",
      "[1, 1, 1, 1, 5, 6, 8, 8, 8, 6]\n",
      "Schubert/Impromptu_op.90_D.899/1/xml_score.musicxml P5 -2\n",
      "['D', 'D', 'D', 'D', 'F#', 'G', 'A', 'A', 'A', 'G']\n",
      "[2, 2, 2, 2, 6, 7, 9, 9, 9, 7]\n",
      "Schubert/Impromptu_op.90_D.899/1/xml_score.musicxml A5 5\n",
      "['D#', 'D#', 'D#', 'D#', 'F##', 'G#', 'A#', 'A#', 'A#', 'G#']\n",
      "[3, 3, 3, 3, 7, 8, 10, 10, 10, 8]\n",
      "Schubert/Impromptu_op.90_D.899/1/xml_score.musicxml M6 0\n",
      "['E', 'E', 'E', 'E', 'G#', 'A', 'B', 'B', 'B', 'A']\n",
      "[4, 4, 4, 4, 8, 9, 11, 11, 11, 9]\n",
      "Schubert/Impromptu_op.90_D.899/1/xml_score.musicxml m7 -5\n",
      "['F', 'F', 'F', 'F', 'A', 'B-', 'C', 'C', 'C', 'B-']\n",
      "[5, 5, 5, 5, 9, 10, 0, 0, 0, 10]\n",
      "Schubert/Impromptu_op.90_D.899/1/xml_score.musicxml M7 2\n",
      "['F#', 'F#', 'F#', 'F#', 'A#', 'B', 'C#', 'C#', 'C#', 'B']\n",
      "[6, 6, 6, 6, 10, 11, 1, 1, 1, 11]\n",
      "Schubert/Piano_Sonatas/664-1/xml_score.musicxml P1 3\n",
      "['C#', 'D', 'E', 'C#', 'A', 'A', 'A', 'C#', 'E', 'A']\n",
      "[1, 2, 4, 1, 9, 9, 9, 1, 4, 9]\n",
      "Schubert/Piano_Sonatas/664-1/xml_score.musicxml m2 -2\n",
      "['D', 'E-', 'F', 'D', 'B-', 'B-', 'B-', 'D', 'F', 'B-']\n",
      "[2, 3, 5, 2, 10, 10, 10, 2, 5, 10]\n",
      "Schubert/Piano_Sonatas/664-1/xml_score.musicxml M2 5\n",
      "['D#', 'E', 'F#', 'D#', 'B', 'B', 'B', 'D#', 'F#', 'B']\n",
      "[3, 4, 6, 3, 11, 11, 11, 3, 6, 11]\n",
      "Schubert/Piano_Sonatas/664-1/xml_score.musicxml m3 0\n",
      "['E', 'F', 'G', 'E', 'C', 'C', 'C', 'E', 'G', 'C']\n",
      "[4, 5, 7, 4, 0, 0, 0, 4, 7, 0]\n",
      "Schubert/Piano_Sonatas/664-1/xml_score.musicxml d4 -5\n",
      "['F', 'G-', 'A-', 'F', 'D-', 'D-', 'D-', 'F', 'A-', 'D-']\n",
      "[5, 6, 8, 5, 1, 1, 1, 5, 8, 1]\n",
      "Schubert/Piano_Sonatas/664-1/xml_score.musicxml P4 2\n",
      "['F#', 'G', 'A', 'F#', 'D', 'D', 'D', 'F#', 'A', 'D']\n",
      "[6, 7, 9, 6, 2, 2, 2, 6, 9, 2]\n",
      "Schubert/Piano_Sonatas/664-1/xml_score.musicxml d5 -3\n",
      "['G', 'A-', 'B-', 'G', 'E-', 'E-', 'E-', 'G', 'B-', 'E-']\n",
      "[7, 8, 10, 7, 3, 3, 3, 7, 10, 3]\n",
      "Schubert/Piano_Sonatas/664-1/xml_score.musicxml P5 4\n",
      "['G#', 'A', 'B', 'G#', 'E', 'E', 'E', 'G#', 'B', 'E']\n",
      "[8, 9, 11, 8, 4, 4, 4, 8, 11, 4]\n",
      "Schubert/Piano_Sonatas/664-1/xml_score.musicxml m6 -1\n",
      "['A', 'B-', 'C', 'A', 'F', 'F', 'F', 'A', 'C', 'F']\n",
      "[9, 10, 0, 9, 5, 5, 5, 9, 0, 5]\n",
      "Schubert/Piano_Sonatas/664-1/xml_score.musicxml d7 -6\n",
      "['B-', 'C-', 'D-', 'B-', 'G-', 'G-', 'G-', 'B-', 'D-', 'G-']\n",
      "[10, 11, 1, 10, 6, 6, 6, 10, 1, 6]\n",
      "Schubert/Piano_Sonatas/664-1/xml_score.musicxml m7 1\n",
      "['B', 'C', 'D', 'B', 'G', 'G', 'G', 'B', 'D', 'G']\n",
      "[11, 0, 2, 11, 7, 7, 7, 11, 2, 7]\n",
      "Schubert/Piano_Sonatas/664-1/xml_score.musicxml d1 -4\n",
      "['C', 'D-', 'E-', 'C', 'A-', 'A-', 'A-', 'C', 'E-', 'A-']\n",
      "[0, 1, 3, 0, 8, 8, 8, 0, 3, 8]\n",
      "Bach/Prelude/bwv_888/xml_score.musicxml P1 3\n",
      "['E', 'A', 'A', 'G#', 'E', 'A', 'C#', 'C#', 'B', 'E']\n",
      "[4, 9, 9, 8, 4, 9, 1, 1, 11, 4]\n",
      "Bach/Prelude/bwv_888/xml_score.musicxml m2 -2\n",
      "['F', 'B-', 'B-', 'A', 'F', 'B-', 'D', 'D', 'C', 'F']\n",
      "[5, 10, 10, 9, 5, 10, 2, 2, 0, 5]\n",
      "Bach/Prelude/bwv_888/xml_score.musicxml M2 5\n",
      "['F#', 'B', 'B', 'A#', 'F#', 'B', 'D#', 'D#', 'C#', 'F#']\n",
      "[6, 11, 11, 10, 6, 11, 3, 3, 1, 6]\n",
      "Bach/Prelude/bwv_888/xml_score.musicxml m3 0\n",
      "['G', 'C', 'C', 'B', 'G', 'C', 'E', 'E', 'D', 'G']\n",
      "[7, 0, 0, 11, 7, 0, 4, 4, 2, 7]\n",
      "Bach/Prelude/bwv_888/xml_score.musicxml d4 -5\n",
      "['A-', 'D-', 'D-', 'C', 'A-', 'D-', 'F', 'F', 'E-', 'A-']\n",
      "[8, 1, 1, 0, 8, 1, 5, 5, 3, 8]\n",
      "Bach/Prelude/bwv_888/xml_score.musicxml P4 2\n",
      "['A', 'D', 'D', 'C#', 'A', 'D', 'F#', 'F#', 'E', 'A']\n",
      "[9, 2, 2, 1, 9, 2, 6, 6, 4, 9]\n",
      "Bach/Prelude/bwv_888/xml_score.musicxml d5 -3\n",
      "['B-', 'E-', 'E-', 'D', 'B-', 'E-', 'G', 'G', 'F', 'B-']\n",
      "[10, 3, 3, 2, 10, 3, 7, 7, 5, 10]\n",
      "Bach/Prelude/bwv_888/xml_score.musicxml P5 4\n",
      "['B', 'E', 'E', 'D#', 'B', 'E', 'G#', 'G#', 'F#', 'B']\n",
      "[11, 4, 4, 3, 11, 4, 8, 8, 6, 11]\n",
      "Bach/Prelude/bwv_888/xml_score.musicxml m6 -1\n",
      "['C', 'F', 'F', 'E', 'C', 'F', 'A', 'A', 'G', 'C']\n",
      "[0, 5, 5, 4, 0, 5, 9, 9, 7, 0]\n",
      "Bach/Prelude/bwv_888/xml_score.musicxml M6 6\n",
      "['C#', 'F#', 'F#', 'E#', 'C#', 'F#', 'A#', 'A#', 'G#', 'C#']\n",
      "[1, 6, 6, 5, 1, 6, 10, 10, 8, 1]\n",
      "Bach/Prelude/bwv_888/xml_score.musicxml m7 1\n",
      "['D', 'G', 'G', 'F#', 'D', 'G', 'B', 'B', 'A', 'D']\n",
      "[2, 7, 7, 6, 2, 7, 11, 11, 9, 2]\n",
      "Bach/Prelude/bwv_888/xml_score.musicxml d1 -4\n",
      "['E-', 'A-', 'A-', 'G', 'E-', 'A-', 'C', 'C', 'B-', 'E-']\n",
      "[3, 8, 8, 7, 3, 8, 0, 0, 10, 3]\n",
      "Bach/Fugue/bwv_860/xml_score.musicxml P1 1\n",
      "['G', 'A', 'G', 'F#', 'G', 'A', 'B', 'A', 'G', 'A']\n",
      "[7, 9, 7, 6, 7, 9, 11, 9, 7, 9]\n",
      "Bach/Fugue/bwv_860/xml_score.musicxml m2 -4\n",
      "['A-', 'B-', 'A-', 'G', 'A-', 'B-', 'C', 'B-', 'A-', 'B-']\n",
      "[8, 10, 8, 7, 8, 10, 0, 10, 8, 10]\n",
      "Bach/Fugue/bwv_860/xml_score.musicxml M2 3\n",
      "['A', 'B', 'A', 'G#', 'A', 'B', 'C#', 'B', 'A', 'B']\n",
      "[9, 11, 9, 8, 9, 11, 1, 11, 9, 11]\n",
      "Bach/Fugue/bwv_860/xml_score.musicxml m3 -2\n",
      "['B-', 'C', 'B-', 'A', 'B-', 'C', 'D', 'C', 'B-', 'C']\n",
      "[10, 0, 10, 9, 10, 0, 2, 0, 10, 0]\n",
      "Bach/Fugue/bwv_860/xml_score.musicxml M3 5\n",
      "['B', 'C#', 'B', 'A#', 'B', 'C#', 'D#', 'C#', 'B', 'C#']\n",
      "[11, 1, 11, 10, 11, 1, 3, 1, 11, 1]\n",
      "Bach/Fugue/bwv_860/xml_score.musicxml P4 0\n",
      "['C', 'D', 'C', 'B', 'C', 'D', 'E', 'D', 'C', 'D']\n",
      "[0, 2, 0, 11, 0, 2, 4, 2, 0, 2]\n",
      "Bach/Fugue/bwv_860/xml_score.musicxml d5 -5\n",
      "['D-', 'E-', 'D-', 'C', 'D-', 'E-', 'F', 'E-', 'D-', 'E-']\n",
      "[1, 3, 1, 0, 1, 3, 5, 3, 1, 3]\n",
      "Bach/Fugue/bwv_860/xml_score.musicxml P5 2\n",
      "['D', 'E', 'D', 'C#', 'D', 'E', 'F#', 'E', 'D', 'E']\n",
      "[2, 4, 2, 1, 2, 4, 6, 4, 2, 4]\n",
      "Bach/Fugue/bwv_860/xml_score.musicxml m6 -3\n",
      "['E-', 'F', 'E-', 'D', 'E-', 'F', 'G', 'F', 'E-', 'F']\n",
      "[3, 5, 3, 2, 3, 5, 7, 5, 3, 5]\n",
      "Bach/Fugue/bwv_860/xml_score.musicxml M6 4\n",
      "['E', 'F#', 'E', 'D#', 'E', 'F#', 'G#', 'F#', 'E', 'F#']\n",
      "[4, 6, 4, 3, 4, 6, 8, 6, 4, 6]\n",
      "Bach/Fugue/bwv_860/xml_score.musicxml m7 -1\n",
      "['F', 'G', 'F', 'E', 'F', 'G', 'A', 'G', 'F', 'G']\n",
      "[5, 7, 5, 4, 5, 7, 9, 7, 5, 7]\n",
      "Bach/Fugue/bwv_860/xml_score.musicxml d1 -6\n",
      "['G-', 'A-', 'G-', 'F', 'G-', 'A-', 'B-', 'A-', 'G-', 'A-']\n",
      "[6, 8, 6, 5, 6, 8, 10, 8, 6, 8]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml P1 -2\n",
      "['D', 'B-', 'D', 'D', 'F', 'B-', 'D', 'D', 'B-', 'D']\n",
      "[2, 10, 2, 2, 5, 10, 2, 2, 10, 2]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml A1 5\n",
      "['D#', 'B', 'D#', 'D#', 'F#', 'B', 'D#', 'D#', 'B', 'D#']\n",
      "[3, 11, 3, 3, 6, 11, 3, 3, 11, 3]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml M2 0\n",
      "['E', 'C', 'E', 'E', 'G', 'C', 'E', 'E', 'C', 'E']\n",
      "[4, 0, 4, 4, 7, 0, 4, 4, 0, 4]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml m3 -5\n",
      "['F', 'D-', 'F', 'F', 'A-', 'D-', 'F', 'F', 'D-', 'F']\n",
      "[5, 1, 5, 5, 8, 1, 5, 5, 1, 5]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml M3 2\n",
      "['F#', 'D', 'F#', 'F#', 'A', 'D', 'F#', 'F#', 'D', 'F#']\n",
      "[6, 2, 6, 6, 9, 2, 6, 6, 2, 6]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml P4 -3\n",
      "['G', 'E-', 'G', 'G', 'B-', 'E-', 'G', 'G', 'E-', 'G']\n",
      "[7, 3, 7, 7, 10, 3, 7, 7, 3, 7]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml A4 4\n",
      "['G#', 'E', 'G#', 'G#', 'B', 'E', 'G#', 'G#', 'E', 'G#']\n",
      "[8, 4, 8, 8, 11, 4, 8, 8, 4, 8]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml P5 -1\n",
      "['A', 'F', 'A', 'A', 'C', 'F', 'A', 'A', 'F', 'A']\n",
      "[9, 5, 9, 9, 0, 5, 9, 9, 5, 9]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml A5 6\n",
      "['A#', 'F#', 'A#', 'A#', 'C#', 'F#', 'A#', 'A#', 'F#', 'A#']\n",
      "[10, 6, 10, 10, 1, 6, 10, 10, 6, 10]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml M6 1\n",
      "['B', 'G', 'B', 'B', 'D', 'G', 'B', 'B', 'G', 'B']\n",
      "[11, 7, 11, 11, 2, 7, 11, 11, 7, 11]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml m7 -4\n",
      "['C', 'A-', 'C', 'C', 'E-', 'A-', 'C', 'C', 'A-', 'C']\n",
      "[0, 8, 0, 0, 3, 8, 0, 0, 8, 0]\n",
      "Schubert/Impromptu_op142/3/xml_score.musicxml M7 3\n",
      "['C#', 'A', 'C#', 'C#', 'E', 'A', 'C#', 'C#', 'A', 'C#']\n",
      "[1, 9, 1, 1, 4, 9, 1, 1, 9, 1]\n",
      "Liszt/Transcendental_Etudes/1/xml_score.musicxml P1 0\n",
      "['C', 'C', 'C', 'C', 'C', 'C', 'C', 'G', 'B-', 'E']\n",
      "[0, 0, 0, 0, 0, 0, 0, 7, 10, 4]\n",
      "Liszt/Transcendental_Etudes/1/xml_score.musicxml m2 -5\n",
      "['D-', 'D-', 'D-', 'D-', 'D-', 'D-', 'D-', 'A-', 'C-', 'F']\n",
      "[1, 1, 1, 1, 1, 1, 1, 8, 11, 5]\n",
      "Liszt/Transcendental_Etudes/1/xml_score.musicxml M2 2\n",
      "['D', 'D', 'D', 'D', 'D', 'D', 'D', 'A', 'C', 'F#']\n",
      "[2, 2, 2, 2, 2, 2, 2, 9, 0, 6]\n",
      "Liszt/Transcendental_Etudes/1/xml_score.musicxml m3 -3\n",
      "['E-', 'E-', 'E-', 'E-', 'E-', 'E-', 'E-', 'B-', 'D-', 'G']\n",
      "[3, 3, 3, 3, 3, 3, 3, 10, 1, 7]\n",
      "Liszt/Transcendental_Etudes/1/xml_score.musicxml M3 4\n",
      "['E', 'E', 'E', 'E', 'E', 'E', 'E', 'B', 'D', 'G#']\n",
      "[4, 4, 4, 4, 4, 4, 4, 11, 2, 8]\n"
     ]
    }
   ],
   "source": [
    "# choose only one enharmonic version for each chromatic interval for each piece\n",
    "dict_dataset = []\n",
    "for path in paths:\n",
    "    for c in range(12):\n",
    "        pieces_to_consider = [opus for opus in full_dict_dataset \n",
    "                              if (opus[\"original_path\"] == path and opus[\"transposed_of\"] in interval_dict[c])  ]\n",
    "        # if the original is in pieces_to_consider, go with the original\n",
    "        originals = [opus for opus in pieces_to_consider if opus[\"transposed_of\"] == \"P1\"]\n",
    "        if len(originals) == 1:\n",
    "            dict_dataset.append(originals[0])\n",
    "        else: #we go with the accidental minization criteria\n",
    "            n_accidentals = [sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in opus[\"pitches\"]]) \n",
    "                            for opus in pieces_to_consider]\n",
    "            if len(pieces_to_consider)>0:\n",
    "                dict_dataset.append(pieces_to_consider[np.argmin(n_accidentals)])\n",
    "            else:\n",
    "                print(\"No options for\", path, \". Chromatic: \",c )\n",
    "\n",
    "# accepted_ks = range(-5,6)\n",
    "# dict_dataset = [e for e in full_dict_dataset if e[\"key_signature\"] in accepted_ks]\n",
    "\n",
    "#test if it worked\n",
    "for i,e in enumerate(dict_dataset):\n",
    "    print(e[\"original_path\"], e[\"transposed_of\"], e[\"key_signature\"])\n",
    "    print(e[\"pitches\"][:10])\n",
    "    print(e[\"midi_number\"][:10])\n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgHkMeoJdb42",
    "outputId": "1f3d172f-3f93-47ce-aa1b-e37a2afba24e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2618\n",
      "Counter({'Bach': 59, 'Beethoven': 57, 'Chopin': 34, 'Liszt': 16, 'Schubert': 13, 'Haydn': 11, 'Schumann': 10, 'Mozart': 6, 'Rachmaninoff': 4, 'Ravel': 4, 'Debussy': 2, 'Scriabin': 2, 'Glinka': 1, 'Brahms': 1, 'Prokofiev': 1, 'Balakirev': 1})\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_dataset))\n",
    "\n",
    "c = Counter()\n",
    "for p in paths:\n",
    "    c[p.split(\"/\")[0]] +=1\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove pieces from asap that are in Musedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GRCM2W3qqeW",
    "outputId": "d53c8146-8b32-43df-cd69-b7423f1ceda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation lenghts:  185 33\n"
     ]
    }
   ],
   "source": [
    "# Temporary remove composer with only one piece, because they create problems with sklearn stratify\n",
    "one_piece_composers = ['Balakirev','Prokofiev','Brahms','Glinka']\n",
    "paths = [p for p in paths if p.split(\"/\")[0] not in one_piece_composers]\n",
    "\n",
    "# Divide train and validation set\n",
    "path_train, path_validation = sklearn.model_selection.train_test_split(paths, test_size=0.15,stratify=[p.split(\"/\")[0] for p in paths ])\n",
    "print(\"Train and validation lenghts: \",len(path_train),len(path_validation))\n",
    "\n",
    "#Put back one piece composers in the validation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "KIZ2_bX1bom5",
    "outputId": "ae8d5b50-ed4d-4376-f9d6-e96c6aa73046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Schubert', 'Scriabin', 'Debussy', 'Mozart', 'Liszt', 'Chopin', 'Haydn', 'Ravel', 'Rachmaninoff', 'Beethoven', 'Bach', 'Schumann']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 383
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#need to find a better way to visualize this\n",
    "composers = list(set([p.split(\"/\")[0] for p in paths ]))\n",
    "print(composers)\n",
    "\n",
    "train_composer = [composers.index(p.split(\"/\")[0]) for p in path_train]\n",
    "val_composer = [composers.index(p.split(\"/\")[0]) for p in path_validation]\n",
    "\n",
    "_ = plt.hist([train_composer, val_composer], label=['train', 'validation'])\n",
    "_ = plt.legend(loc='upper left')\n",
    "_ = plt.xticks(list(range(12)), composers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-qaT10ApkCY"
   },
   "source": [
    "## Transform the input into a convenient format for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEYec2TDOWvj",
    "outputId": "1b69573b-cfeb-4dc9-8882-da42f9c25537"
   },
   "outputs": [],
   "source": [
    "# Helper functions to feed the correct input into the NN \n",
    "\n",
    "PAD = \"<PAD>\"\n",
    "\n",
    "tag_to_ix = {p: accepted_pitches.index(p) for p in accepted_pitches}\n",
    "#add PADDING TAD\n",
    "tag_to_ix[PAD] = len(accepted_pitches)\n",
    "\n",
    "midi_to_ix = {m: m for m in range(12)}\n",
    "# #add PADDING TAD\n",
    "# midi_to_ix[PAD] = 12\n",
    "\n",
    "# print(midi_to_ix[1])\n",
    "# print(len(midi_to_ix))\n",
    "\n",
    "duration_delimiter = [0.125,0.25,0.5,1,2,4]\n",
    "\n",
    "\n",
    "class Pitch2Diatonic():\n",
    "    def __call__(self, in_seq,weights = None):\n",
    "        return [p for p in in_seq]\n",
    "\n",
    "class Diatonic2Int():\n",
    "    def __call__(self, in_seq,weights = None):\n",
    "        idxs = [tag_to_ix[w] for w in in_seq]\n",
    "        return idxs\n",
    "\n",
    "class Int2Pitch():\n",
    "    def __call__(self, in_seq):\n",
    "        return [accepted_pitches[i] for i in in_seq]\n",
    "\n",
    "class OneHotEncoder():\n",
    "    def __init__(self, alphabet_len):\n",
    "        self.alphabet_len = alphabet_len\n",
    "        \n",
    "    def __call__(self, sample,weights = None):\n",
    "        onehot = np.zeros([len(sample), self.alphabet_len])\n",
    "        tot_chars = len(sample)\n",
    "        onehot[np.arange(tot_chars), sample] = 1\n",
    "        return onehot\n",
    "\n",
    "# class WeightedOneHotEncoder():\n",
    "#     def __init__(self, alphabet_len):\n",
    "#         self.alphabet_len = alphabet_len\n",
    "        \n",
    "#     def __call__(self, sample, weights=None):\n",
    "#         if weights == None:\n",
    "#             weights = np.ones(len(sample))\n",
    "#         onehot = torch.nn.functional.one_hot(sample,self.alphabet_len)\n",
    "#         return (onehot.t()*torch.Tensor(weights)).t() #transpositions to allow the broadcasting\n",
    "    \n",
    "class DurationOneHotEncoder():\n",
    "    def __init__(self, pitch_alphabet_len, duration_delimiter):\n",
    "        self.pitch_alphabet_len = pitch_alphabet_len\n",
    "        self.dur_alphabet_len = len(duration_delimiter)+2\n",
    "        self.duration_delimiter = duration_delimiter\n",
    "        \n",
    "    def __call__(self, sample, durs):\n",
    "        sample = torch.tensor(sample,dtype=torch.long)\n",
    "        onehot_pitch = torch.nn.functional.one_hot(sample,self.pitch_alphabet_len)\n",
    "        quantized_durations = np.digitize(durs,self.duration_delimiter)\n",
    "        quantized_durations = torch.tensor(quantized_durations,dtype=torch.long)\n",
    "        onehot_duration = torch.nn.functional.one_hot(quantized_durations,self.dur_alphabet_len)\n",
    "        return torch.cat([onehot_pitch,onehot_duration],1)\n",
    "        \n",
    "class ToTensorFloat():\n",
    "    def __call__(self, sample, weight = None):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.float()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.float)\n",
    "\n",
    "class ToTensorLong():\n",
    "    def __call__(self, sample, weights = None):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.long()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.long)\n",
    "    \n",
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, sample, weights):\n",
    "        for t in self.transforms:\n",
    "            sample = t(sample, weights)\n",
    "        return sample\n",
    "\n",
    "pitches_len = len(accepted_pitches)\n",
    "midinote_len = 12\n",
    "\n",
    "### Define the preprocessing pipeline\n",
    "transform_diat = Compose([Pitch2Diatonic(),Diatonic2Int(),ToTensorLong()])\n",
    "transform_chrom = Compose([DurationOneHotEncoder(len(midi_to_ix),duration_delimiter),ToTensorFloat()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =[list(range(10)) for e in range(4)]\n",
    "torch.Tensor(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV9boYaToUs2",
    "outputId": "92bcd8d3-87a2-4d2c-8e92-4a106139f59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2179 33\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n",
      "tensor([ 5,  5,  0,  9,  9,  7,  9,  0,  0,  5,  9,  9,  0,  5,  3,  2,  9,  0,\n",
      "         2, 10, 10,  5,  2,  4,  5, 10, 10,  2,  5,  5])\n",
      "['F', 'F', 'C', 'A', 'A', 'G', 'A', 'C', 'C', 'F', 'A', 'A', 'C', 'F', 'E-', 'D', 'A', 'C', 'D', 'B-', 'B-', 'F', 'D', 'E', 'F', 'B-', 'B-', 'D', 'F', 'F']\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "\n",
    "class PSDataset(Dataset):\n",
    "    def __init__(self, dict_dataset, paths, transf_c, transf_d, augment_dataset, truncate = None):\n",
    "        if augment_dataset:\n",
    "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset if e[\"original_path\"] in paths]\n",
    "            self.diatonic_sequences = [e[\"pitches\"]\n",
    "                                       for e in dict_dataset \n",
    "                                       if e[\"original_path\"] in paths]\n",
    "            self.durations = [e[\"duration\"] for e in dict_dataset if e[\"original_path\"] in paths]\n",
    "        else: #consider only non transposed pieces\n",
    "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset \n",
    "                                        if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "            self.diatonic_sequences = [e[\"pitches\"]\n",
    "                                       for e in dict_dataset \n",
    "                                       if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "            self.durations = [e[\"duration\"] \n",
    "                              for e in dict_dataset \n",
    "                              if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "        #the transformations to apply to data\n",
    "        self.transf_c = transf_c\n",
    "        self.transf_d = transf_d\n",
    "        self.truncate = truncate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chromatic_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chromatic_seq = self.chromatic_sequences[idx]\n",
    "        diatonic_seq = self.diatonic_sequences[idx]\n",
    "        duration_seq = self.durations[idx]\n",
    "        weights = [dur/4  if dur<=4 else 1 for dur in duration_seq  ] # limit the weights to (0,4)       \n",
    "\n",
    "        #transform\n",
    "        chromatic_seq = self.transf_c(chromatic_seq,weights)\n",
    "        diatonic_seq = self.transf_d(diatonic_seq,None)\n",
    "\n",
    "        if not self.truncate is None:\n",
    "            if len(diatonic_seq) > self.truncate:\n",
    "                chromatic_seq = chromatic_seq[0:self.truncate]\n",
    "                diatonic_seq = diatonic_seq[0:self.truncate]\n",
    "\n",
    "        #sanity check\n",
    "        assert len(chromatic_seq) == len(diatonic_seq)\n",
    "        seq_len = len(diatonic_seq)\n",
    "        \n",
    "        return chromatic_seq, diatonic_seq, seq_len\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\n",
    "\n",
    "print(len(train_dataset),len(validation_dataset))\n",
    "\n",
    "\n",
    "\n",
    "# test if it works\n",
    "for chrom,diat,seq_len in train_dataset:\n",
    "    print(chrom[0:30])\n",
    "    print(torch.argmax(chrom[0:30],1))\n",
    "    # print([diatonic_pitches[p.item()] for p in diat[0:30]])\n",
    "    print([accepted_pitches[p.item()] for p in diat[0:30]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAubyjw2LC8P",
    "outputId": "d6f8574f-8901-41e7-fd7a-9a0c6091eafa"
   },
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (xx, yy, l) = zip(*batch)\n",
    "    \n",
    "    xx_pad = pad_sequence(xx)\n",
    "    yy_pad = pad_sequence(yy, padding_value=tag_to_ix[PAD])\n",
    "\n",
    "    #sort the sequences by length\n",
    "    seq_lengths, perm_idx = torch.Tensor(l).sort(0, descending=True)\n",
    "    xx_pad = xx_pad[:,perm_idx,:]\n",
    "    yy_pad = yy_pad[:,perm_idx]\n",
    "\n",
    "    return xx_pad, yy_pad, seq_lengths\n",
    "\n",
    "# data_loader = DataLoader(dataset=validation_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "\n",
    "\n",
    "# #test if it work\n",
    "# for batch in data_loader:\n",
    "#     print(batch[0].shape,batch[1].shape,batch[2])\n",
    "#     print(batch[1])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O1OA1AjGWO-"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QEkFBY5cUsmN"
   },
   "outputs": [],
   "source": [
    "class RNNTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='sum',ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "       \n",
    "        # # Find the positions where the token is a dummy padding token.\n",
    "        # pad_mask = (sentences == self.pad_word_id).float()\n",
    "\n",
    "        # # For these positions, we add some large number in the column corresponding\n",
    "        # # to the dummy padding label.\n",
    "        # out[:, :, self.pad_label_id] += pad_mask*10000\n",
    "\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        return [predicted[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QE7itQ88Qx17"
   },
   "outputs": [],
   "source": [
    "class RNNCRFTagger(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNCRFTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        self.crf = CRF(self.n_labels)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        ## should I initialize here??\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "      \n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # Compute the outputs of the lower layers, which will be used as emission\n",
    "        # scores for the CRF.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # We return the loss value. The CRF returns the log likelihood, but we return \n",
    "        # the *negative* log likelihood as the loss value.            \n",
    "        # PyTorch's optimizers *minimize* the loss, while we want to *maximize* the\n",
    "        # log likelihood.\n",
    "\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return -self.crf(scores, labels, mask = pad_mask )\n",
    "            \n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the emission scores, as above.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Apply the Viterbi algorithm to get the predictions. This implementation returns\n",
    "        # the result as a list of lists (not a tensor), corresponding to a matrix\n",
    "        # of shape (n_sentences, max_len).\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return self.crf.decode(scores,mask = pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNAttentionTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNAttentionTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='sum',ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "        # attention function\n",
    "        # TODO : set right parameters\n",
    "        self.attention = AdditiveAttention(encoder_dim=hidden_dim, decoder_dim=hidden_dim)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "        # use attention\n",
    "        attn_applied = self.attention(rnn_out,rnn_out)\n",
    "        \n",
    "        out = self.top_layer(attn_applied) #maybe remove this one?\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        return [predicted[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]\n",
    "    \n",
    "    \n",
    "\n",
    "class AdditiveAttention(torch.nn.Module):\n",
    "    def __init__(self, encoder_dim=100, decoder_dim=50):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.decoder_dim = decoder_dim \n",
    "        self.v = torch.nn.Parameter(torch.rand(self.decoder_dim))\n",
    "        self.W_1 = torch.nn.Linear(self.decoder_dim, self.decoder_dim)\n",
    "        self.W_2 = torch.nn.Linear(self.encoder_dim, self.decoder_dim)\n",
    "\n",
    "    def forward(self,\n",
    "                query, # [decoder_dim]\n",
    "                values # [seq_length, encoder_dim]\n",
    "               ):\n",
    "        weights = self._get_weights(query, values) # [seq_length]\n",
    "        weights = torch.nn.functional.softmax(weights, dim=0)\n",
    "        return weights @ values # [encoder_dim]\n",
    "\n",
    "    def _get_weights(self, \n",
    "                     query, # [decoder_dim]\n",
    "                     values # [seq_length, encoder_dim]\n",
    "                    ): \n",
    "        query = query.repeat(values.size(0), 1) # [seq_length, decoder_dim]\n",
    "        weights = self.W_1(query) + self.W_2(values) # [seq_length, decoder_dim]\n",
    "        return torch.tanh(weights) @ self.v # [seq_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXixmVQfvw8T"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3m_nj4HCuCe1"
   },
   "outputs": [],
   "source": [
    "# TODO: search over the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uAMSIlw0AJb6"
   },
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, train_dataloader, val_dataloader, n_epochs):\n",
    "    history = defaultdict(list)  \n",
    "    for i_epoch in range(1,n_epochs +1):\n",
    "        t0 = time.time()\n",
    "        loss_sum = 0\n",
    "        accuracy_sum = 0\n",
    "        model.train()\n",
    "        for seqs, targets, lens in train_dataloader: #seqs, targets, lens are batches\n",
    "            seqs, targets = seqs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = model(seqs,targets,lens) / sum(lens) #normalize for the number of symbol considered (without padding)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            predicted = model.predict(seqs,lens)\n",
    "            for i,p in enumerate(predicted):\n",
    "                acc= accuracy_score(p,targets[:,i][:len(p)].cpu()) #compute the accuracy without considering the padding\n",
    "                accuracy_sum += acc/len(lens) #normalize according to the number of sequences in the batch\n",
    "\n",
    "        train_loss = loss_sum/len(train_dataloader)\n",
    "        train_accuracy = accuracy_sum/len(train_dataloader) #normalize according to the number of batches\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_accuracy\"].append(train_accuracy)\n",
    "\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        all_predicted = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for seqs,targets, lens in val_dataloader:\n",
    "                # Predict the model's output on a batch\n",
    "                predicted = model.predict(seqs.to(device),lens)                   \n",
    "                # Update the lists that will be used to compute the accuracy\n",
    "                for i,p in enumerate(predicted):\n",
    "                    all_predicted.append(torch.Tensor(p))\n",
    "                    all_targets.append(targets[0:int(lens[i]),i])\n",
    "                \n",
    "        # Compute the overall accuracy for the validation set\n",
    "        val_accuracy = accuracy_score(torch.cat(all_predicted),torch.cat(all_targets))\n",
    "        history[\"val_accuracy\"].append(val_accuracy)\n",
    "\n",
    "#         save the model\n",
    "        torch.save(model, \"./models/temp/model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "#         files.download(\"model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "\n",
    "    \n",
    "        t1 = time.time()\n",
    "        print(f'Epoch {i_epoch}: train loss = {train_loss:.4f}, train_accuracy: {train_accuracy:.4f},val_accuracy: {val_accuracy:.4f}, time = {t1-t0:.4f}')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "2g2st8znpGW_",
    "outputId": "fe232e42-e270-4f5d-9bd8-718bba5e7151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-07c3e1652024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# otimizer = torch.optim.Adam(model.parameters(),lr = 0.05, weight_decay=1e-4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# After the final evaluation, we print more detailed evaluation statistics,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-757a3c567616>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, optimizer, train_dataloader, val_dataloader, n_epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#normalize for the number of symbol considered (without padding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-fba14feaae55>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences, labels, sentences_len)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Compute the outputs. The shape is (max_len, n_sentences, n_labels).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentences_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Flatten the outputs and the gold-standard labels, to compute the loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-fba14feaae55>\u001b[0m in \u001b[0;36mcompute_outputs\u001b[0;34m(self, sentences, sentences_len)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mrnn_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# use attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mattn_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrnn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#maybe remove this one?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-fba14feaae55>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, values)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;31m# [seq_length, encoder_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                ):\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [seq_length]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;31m# [encoder_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-fba14feaae55>\u001b[0m in \u001b[0;36m_get_weights\u001b[0;34m(self, query, values)\u001b[0m\n\u001b[1;32m     78\u001b[0m                      \u001b[0mvalues\u001b[0m \u001b[0;31m# [seq_length, encoder_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     ): \n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [seq_length, decoder_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [seq_length, decoder_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m \u001b[0;31m# [seq_length]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 1\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True, truncate = None)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\n",
    "val_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False,collate_fn=pad_collate)\n",
    "\n",
    "# model = torch.load(\"./models/temp/model_temp_epoch30-to_restart.pkl\")\n",
    "# model = RNNCRFTagger(len(midi_to_ix)+len(duration_delimiter)+2,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "model = RNNAttentionTagger(len(midi_to_ix)+len(duration_delimiter)+2,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_WEIGHT)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_WEIGHT, momentum = 0.9,weight_decay=WEIGHT_DECAY)\n",
    "# otimizer = torch.optim.Adam(model.parameters(),lr = 0.05, weight_decay=1e-4)\n",
    "\n",
    "history = training_loop(model,optimizer,train_dataloader,val_dataloader, n_epochs)\n",
    "\n",
    "# After the final evaluation, we print more detailed evaluation statistics,\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.legend(['training loss', 'training accuracy', 'validation_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy:  0.9548586557910835 at epoch 13\n"
     ]
    }
   ],
   "source": [
    "#find the best working model on the accuracy\n",
    "max_accuracy = np.max(history['val_accuracy'])\n",
    "best_epoch = np.argmax(history['val_accuracy'])\n",
    "print(\"Best validation accuracy: \",max_accuracy, \"at epoch\",best_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tTv2BrGbvSHh",
    "outputId": "801ff32d-24dc-4434-a436-17d9ca832214"
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"./models/model_asap_crf200dur.pkl\")\n",
    "# files.download(\"model_asap_crf300.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXcmLpCKt28l"
   },
   "source": [
    "## Test on Mdata dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./models/model_temp_CRFacc9548.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BacUqgD5usGL"
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "with open(Path(basepath,'./datasets/musedata.pkl'), 'rb') as fid:\n",
    "     full_mdata_dict_dataset = pickle.load( fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgaUwW2fuwg0",
    "outputId": "89fc5f7d-884a-4ee6-fc34-b3d512f0c4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 different pieces\n",
      "Average number of notes:  858.6319771007974\n"
     ]
    }
   ],
   "source": [
    "mdata_paths = list(set([e[\"original_path\"] for e in full_mdata_dict_dataset ]))\n",
    "\n",
    "# # remove the symbphony No.100 from Haydn because of the enharmonic transposition\n",
    "# paths.remove(\"datasets\\\\opnd\\\\haydndoversyms-10004m.opnd-m\")\n",
    "\n",
    "# print(paths)\n",
    "print(len(mdata_paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_mdata_dict_dataset ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "f-Fg6gJKvNLt"
   },
   "outputs": [],
   "source": [
    "mdata_dataset = PSDataset(full_mdata_dict_dataset,mdata_paths, transform_chrom,transform_diat,False)\n",
    "mdata_dataloader  = DataLoader(mdata_dataset,  batch_size=16, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ml905Mtdvj-T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "all_inputs = []\n",
    "all_outputs = []\n",
    "all_targets = []\n",
    "model.eval() # Evaluation mode (e.g. disable dropout)\n",
    "with torch.no_grad(): # Disable gradient tracking\n",
    "    for seqs, targets,lens in mdata_dataloader:\n",
    "        # Move data to device\n",
    "        seqs = seqs.to(device)\n",
    "\n",
    "        # Predict the model's output on a batch.\n",
    "        predicted = model.predict(seqs,lens)                   \n",
    "        # Update the evaluation statistics.\n",
    "        for i,p in enumerate(predicted):\n",
    "            all_inputs.append(torch.argmax(seqs[0:int(lens[i]),i,:].cpu(),1).numpy())\n",
    "            all_outputs.append(torch.Tensor(p))\n",
    "            all_targets.append(targets[0:int(lens[i]),i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsefdSHxvrWy",
    "outputId": "33785b90-5e03-4a6d-86dd-92b6b763a505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['viv', 'tel', 'bee', 'bac', 'han', 'cor', 'moz', 'hay']\n"
     ]
    }
   ],
   "source": [
    "# Divide accuracy according to author\n",
    "authors = []\n",
    "\n",
    "for sequence in all_inputs:\n",
    "    author = [e[\"original_path\"].split(\"\\\\\")[-1][:3] for e in full_mdata_dict_dataset\n",
    "              if len(e[\"midi_number\"]) == len(sequence) and\n",
    "              list(e[\"midi_number\"]) ==list(sequence) ]\n",
    "    # assert len(author) == 1\n",
    "    authors.append(author[0])\n",
    "\n",
    "considered_authors = list(set(authors))\n",
    "print(considered_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgNt_yG7vrfd",
    "outputId": "8473393f-dac6-4930-9d9e-da9c1046f1ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'viv': 36, 'tel': 41, 'bee': 185, 'bac': 101, 'han': 44, 'cor': 14, 'moz': 131, 'hay': 376}\n",
      "{'viv': 0.9985304322978323, 'tel': 0.9983265306122449, 'bee': 0.9924468215408484, 'bac': 0.9958783921648643, 'han': 0.9982040816326531, 'cor': 0.9994284081166047, 'moz': 0.9946517514493345, 'hay': 0.9846467946100449}\n",
      "{'viv': 24497, 'tel': 24500, 'bee': 24493, 'bac': 24505, 'han': 24500, 'cor': 24493, 'moz': 24494, 'hay': 24490}\n",
      "Total errors : 928\n"
     ]
    }
   ],
   "source": [
    "errors_per_author = {}\n",
    "accuracy_per_author = {}\n",
    "notes_per_author = {}\n",
    "for ca in considered_authors:\n",
    "    # ca_inputs = torch.cat([all_inputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_outputs = torch.cat([all_outputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_targets = torch.cat([all_targets[i] for i,a in enumerate(authors) if a == ca])\n",
    "    # print(ca_inputs.shape,ca_outputs.shape,ca_targets.shape,ca_predicted_pitches.shape)\n",
    "    ca_acc = accuracy_score(ca_outputs,ca_targets)\n",
    "    accuracy_per_author[ca] = float(ca_acc)\n",
    "    errors_per_author[ca] = int(len(ca_targets) - sum(torch.eq(ca_outputs,ca_targets)))\n",
    "    notes_per_author[ca] = len(ca_targets)\n",
    "\n",
    "print(errors_per_author)\n",
    "print(accuracy_per_author)\n",
    "print(notes_per_author)\n",
    "print(\"Total errors :\", sum([e for e in errors_per_author.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5s0d56evrje"
   },
   "source": [
    "### Best accuracy for now\n",
    "for now best accuracy is with  no CRF (but considering durations) n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 0.09\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "duration_delimiter = [0.125,0.25,0.5,1,2,4]\n",
    "\n",
    "Model available in: \"model_temp_epoch12-noCRFacc9575.pkl\"\n",
    "accuracy on validation set 0.9575\n",
    "Trained on all dataset\n",
    "\n",
    "\n",
    "{'moz': 98, 'tel': 116, 'bac': 93, 'hay': 200, 'cor': 25, 'bee': 127, 'viv': 45, 'han': 52}\n",
    "{'moz': 0.9959990201682044, 'tel': 0.995265306122449, 'bac': 0.9962048561518058, 'hay': 0.9918334013883218, 'cor': 0.9989793002082228, 'bee': 0.9948148450577716, 'viv': 0.9981630403722905, 'han': 0.9978775510204082}\n",
    "{'moz': 24494, 'tel': 24500, 'bac': 24505, 'hay': 24490, 'cor': 24493, 'bee': 24493, 'viv': 24497, 'han': 24500}\n",
    "Total errors : 756\n",
    "\n",
    "This win by far against ps13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVvP1eH8vrl3"
   },
   "source": [
    "### Best accuracy with CRF\n",
    "n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 1\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "model = RNNCRFTagger(len(midi_to_ix)+len(duration_delimiter)+2,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "\n",
    "Model available in: \"\"./models/model_temp_CRFacc9548.pkl\"\"\n",
    "accuracy on validation set 0.9548586557910835\n",
    "Trained on all asap dataset\n",
    "\n",
    "{'viv': 36, 'tel': 41, 'bee': 185, 'bac': 101, 'han': 44, 'cor': 14, 'moz': 131, 'hay': 376}\n",
    "{'viv': 0.9985304322978323, 'tel': 0.9983265306122449, 'bee': 0.9924468215408484, 'bac': 0.9958783921648643, 'han': 0.9982040816326531, 'cor': 0.9994284081166047, 'moz': 0.9946517514493345, 'hay': 0.9846467946100449}\n",
    "{'viv': 24497, 'tel': 24500, 'bee': 24493, 'bac': 24505, 'han': 24500, 'cor': 24493, 'moz': 24494, 'hay': 24490}\n",
    "Total errors : 928\n",
    "\n",
    "Still win against ps13"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOTDh55Hh2OWCo66dGc+SES",
   "include_colab_link": true,
   "name": "rnncrf_pitch_spelling",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
