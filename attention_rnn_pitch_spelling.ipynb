{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fosfrancesco/pitch-spelling/blob/main/rnncrf_pitch_spelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fifMg_hxNSOg",
    "outputId": "a8b320f9-4231-40d9-8f10-a7b8acd1da37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-crf\n",
      "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hsciybUBNkur"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "import music21 as m21\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn\n",
    "import music21 as m21\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchcrf import CRF\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "\n",
    "import jenkspy\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "# import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Naq6UG5jRbyK"
   },
   "source": [
    "# RNN-CRF for Pitch Spelling\n",
    "\n",
    "Dataset: different authors from ASAP collection\n",
    "Challenges:\n",
    "- extremely long sequences\n",
    "- small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mHJvrZ2Wo_e",
    "outputId": "1319f78b-cfb1-4e2a-937c-c47cf952757c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'C'), (1, 'B#'), (2, 'D--'), (3, 'C#'), (4, 'B##'), (5, 'D-'), (6, 'D'), (7, 'C##'), (8, 'E--'), (9, 'D#'), (10, 'E-'), (11, 'F--'), (12, 'E'), (13, 'D##'), (14, 'F-'), (15, 'F'), (16, 'E#'), (17, 'G--'), (18, 'F#'), (19, 'E##'), (20, 'G-'), (21, 'G'), (22, 'F##'), (23, 'A--'), (24, 'G#'), (25, 'A-'), (26, 'A'), (27, 'G##'), (28, 'B--'), (29, 'A#'), (30, 'B-'), (31, 'C--'), (32, 'B'), (33, 'A##'), (34, 'C-')]\n",
      "['D--', 'B##', 'C##', 'E--', 'F--', 'D##', 'G--', 'E##', 'F##', 'A--', 'G##', 'B--', 'C--', 'A##']\n",
      "[(0, 'P1'), (1, 'd2'), (2, 'A7'), (3, 'm2'), (4, 'A1'), (5, 'M2'), (6, 'd3'), (7, 'AA1'), (8, 'm3'), (9, 'A2'), (10, 'M3'), (11, 'd4'), (12, 'AA2'), (13, 'P4'), (14, 'A3'), (15, 'd5'), (16, 'A4'), (17, 'P5'), (18, 'd6'), (19, 'AA4'), (20, 'm6'), (21, 'A5'), (22, 'M6'), (23, 'd7'), (24, 'AA5'), (25, 'm7'), (26, 'A6'), (27, 'M7'), (28, 'd1'), (29, 'AA6')]\n"
     ]
    }
   ],
   "source": [
    "pitches_dict = {\n",
    "    0 : [\"C\",\"B#\",\"D--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    1 : [\"C#\",\"B##\",\"D-\"], # nn.Linear(input_size+context_size, 2)\n",
    "    2 : [\"D\",\"C##\",\"E--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    3 : [\"D#\",\"E-\",\"F--\"],\n",
    "    4 : [\"E\",\"D##\",\"F-\"],\n",
    "    5 : [\"F\",\"E#\",\"G--\"],\n",
    "    6 : [\"F#\",\"E##\",\"G-\"],\n",
    "    7 : [\"G\",\"F##\",\"A--\"],\n",
    "    8 : [\"G#\",\"A-\"],\n",
    "    9 : [\"A\",\"G##\",\"B--\"],\n",
    "    10 : [\"A#\",\"B-\",\"C--\"],\n",
    "    11 : [\"B\",\"A##\",\"C-\"]\n",
    "}\n",
    "\n",
    "accepted_pitches = [ii for i in pitches_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_pitches)])\n",
    "\n",
    "double_acc_pitches = [ii for i in pitches_dict.values() for ii in i if ii.endswith(\"##\") or  ii.endswith(\"--\") ]\n",
    "print(double_acc_pitches)\n",
    "\n",
    "def score2midi_numbers(score):\n",
    "    return [p.midi%12 for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "def score2pitches(score):\n",
    "    return [p.name for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "interval_dict = {\n",
    "    0 : [\"P1\",\"d2\",\"A7\"], \n",
    "    1 : [\"m2\",\"A1\"], \n",
    "    2 : [\"M2\",\"d3\",\"AA1\"], \n",
    "    3 : [\"m3\",\"A2\"],\n",
    "    4 : [\"M3\",\"d4\",\"AA2\"],\n",
    "    5 : [\"P4\",\"A3\"],\n",
    "    6 : [\"d5\",\"A4\"],\n",
    "    7 : [\"P5\",\"d6\",\"AA4\"],\n",
    "    8 : [\"m6\",\"A5\"],\n",
    "    9 : [\"M6\",\"d7\",\"AA5\"],\n",
    "    10 : [\"m7\",\"A6\"],\n",
    "    11 : [\"M7\",\"d1\",\"AA6\"]\n",
    "}\n",
    "\n",
    "accepted_intervals = [ii for i in interval_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_intervals)])\n",
    "\n",
    "def transp_score(score):\n",
    "    \"\"\" For each input return len(accepted_intervals) transposed scores\"\"\"\n",
    "    return [score.transpose(interval) for interval in accepted_intervals]\n",
    "\n",
    "def smart_transp_score(score):\n",
    "    \"\"\" For each chromatic interval chose the interval that lead to the smallest number of accidentals\"\"\"\n",
    "    scores = []\n",
    "    for chromatic_int in interval_dict.keys():\n",
    "        temp_scores = []\n",
    "        temp_acc_number = []\n",
    "        for diat_interval in interval_dict[chromatic_int]:\n",
    "            new_score = score.transpose(diat_interval)\n",
    "            temp_scores.append(new_score)\n",
    "            temp_acc_number.append(sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in score2pitches(new_score)]))\n",
    "            # print(\"choice:\", [note.name for note in temp_scores[-1].flat.notes][0:10],\"acc:\",temp_acc_number[-1] )\n",
    "        #keep only the one with the lowest number of accidentals\n",
    "        min_index = np.argmin(temp_acc_number)\n",
    "        # print(\"preferred the number\", min_index)\n",
    "        scores.append(temp_scores[min_index])\n",
    "    return scores\n",
    "\n",
    "def acc_simple_enough(score,accepted_ratio = 0.2 ):\n",
    "    pitches = score2pitches(score)\n",
    "    double_acc = sum(el in double_acc_pitches for el in pitches)\n",
    "    if double_acc/len(pitches) < accepted_ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "diatonic_pitches = [\"C\",\"D\", \"E\", \"F\", \"G\", \"A\", \"B\"]\n",
    "\n",
    "# #test acc_simple_enough()\n",
    "# score = m21.converter.parse(paths[356])\n",
    "# scores = smart_transp_score(score)\n",
    "# #delete the pieces with non accepted pitches (e.g. triple sharps)\n",
    "# scores = [s for s in scores if all(pitch in accepted_pitches for pitch in score2pitches(s))]\n",
    "# for s in scores:\n",
    "#     print(s.parts[0].flat.getElementsByClass(m21.key.KeySignature)[0], \"simple enough:\", acc_simple_enough(s))\n",
    "#     print([n.name for n in s.flat.notes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw-SuL4ZB_2C"
   },
   "source": [
    "## Import ASAP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrZ0BwLEj2Gp",
    "outputId": "6b521f78-28db-4d4f-f4ef-9345c5d91db9"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/fosfrancesco/pitch-spelling.git\n",
    "\n",
    "basepath = \"./\" #to change if running locally or on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WaINjDS2kpxE"
   },
   "outputs": [],
   "source": [
    "# load the asap datasets\n",
    "with open(Path(basepath,'datasets','baroque_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_baroque = pickle.load( fid)\n",
    "\n",
    "with open(Path(basepath,'datasets','classical_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_classical = pickle.load( fid)\n",
    "\n",
    "with open(Path(basepath,'datasets','romantic_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_romantic = pickle.load( fid)\n",
    "        \n",
    "# with open(Path(basepath,'datasets','remaining_aug_asap.pkl'), 'rb') as fid:\n",
    "#      dataset_remaining = pickle.load( fid)\n",
    "\n",
    "# merge the three files together\n",
    "# full_dict_dataset = dataset_baroque + dataset_classical + dataset_romantic + dataset_remaining\n",
    "full_dict_dataset = dataset_baroque + dataset_classical + dataset_romantic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYQdkJAiTS6_",
    "outputId": "72835948-2884-40bb-e5b4-6ebbc8488895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 different pieces\n",
      "Average number of notes:  2219.6285387474977\n"
     ]
    }
   ],
   "source": [
    "paths = list(set([e[\"original_path\"] for e in full_dict_dataset ]))\n",
    "\n",
    "# print(paths)\n",
    "print(len(paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_dict_dataset ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMdKkzNnCTrK"
   },
   "source": [
    "## Chose the convenient data augmentation\n",
    "Two possibilities:\n",
    "- for each chromatic interval, take only the diatonic transposition that produce the smallest number of accidentals (or the original if present)\n",
    "- take only a certain interval of time signatures\n",
    "\n",
    "The second is probably better for a smaller and simple dataset, but gives the problem of chosing between for example F# and G# that are both present in this bigger dataset. So we go for the first criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oign7EZ9BSX4",
    "outputId": "9aa3f694-289a-43fd-fd14-9cad3b8dd3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No options for Chopin/Ballades/4/xml_score.musicxml . Chromatic:  6\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  1\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  4\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  6\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  9\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml . Chromatic:  1\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  1\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  3\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  8\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  10\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  11\n",
      "Beethoven/Piano_Sonatas/11-1/xml_score.musicxml P1 -2\n",
      "['D', 'B-', 'A', 'B-', 'F', 'F', 'D', 'B-', 'B-', 'D']\n",
      "[2, 10, 9, 10, 5, 5, 2, 10, 10, 2]\n",
      "Beethoven/Piano_Sonatas/11-1/xml_score.musicxml A1 5\n",
      "['D#', 'B', 'A#', 'B', 'F#', 'F#', 'D#', 'B', 'B', 'D#']\n",
      "[3, 11, 10, 11, 6, 6, 3, 11, 11, 3]\n",
      "Beethoven/Piano_Sonatas/11-1/xml_score.musicxml M2 0\n",
      "['E', 'C', 'B', 'C', 'G', 'G', 'E', 'C', 'C', 'E']\n",
      "[4, 0, 11, 0, 7, 7, 4, 0, 0, 4]\n",
      "Beethoven/Piano_Sonatas/11-1/xml_score.musicxml m3 -5\n",
      "['F', 'D-', 'C', 'D-', 'A-', 'A-', 'F', 'D-', 'D-', 'F']\n",
      "[5, 1, 0, 1, 8, 8, 5, 1, 1, 5]\n",
      "Beethoven/Piano_Sonatas/11-1/xml_score.musicxml M3 2\n",
      "['F#', 'D', 'C#', 'D', 'A', 'A', 'F#', 'D', 'D', 'F#']\n",
      "[6, 2, 1, 2, 9, 9, 6, 2, 2, 6]\n",
      "Beethoven/Piano_Sonatas/11-1/xml_score.musicxml P4 -3\n",
      "['G', 'E-', 'D', 'E-', 'B-', 'B-', 'G', 'E-', 'E-', 'G']\n",
      "[7, 3, 2, 3, 10, 10, 7, 3, 3, 7]\n",
      "Beethoven/Piano_Sonatas/11-1/xml_score.musicxml A4 4\n",
      "['G#', 'E', 'D#', 'E', 'B', 'B', 'G#', 'E', 'E', 'G#']\n",
      "[8, 4, 3, 4, 11, 11, 8, 4, 4, 8]\n",
      "Beethoven/Piano_Sonatas/11-1/xml_score.musicxml P5 -1\n",
      "['A', 'F', 'E', 'F', 'C', 'C', 'A', 'F', 'F', 'A']\n",
      "[9, 5, 4, 5, 0, 0, 9, 5, 5, 9]\n",
      "Beethoven/Piano_Sonatas/11-1/xml_score.musicxml m6 -6\n",
      "['B-', 'G-', 'F', 'G-', 'D-', 'D-', 'B-', 'G-', 'G-', 'B-']\n",
      "[10, 6, 5, 6, 1, 1, 10, 6, 6, 10]\n",
      "Beethoven/Piano_Sonatas/11-1/xml_score.musicxml M6 1\n",
      "['B', 'G', 'F#', 'G', 'D', 'D', 'B', 'G', 'G', 'B']\n",
      "[11, 7, 6, 7, 2, 2, 11, 7, 7, 11]\n",
      "Beethoven/Piano_Sonatas/11-1/xml_score.musicxml m7 -4\n",
      "['C', 'A-', 'G', 'A-', 'E-', 'E-', 'C', 'A-', 'A-', 'C']\n",
      "[0, 8, 7, 8, 3, 3, 0, 8, 8, 0]\n",
      "Beethoven/Piano_Sonatas/11-1/xml_score.musicxml M7 3\n",
      "['C#', 'A', 'G#', 'A', 'E', 'E', 'C#', 'A', 'A', 'C#']\n",
      "[1, 9, 8, 9, 4, 4, 1, 9, 9, 1]\n",
      "Bach/Fugue/bwv_868/xml_score.musicxml P1 5\n",
      "['B', 'A#', 'B', 'C#', 'F#', 'G#', 'A#', 'B', 'C#', 'D#']\n",
      "[11, 10, 11, 1, 6, 8, 10, 11, 1, 3]\n",
      "Bach/Fugue/bwv_868/xml_score.musicxml m2 0\n",
      "['C', 'B', 'C', 'D', 'G', 'A', 'B', 'C', 'D', 'E']\n",
      "[0, 11, 0, 2, 7, 9, 11, 0, 2, 4]\n",
      "Bach/Fugue/bwv_868/xml_score.musicxml d3 -5\n",
      "['D-', 'C', 'D-', 'E-', 'A-', 'B-', 'C', 'D-', 'E-', 'F']\n",
      "[1, 0, 1, 3, 8, 10, 0, 1, 3, 5]\n",
      "Bach/Fugue/bwv_868/xml_score.musicxml m3 2\n",
      "['D', 'C#', 'D', 'E', 'A', 'B', 'C#', 'D', 'E', 'F#']\n",
      "[2, 1, 2, 4, 9, 11, 1, 2, 4, 6]\n",
      "Bach/Fugue/bwv_868/xml_score.musicxml d4 -3\n",
      "['E-', 'D', 'E-', 'F', 'B-', 'C', 'D', 'E-', 'F', 'G']\n",
      "[3, 2, 3, 5, 10, 0, 2, 3, 5, 7]\n",
      "Bach/Fugue/bwv_868/xml_score.musicxml P4 4\n",
      "['E', 'D#', 'E', 'F#', 'B', 'C#', 'D#', 'E', 'F#', 'G#']\n",
      "[4, 3, 4, 6, 11, 1, 3, 4, 6, 8]\n",
      "Bach/Fugue/bwv_868/xml_score.musicxml d5 -1\n",
      "['F', 'E', 'F', 'G', 'C', 'D', 'E', 'F', 'G', 'A']\n",
      "[5, 4, 5, 7, 0, 2, 4, 5, 7, 9]\n",
      "Bach/Fugue/bwv_868/xml_score.musicxml d6 -6\n",
      "['G-', 'F', 'G-', 'A-', 'D-', 'E-', 'F', 'G-', 'A-', 'B-']\n",
      "[6, 5, 6, 8, 1, 3, 5, 6, 8, 10]\n",
      "Bach/Fugue/bwv_868/xml_score.musicxml m6 1\n",
      "['G', 'F#', 'G', 'A', 'D', 'E', 'F#', 'G', 'A', 'B']\n",
      "[7, 6, 7, 9, 2, 4, 6, 7, 9, 11]\n",
      "Bach/Fugue/bwv_868/xml_score.musicxml d7 -4\n",
      "['A-', 'G', 'A-', 'B-', 'E-', 'F', 'G', 'A-', 'B-', 'C']\n",
      "[8, 7, 8, 10, 3, 5, 7, 8, 10, 0]\n",
      "Bach/Fugue/bwv_868/xml_score.musicxml m7 3\n",
      "['A', 'G#', 'A', 'B', 'E', 'F#', 'G#', 'A', 'B', 'C#']\n",
      "[9, 8, 9, 11, 4, 6, 8, 9, 11, 1]\n",
      "Bach/Fugue/bwv_868/xml_score.musicxml d1 -2\n",
      "['B-', 'A', 'B-', 'C', 'F', 'G', 'A', 'B-', 'C', 'D']\n",
      "[10, 9, 10, 0, 5, 7, 9, 10, 0, 2]\n",
      "Beethoven/Piano_Sonatas/3-2/xml_score.musicxml P1 4\n",
      "['G#', 'B', 'E', 'E', 'F#', 'G#', 'A', 'F#', 'B', 'A']\n",
      "[8, 11, 4, 4, 6, 8, 9, 6, 11, 9]\n",
      "Beethoven/Piano_Sonatas/3-2/xml_score.musicxml m2 -1\n",
      "['A', 'C', 'F', 'F', 'G', 'A', 'B-', 'G', 'C', 'B-']\n",
      "[9, 0, 5, 5, 7, 9, 10, 7, 0, 10]\n",
      "Beethoven/Piano_Sonatas/3-2/xml_score.musicxml M2 6\n",
      "['A#', 'C#', 'F#', 'F#', 'G#', 'A#', 'B', 'G#', 'C#', 'B']\n",
      "[10, 1, 6, 6, 8, 10, 11, 8, 1, 11]\n",
      "Beethoven/Piano_Sonatas/3-2/xml_score.musicxml m3 1\n",
      "['B', 'D', 'G', 'G', 'A', 'B', 'C', 'A', 'D', 'C']\n",
      "[11, 2, 7, 7, 9, 11, 0, 9, 2, 0]\n",
      "Beethoven/Piano_Sonatas/3-2/xml_score.musicxml d4 -4\n",
      "['C', 'E-', 'A-', 'A-', 'B-', 'C', 'D-', 'B-', 'E-', 'D-']\n",
      "[0, 3, 8, 8, 10, 0, 1, 10, 3, 1]\n",
      "Beethoven/Piano_Sonatas/3-2/xml_score.musicxml P4 3\n",
      "['C#', 'E', 'A', 'A', 'B', 'C#', 'D', 'B', 'E', 'D']\n",
      "[1, 4, 9, 9, 11, 1, 2, 11, 4, 2]\n",
      "Beethoven/Piano_Sonatas/3-2/xml_score.musicxml d5 -2\n",
      "['D', 'F', 'B-', 'B-', 'C', 'D', 'E-', 'C', 'F', 'E-']\n",
      "[2, 5, 10, 10, 0, 2, 3, 0, 5, 3]\n",
      "Beethoven/Piano_Sonatas/3-2/xml_score.musicxml P5 5\n",
      "['D#', 'F#', 'B', 'B', 'C#', 'D#', 'E', 'C#', 'F#', 'E']\n",
      "[3, 6, 11, 11, 1, 3, 4, 1, 6, 4]\n",
      "Beethoven/Piano_Sonatas/3-2/xml_score.musicxml m6 0\n",
      "['E', 'G', 'C', 'C', 'D', 'E', 'F', 'D', 'G', 'F']\n",
      "[4, 7, 0, 0, 2, 4, 5, 2, 7, 5]\n",
      "Beethoven/Piano_Sonatas/3-2/xml_score.musicxml M6 7\n",
      "['E#', 'G#', 'C#', 'C#', 'D#', 'E#', 'F#', 'D#', 'G#', 'F#']\n",
      "[5, 8, 1, 1, 3, 5, 6, 3, 8, 6]\n",
      "Beethoven/Piano_Sonatas/3-2/xml_score.musicxml m7 2\n",
      "['F#', 'A', 'D', 'D', 'E', 'F#', 'G', 'E', 'A', 'G']\n",
      "[6, 9, 2, 2, 4, 6, 7, 4, 9, 7]\n",
      "Beethoven/Piano_Sonatas/3-2/xml_score.musicxml d1 -3\n",
      "['G', 'B-', 'E-', 'E-', 'F', 'G', 'A-', 'F', 'B-', 'A-']\n",
      "[7, 10, 3, 3, 5, 7, 8, 5, 10, 8]\n",
      "Beethoven/Piano_Sonatas/26-3/xml_score.musicxml P1 -3\n",
      "['A-', 'D', 'F', 'A-', 'B-', 'D', 'F', 'A-', 'B-', 'B-']\n",
      "[8, 2, 5, 8, 10, 2, 5, 8, 10, 10]\n",
      "Beethoven/Piano_Sonatas/26-3/xml_score.musicxml A1 4\n",
      "['A', 'D#', 'F#', 'A', 'B', 'D#', 'F#', 'A', 'B', 'B']\n",
      "[9, 3, 6, 9, 11, 3, 6, 9, 11, 11]\n",
      "Beethoven/Piano_Sonatas/26-3/xml_score.musicxml M2 -1\n",
      "['B-', 'E', 'G', 'B-', 'C', 'E', 'G', 'B-', 'C', 'C']\n",
      "[10, 4, 7, 10, 0, 4, 7, 10, 0, 0]\n",
      "Beethoven/Piano_Sonatas/26-3/xml_score.musicxml m3 -6\n",
      "['C-', 'F', 'A-', 'C-', 'D-', 'F', 'A-', 'C-', 'D-', 'D-']\n",
      "[11, 5, 8, 11, 1, 5, 8, 11, 1, 1]\n",
      "Beethoven/Piano_Sonatas/26-3/xml_score.musicxml M3 1\n",
      "['C', 'F#', 'A', 'C', 'D', 'F#', 'A', 'C', 'D', 'D']\n",
      "[0, 6, 9, 0, 2, 6, 9, 0, 2, 2]\n",
      "Beethoven/Piano_Sonatas/26-3/xml_score.musicxml P4 -4\n",
      "['D-', 'G', 'B-', 'D-', 'E-', 'G', 'B-', 'D-', 'E-', 'E-']\n",
      "[1, 7, 10, 1, 3, 7, 10, 1, 3, 3]\n",
      "Beethoven/Piano_Sonatas/26-3/xml_score.musicxml A4 3\n",
      "['D', 'G#', 'B', 'D', 'E', 'G#', 'B', 'D', 'E', 'E']\n",
      "[2, 8, 11, 2, 4, 8, 11, 2, 4, 4]\n",
      "Beethoven/Piano_Sonatas/26-3/xml_score.musicxml P5 -2\n",
      "['E-', 'A', 'C', 'E-', 'F', 'A', 'C', 'E-', 'F', 'F']\n",
      "[3, 9, 0, 3, 5, 9, 0, 3, 5, 5]\n",
      "Beethoven/Piano_Sonatas/26-3/xml_score.musicxml m6 -7\n",
      "['F-', 'B-', 'D-', 'F-', 'G-', 'B-', 'D-', 'F-', 'G-', 'G-']\n",
      "[4, 10, 1, 4, 6, 10, 1, 4, 6, 6]\n",
      "Beethoven/Piano_Sonatas/26-3/xml_score.musicxml M6 0\n",
      "['F', 'B', 'D', 'F', 'G', 'B', 'D', 'F', 'G', 'G']\n",
      "[5, 11, 2, 5, 7, 11, 2, 5, 7, 7]\n",
      "Beethoven/Piano_Sonatas/26-3/xml_score.musicxml m7 -5\n",
      "['G-', 'C', 'E-', 'G-', 'A-', 'C', 'E-', 'G-', 'A-', 'A-']\n",
      "[6, 0, 3, 6, 8, 0, 3, 6, 8, 8]\n",
      "Beethoven/Piano_Sonatas/26-3/xml_score.musicxml M7 2\n",
      "['G', 'C#', 'E', 'G', 'A', 'C#', 'E', 'G', 'A', 'A']\n",
      "[7, 1, 4, 7, 9, 1, 4, 7, 9, 9]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml P1 -3\n",
      "['E-', 'C', 'G', 'G', 'E-', 'C', 'E-', 'C', 'G', 'G']\n",
      "[3, 0, 7, 7, 3, 0, 3, 0, 7, 7]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml A1 4\n",
      "['E', 'C#', 'G#', 'G#', 'E', 'C#', 'E', 'C#', 'G#', 'G#']\n",
      "[4, 1, 8, 8, 4, 1, 4, 1, 8, 8]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml M2 -1\n",
      "['F', 'D', 'A', 'A', 'F', 'D', 'F', 'D', 'A', 'A']\n",
      "[5, 2, 9, 9, 5, 2, 5, 2, 9, 9]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml m3 -6\n",
      "['G-', 'E-', 'B-', 'B-', 'G-', 'E-', 'G-', 'E-', 'B-', 'B-']\n",
      "[6, 3, 10, 10, 6, 3, 6, 3, 10, 10]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml M3 1\n",
      "['G', 'E', 'B', 'B', 'G', 'E', 'G', 'E', 'B', 'B']\n",
      "[7, 4, 11, 11, 7, 4, 7, 4, 11, 11]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml P4 -4\n",
      "['A-', 'F', 'C', 'C', 'A-', 'F', 'A-', 'F', 'C', 'C']\n",
      "[8, 5, 0, 0, 8, 5, 8, 5, 0, 0]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml A4 3\n",
      "['A', 'F#', 'C#', 'C#', 'A', 'F#', 'A', 'F#', 'C#', 'C#']\n",
      "[9, 6, 1, 1, 9, 6, 9, 6, 1, 1]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml P5 -2\n",
      "['B-', 'G', 'D', 'D', 'B-', 'G', 'B-', 'G', 'D', 'D']\n",
      "[10, 7, 2, 2, 10, 7, 10, 7, 2, 2]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml A5 5\n",
      "['B', 'G#', 'D#', 'D#', 'B', 'G#', 'B', 'G#', 'D#', 'D#']\n",
      "[11, 8, 3, 3, 11, 8, 11, 8, 3, 3]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml M6 0\n",
      "['C', 'A', 'E', 'E', 'C', 'A', 'C', 'A', 'E', 'E']\n",
      "[0, 9, 4, 4, 0, 9, 0, 9, 4, 4]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml m7 -5\n",
      "['D-', 'B-', 'F', 'F', 'D-', 'B-', 'D-', 'B-', 'F', 'F']\n",
      "[1, 10, 5, 5, 1, 10, 1, 10, 5, 5]\n",
      "Chopin/Etudes_op_25/12/xml_score.musicxml M7 2\n",
      "['D', 'B', 'F#', 'F#', 'D', 'B', 'D', 'B', 'F#', 'F#']\n",
      "[2, 11, 6, 6, 2, 11, 2, 11, 6, 6]\n",
      "Bach/Prelude/bwv_848/xml_score.musicxml P1 7\n",
      "['E#', 'C#', 'C#', 'G#', 'C#', 'E#', 'C#', 'C#', 'F#', 'D#']\n",
      "[5, 1, 1, 8, 1, 5, 1, 1, 6, 3]\n",
      "Bach/Prelude/bwv_848/xml_score.musicxml m2 2\n",
      "['F#', 'D', 'D', 'A', 'D', 'F#', 'D', 'D', 'G', 'E']\n",
      "[6, 2, 2, 9, 2, 6, 2, 2, 7, 4]\n",
      "Bach/Prelude/bwv_848/xml_score.musicxml d3 -3\n",
      "['G', 'E-', 'E-', 'B-', 'E-', 'G', 'E-', 'E-', 'A-', 'F']\n",
      "[7, 3, 3, 10, 3, 7, 3, 3, 8, 5]\n",
      "Bach/Prelude/bwv_848/xml_score.musicxml m3 4\n",
      "['G#', 'E', 'E', 'B', 'E', 'G#', 'E', 'E', 'A', 'F#']\n",
      "[8, 4, 4, 11, 4, 8, 4, 4, 9, 6]\n",
      "Bach/Prelude/bwv_848/xml_score.musicxml d4 -1\n",
      "['A', 'F', 'F', 'C', 'F', 'A', 'F', 'F', 'B-', 'G']\n",
      "[9, 5, 5, 0, 5, 9, 5, 5, 10, 7]\n",
      "Bach/Prelude/bwv_848/xml_score.musicxml P4 6\n",
      "['A#', 'F#', 'F#', 'C#', 'F#', 'A#', 'F#', 'F#', 'B', 'G#']\n",
      "[10, 6, 6, 1, 6, 10, 6, 6, 11, 8]\n",
      "Bach/Prelude/bwv_848/xml_score.musicxml d5 1\n",
      "['B', 'G', 'G', 'D', 'G', 'B', 'G', 'G', 'C', 'A']\n",
      "[11, 7, 7, 2, 7, 11, 7, 7, 0, 9]\n",
      "Bach/Prelude/bwv_848/xml_score.musicxml d6 -4\n",
      "['C', 'A-', 'A-', 'E-', 'A-', 'C', 'A-', 'A-', 'D-', 'B-']\n",
      "[0, 8, 8, 3, 8, 0, 8, 8, 1, 10]\n",
      "Bach/Prelude/bwv_848/xml_score.musicxml m6 3\n",
      "['C#', 'A', 'A', 'E', 'A', 'C#', 'A', 'A', 'D', 'B']\n",
      "[1, 9, 9, 4, 9, 1, 9, 9, 2, 11]\n",
      "Bach/Prelude/bwv_848/xml_score.musicxml d7 -2\n",
      "['D', 'B-', 'B-', 'F', 'B-', 'D', 'B-', 'B-', 'E-', 'C']\n",
      "[2, 10, 10, 5, 10, 2, 10, 10, 3, 0]\n",
      "Bach/Prelude/bwv_848/xml_score.musicxml m7 5\n",
      "['D#', 'B', 'B', 'F#', 'B', 'D#', 'B', 'B', 'E', 'C#']\n",
      "[3, 11, 11, 6, 11, 3, 11, 11, 4, 1]\n",
      "Bach/Prelude/bwv_848/xml_score.musicxml d1 0\n",
      "['E', 'C', 'C', 'G', 'C', 'E', 'C', 'C', 'F', 'D']\n",
      "[4, 0, 0, 7, 0, 4, 0, 0, 5, 2]\n",
      "Beethoven/Piano_Sonatas/27-1/xml_score.musicxml P1 1\n",
      "['G', 'B', 'E', 'G', 'E', 'E', 'G', 'G', 'B', 'E']\n",
      "[7, 11, 4, 7, 4, 4, 7, 7, 11, 4]\n",
      "Beethoven/Piano_Sonatas/27-1/xml_score.musicxml m2 -4\n",
      "['A-', 'C', 'F', 'A-', 'F', 'F', 'A-', 'A-', 'C', 'F']\n",
      "[8, 0, 5, 8, 5, 5, 8, 8, 0, 5]\n",
      "Beethoven/Piano_Sonatas/27-1/xml_score.musicxml M2 3\n",
      "['A', 'C#', 'F#', 'A', 'F#', 'F#', 'A', 'A', 'C#', 'F#']\n",
      "[9, 1, 6, 9, 6, 6, 9, 9, 1, 6]\n",
      "Beethoven/Piano_Sonatas/27-1/xml_score.musicxml m3 -2\n",
      "['B-', 'D', 'G', 'B-', 'G', 'G', 'B-', 'B-', 'D', 'G']\n",
      "[10, 2, 7, 10, 7, 7, 10, 10, 2, 7]\n",
      "Beethoven/Piano_Sonatas/27-1/xml_score.musicxml M3 5\n",
      "['B', 'D#', 'G#', 'B', 'G#', 'G#', 'B', 'B', 'D#', 'G#']\n",
      "[11, 3, 8, 11, 8, 8, 11, 11, 3, 8]\n",
      "Beethoven/Piano_Sonatas/27-1/xml_score.musicxml P4 0\n",
      "['C', 'E', 'A', 'C', 'A', 'A', 'C', 'C', 'E', 'A']\n",
      "[0, 4, 9, 0, 9, 9, 0, 0, 4, 9]\n",
      "Beethoven/Piano_Sonatas/27-1/xml_score.musicxml d5 -5\n",
      "['D-', 'F', 'B-', 'D-', 'B-', 'B-', 'D-', 'D-', 'F', 'B-']\n",
      "[1, 5, 10, 1, 10, 10, 1, 1, 5, 10]\n",
      "Beethoven/Piano_Sonatas/27-1/xml_score.musicxml P5 2\n",
      "['D', 'F#', 'B', 'D', 'B', 'B', 'D', 'D', 'F#', 'B']\n",
      "[2, 6, 11, 2, 11, 11, 2, 2, 6, 11]\n",
      "Beethoven/Piano_Sonatas/27-1/xml_score.musicxml m6 -3\n",
      "['E-', 'G', 'C', 'E-', 'C', 'C', 'E-', 'E-', 'G', 'C']\n",
      "[3, 7, 0, 3, 0, 0, 3, 3, 7, 0]\n",
      "Beethoven/Piano_Sonatas/27-1/xml_score.musicxml M6 4\n",
      "['E', 'G#', 'C#', 'E', 'C#', 'C#', 'E', 'E', 'G#', 'C#']\n",
      "[4, 8, 1, 4, 1, 1, 4, 4, 8, 1]\n",
      "Beethoven/Piano_Sonatas/27-1/xml_score.musicxml m7 -1\n",
      "['F', 'A', 'D', 'F', 'D', 'D', 'F', 'F', 'A', 'D']\n",
      "[5, 9, 2, 5, 2, 2, 5, 5, 9, 2]\n",
      "Beethoven/Piano_Sonatas/27-1/xml_score.musicxml d1 -6\n",
      "['G-', 'B-', 'E-', 'G-', 'E-', 'E-', 'G-', 'G-', 'B-', 'E-']\n",
      "[6, 10, 3, 6, 3, 3, 6, 6, 10, 3]\n",
      "Bach/Prelude/bwv_887/xml_score.musicxml P1 5\n",
      "['G#', 'G#', 'B', 'D#', 'A#', 'B', 'C#', 'D#', 'B', 'A#']\n",
      "[8, 8, 11, 3, 10, 11, 1, 3, 11, 10]\n",
      "Bach/Prelude/bwv_887/xml_score.musicxml m2 0\n",
      "['A', 'A', 'C', 'E', 'B', 'C', 'D', 'E', 'C', 'B']\n",
      "[9, 9, 0, 4, 11, 0, 2, 4, 0, 11]\n",
      "Bach/Prelude/bwv_887/xml_score.musicxml d3 -5\n",
      "['B-', 'B-', 'D-', 'F', 'C', 'D-', 'E-', 'F', 'D-', 'C']\n",
      "[10, 10, 1, 5, 0, 1, 3, 5, 1, 0]\n",
      "Bach/Prelude/bwv_887/xml_score.musicxml m3 2\n",
      "['B', 'B', 'D', 'F#', 'C#', 'D', 'E', 'F#', 'D', 'C#']\n",
      "[11, 11, 2, 6, 1, 2, 4, 6, 2, 1]\n",
      "Bach/Prelude/bwv_887/xml_score.musicxml d4 -3\n",
      "['C', 'C', 'E-', 'G', 'D', 'E-', 'F', 'G', 'E-', 'D']\n",
      "[0, 0, 3, 7, 2, 3, 5, 7, 3, 2]\n",
      "Bach/Prelude/bwv_887/xml_score.musicxml P4 4\n",
      "['C#', 'C#', 'E', 'G#', 'D#', 'E', 'F#', 'G#', 'E', 'D#']\n",
      "[1, 1, 4, 8, 3, 4, 6, 8, 4, 3]\n",
      "Bach/Prelude/bwv_887/xml_score.musicxml d5 -1\n",
      "['D', 'D', 'F', 'A', 'E', 'F', 'G', 'A', 'F', 'E']\n",
      "[2, 2, 5, 9, 4, 5, 7, 9, 5, 4]\n",
      "Bach/Prelude/bwv_887/xml_score.musicxml d6 -6\n",
      "['E-', 'E-', 'G-', 'B-', 'F', 'G-', 'A-', 'B-', 'G-', 'F']\n",
      "[3, 3, 6, 10, 5, 6, 8, 10, 6, 5]\n",
      "Bach/Prelude/bwv_887/xml_score.musicxml m6 1\n",
      "['E', 'E', 'G', 'B', 'F#', 'G', 'A', 'B', 'G', 'F#']\n",
      "[4, 4, 7, 11, 6, 7, 9, 11, 7, 6]\n",
      "Bach/Prelude/bwv_887/xml_score.musicxml d7 -4\n",
      "['F', 'F', 'A-', 'C', 'G', 'A-', 'B-', 'C', 'A-', 'G']\n",
      "[5, 5, 8, 0, 7, 8, 10, 0, 8, 7]\n",
      "Bach/Prelude/bwv_887/xml_score.musicxml m7 3\n",
      "['F#', 'F#', 'A', 'C#', 'G#', 'A', 'B', 'C#', 'A', 'G#']\n",
      "[6, 6, 9, 1, 8, 9, 11, 1, 9, 8]\n",
      "Bach/Prelude/bwv_887/xml_score.musicxml d1 -2\n",
      "['G', 'G', 'B-', 'D', 'A', 'B-', 'C', 'D', 'B-', 'A']\n",
      "[7, 7, 10, 2, 9, 10, 0, 2, 10, 9]\n",
      "Bach/Prelude/bwv_892/xml_score.musicxml P1 5\n",
      "['B', 'B', 'C#', 'D#', 'E', 'F#', 'G#', 'A#', 'B', 'B']\n",
      "[11, 11, 1, 3, 4, 6, 8, 10, 11, 11]\n",
      "Bach/Prelude/bwv_892/xml_score.musicxml m2 0\n",
      "['C', 'C', 'D', 'E', 'F', 'G', 'A', 'B', 'C', 'C']\n",
      "[0, 0, 2, 4, 5, 7, 9, 11, 0, 0]\n",
      "Bach/Prelude/bwv_892/xml_score.musicxml d3 -5\n",
      "['D-', 'D-', 'E-', 'F', 'G-', 'A-', 'B-', 'C', 'D-', 'D-']\n",
      "[1, 1, 3, 5, 6, 8, 10, 0, 1, 1]\n",
      "Bach/Prelude/bwv_892/xml_score.musicxml m3 2\n",
      "['D', 'D', 'E', 'F#', 'G', 'A', 'B', 'C#', 'D', 'D']\n",
      "[2, 2, 4, 6, 7, 9, 11, 1, 2, 2]\n",
      "Bach/Prelude/bwv_892/xml_score.musicxml d4 -3\n",
      "['E-', 'E-', 'F', 'G', 'A-', 'B-', 'C', 'D', 'E-', 'E-']\n",
      "[3, 3, 5, 7, 8, 10, 0, 2, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# choose only one enharmonic version for each chromatic interval for each piece\n",
    "dict_dataset = []\n",
    "for path in paths:\n",
    "    for c in range(12):\n",
    "        pieces_to_consider = [opus for opus in full_dict_dataset \n",
    "                              if (opus[\"original_path\"] == path and opus[\"transposed_of\"] in interval_dict[c])  ]\n",
    "        # if the original is in pieces_to_consider, go with the original\n",
    "        originals = [opus for opus in pieces_to_consider if opus[\"transposed_of\"] == \"P1\"]\n",
    "        if len(originals) == 1:\n",
    "            dict_dataset.append(originals[0])\n",
    "        else: #we go with the accidental minization criteria\n",
    "            n_accidentals = [sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in opus[\"pitches\"]]) \n",
    "                            for opus in pieces_to_consider]\n",
    "            if len(pieces_to_consider)>0:\n",
    "                dict_dataset.append(pieces_to_consider[np.argmin(n_accidentals)])\n",
    "            else:\n",
    "                print(\"No options for\", path, \". Chromatic: \",c )\n",
    "\n",
    "# accepted_ks = range(-5,6)\n",
    "# dict_dataset = [e for e in full_dict_dataset if e[\"key_signature\"] in accepted_ks]\n",
    "\n",
    "#test if it worked\n",
    "for i,e in enumerate(dict_dataset):\n",
    "    print(e[\"original_path\"], e[\"transposed_of\"], e[\"key_signature\"])\n",
    "    print(e[\"pitches\"][:10])\n",
    "    print(e[\"midi_number\"][:10])\n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgHkMeoJdb42",
    "outputId": "1f3d172f-3f93-47ce-aa1b-e37a2afba24e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2271\n",
      "Counter({'Bach': 59, 'Beethoven': 57, 'Chopin': 34, 'Schubert': 13, 'Haydn': 11, 'Schumann': 10, 'Mozart': 6, 'Brahms': 1})\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_dataset))\n",
    "\n",
    "c = Counter()\n",
    "for p in paths:\n",
    "    c[p.split(\"/\")[0]] +=1\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 initial pieces\n",
      "190 pieces after removing overlapping with musedata\n"
     ]
    }
   ],
   "source": [
    "# TODO: remove pieces from asap that are in Musedata\n",
    "print(len(paths), \"initial pieces\")\n",
    "paths = [p for p in paths if p!= \"Bach/Prelude/bwv_865/xml_score.musicxml\"]\n",
    "print(len(paths), \"pieces after removing overlapping with musedata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GRCM2W3qqeW",
    "outputId": "d53c8146-8b32-43df-cd69-b7423f1ceda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation lenghts:  160 29\n"
     ]
    }
   ],
   "source": [
    "# Temporary remove composer with only one piece, because they create problems with sklearn stratify\n",
    "one_piece_composers = ['Balakirev','Prokofiev','Brahms','Glinka']\n",
    "paths = [p for p in paths if p.split(\"/\")[0] not in one_piece_composers]\n",
    "\n",
    "# Divide train and validation set\n",
    "path_train, path_validation = sklearn.model_selection.train_test_split(paths, test_size=0.15,stratify=[p.split(\"/\")[0] for p in paths ])\n",
    "print(\"Train and validation lenghts: \",len(path_train),len(path_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "KIZ2_bX1bom5",
    "outputId": "ae8d5b50-ed4d-4376-f9d6-e96c6aa73046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chopin', 'Schumann', 'Beethoven', 'Bach', 'Mozart', 'Haydn', 'Schubert']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 379
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#need to find a better way to visualize this\n",
    "composers = list(set([p.split(\"/\")[0] for p in paths ]))\n",
    "print(composers)\n",
    "\n",
    "train_composer = [composers.index(p.split(\"/\")[0]) for p in path_train]\n",
    "val_composer = [composers.index(p.split(\"/\")[0]) for p in path_validation]\n",
    "\n",
    "_ = plt.hist([train_composer, val_composer], label=['train', 'validation'])\n",
    "_ = plt.legend(loc='upper left')\n",
    "_ = plt.xticks(list(range(len(composers))), composers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-qaT10ApkCY"
   },
   "source": [
    "## Transform the input into a convenient format for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEYec2TDOWvj",
    "outputId": "1b69573b-cfeb-4dc9-8882-da42f9c25537"
   },
   "outputs": [],
   "source": [
    "# Helper functions to feed the correct input into the NN \n",
    "\n",
    "PAD = \"<PAD>\"\n",
    "\n",
    "tag_to_ix = {p: accepted_pitches.index(p) for p in accepted_pitches}\n",
    "#add PADDING TAD\n",
    "tag_to_ix[PAD] = len(accepted_pitches)\n",
    "\n",
    "midi_to_ix = {m: m for m in range(12)}\n",
    "# #add PADDING TAD\n",
    "# midi_to_ix[PAD] = 12\n",
    "\n",
    "# print(midi_to_ix[1])\n",
    "# print(len(midi_to_ix))\n",
    "N_DURATION_CLASSES = 4\n",
    "\n",
    "\n",
    "class Pitch2Diatonic():\n",
    "    def __call__(self, in_seq,weights = None):\n",
    "        return [p for p in in_seq]\n",
    "\n",
    "class Diatonic2Int():\n",
    "    def __call__(self, in_seq,weights = None):\n",
    "        idxs = [tag_to_ix[w] for w in in_seq]\n",
    "        return idxs\n",
    "\n",
    "class Int2Pitch():\n",
    "    def __call__(self, in_seq):\n",
    "        return [accepted_pitches[i] for i in in_seq]\n",
    "\n",
    "class OneHotEncoder():\n",
    "    def __init__(self, alphabet_len):\n",
    "        self.alphabet_len = alphabet_len\n",
    "        \n",
    "    def __call__(self, sample,weights = None):\n",
    "        onehot = np.zeros([len(sample), self.alphabet_len])\n",
    "        tot_chars = len(sample)\n",
    "        onehot[np.arange(tot_chars), sample] = 1\n",
    "        return onehot\n",
    "    \n",
    "class DurationOneHotEncoder():\n",
    "    def __init__(self, pitch_alphabet_len, n_dur_class = 4):\n",
    "        self.pitch_alphabet_len = pitch_alphabet_len\n",
    "        self.dur_alphabet_len = n_dur_class\n",
    "        \n",
    "    def __call__(self, sample, durs):\n",
    "        sample = torch.tensor(sample,dtype=torch.long)\n",
    "        onehot_pitch = torch.nn.functional.one_hot(sample,self.pitch_alphabet_len)\n",
    "        #compute breaks in duration list\n",
    "        if len(set(durs)) > N_DURATION_CLASSES: \n",
    "            breaks = jenkspy.jenks_breaks(list(set(durs)), nb_class=N_DURATION_CLASSES)\n",
    "            #quantize according to the breaks selected\n",
    "            quantized_durations = np.digitize(durs,breaks[1:-1])\n",
    "        elif len(set(durs)) > 2 : # in this case jenks breaks would throw an exception \n",
    "            temp_n_classes = len(set(durs)) -1\n",
    "            breaks = jenkspy.jenks_breaks(list(set(durs)), nb_class=temp_n_classes)\n",
    "            # add lower classes to have the same number for all dataset\n",
    "            for __ in range(N_DURATION_CLASSES-temp_n_classes):\n",
    "                breaks = [breaks[0]/2] + breaks\n",
    "            #quantize according to the breaks selected\n",
    "            quantized_durations = np.digitize(durs,breaks[1:-1])\n",
    "        else: # just use custom default\n",
    "            #quantize according to the breaks selected\n",
    "            quantized_durations = [1 for d in durs]        \n",
    "        quantized_durations = torch.tensor(quantized_durations,dtype=torch.long)\n",
    "        onehot_duration = torch.nn.functional.one_hot(quantized_durations,self.dur_alphabet_len)\n",
    "        return torch.cat([onehot_pitch,onehot_duration],1)\n",
    "        \n",
    "class ToTensorFloat():\n",
    "    def __call__(self, sample, weight = None):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.float()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.float)\n",
    "\n",
    "class ToTensorLong():\n",
    "    def __call__(self, sample, weights = None):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.long()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.long)\n",
    "    \n",
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, sample, weights):\n",
    "        for t in self.transforms:\n",
    "            sample = t(sample, weights)\n",
    "        return sample\n",
    "\n",
    "pitches_len = len(accepted_pitches)\n",
    "midinote_len = 12\n",
    "\n",
    "### Define the preprocessing pipeline\n",
    "transform_diat = Compose([Pitch2Diatonic(),Diatonic2Int(),ToTensorLong()])\n",
    "transform_chrom = Compose([DurationOneHotEncoder(len(midi_to_ix),N_DURATION_CLASSES),ToTensorFloat()])\n",
    "\n",
    "### Test if it work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV9boYaToUs2",
    "outputId": "92bcd8d3-87a2-4d2c-8e92-4a106139f59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1904 29\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "7797\n",
      "7797\n",
      "7797\n",
      "7797\n",
      "7797\n",
      "7797\n",
      "7797\n",
      "7797\n",
      "7797\n",
      "7797\n",
      "7797\n",
      "7797\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6708\n",
      "6708\n",
      "6708\n",
      "6708\n",
      "6708\n",
      "6708\n",
      "6708\n",
      "6708\n",
      "6708\n",
      "6708\n",
      "6708\n",
      "6708\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6277\n",
      "6277\n",
      "6277\n",
      "6277\n",
      "6277\n",
      "6277\n",
      "6277\n",
      "6277\n",
      "6277\n",
      "6277\n",
      "6277\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "4979\n",
      "4979\n",
      "4979\n",
      "4979\n",
      "4979\n",
      "4979\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4650\n",
      "4650\n",
      "4650\n",
      "4650\n",
      "4650\n",
      "4650\n",
      "4650\n",
      "4650\n",
      "4650\n",
      "4650\n",
      "4650\n",
      "4650\n",
      "4419\n",
      "4419\n",
      "4419\n",
      "4419\n",
      "4419\n",
      "4419\n",
      "4419\n",
      "4419\n",
      "4308\n",
      "4308\n",
      "4308\n",
      "4308\n",
      "4308\n",
      "4308\n",
      "4308\n",
      "4308\n",
      "4308\n",
      "4308\n",
      "4308\n",
      "4308\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3491\n",
      "3491\n",
      "3491\n",
      "3491\n",
      "3491\n",
      "3491\n",
      "3491\n",
      "3491\n",
      "3491\n",
      "3491\n",
      "3491\n",
      "3491\n",
      "3451\n",
      "3451\n",
      "3451\n",
      "3451\n",
      "3451\n",
      "3451\n",
      "3451\n",
      "3451\n",
      "3451\n",
      "3451\n",
      "3451\n",
      "3451\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3266\n",
      "3266\n",
      "3266\n",
      "3266\n",
      "3266\n",
      "3266\n",
      "3266\n",
      "3266\n",
      "3266\n",
      "3266\n",
      "3266\n",
      "3266\n",
      "3235\n",
      "3235\n",
      "3235\n",
      "3235\n",
      "3235\n",
      "3235\n",
      "3235\n",
      "3235\n",
      "3235\n",
      "3235\n",
      "3235\n",
      "3235\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2692\n",
      "2692\n",
      "2692\n",
      "2692\n",
      "2692\n",
      "2692\n",
      "2692\n",
      "2692\n",
      "2692\n",
      "2692\n",
      "2692\n",
      "2692\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1550\n",
      "1550\n",
      "1550\n",
      "1550\n",
      "1550\n",
      "1550\n",
      "1550\n",
      "1550\n",
      "1550\n",
      "1550\n",
      "1550\n",
      "1550\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1395\n",
      "1395\n",
      "1395\n",
      "1395\n",
      "1395\n",
      "1395\n",
      "1395\n",
      "1395\n",
      "1395\n",
      "1395\n",
      "1395\n",
      "1395\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1104\n",
      "1104\n",
      "1104\n",
      "1104\n",
      "1104\n",
      "1104\n",
      "1104\n",
      "1104\n",
      "1104\n",
      "1104\n",
      "1104\n",
      "1104\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "953\n",
      "953\n",
      "953\n",
      "953\n",
      "953\n",
      "953\n",
      "953\n",
      "953\n",
      "953\n",
      "953\n",
      "953\n",
      "953\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "838\n",
      "838\n",
      "838\n",
      "838\n",
      "838\n",
      "838\n",
      "838\n",
      "838\n",
      "838\n",
      "838\n",
      "838\n",
      "838\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "794\n",
      "794\n",
      "794\n",
      "794\n",
      "794\n",
      "794\n",
      "794\n",
      "794\n",
      "794\n",
      "794\n",
      "794\n",
      "794\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "\n",
    "class PSDataset(Dataset):\n",
    "    def __init__(self, dict_dataset, paths, transf_c, transf_d, augment_dataset, sort =False, truncate = None):\n",
    "        if sort:\n",
    "            dict_dataset = sorted(dict_dataset, key = lambda e: (len(e['midi_number'])),reverse=True)\n",
    "        if augment_dataset:\n",
    "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset if e[\"original_path\"] in paths]\n",
    "            self.diatonic_sequences = [e[\"pitches\"]\n",
    "                                       for e in dict_dataset \n",
    "                                       if e[\"original_path\"] in paths]\n",
    "            self.durations = [e[\"duration\"] for e in dict_dataset if e[\"original_path\"] in paths]\n",
    "        else: #consider only non transposed pieces\n",
    "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset \n",
    "                                        if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "            self.diatonic_sequences = [e[\"pitches\"]\n",
    "                                       for e in dict_dataset \n",
    "                                       if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "            self.durations = [e[\"duration\"] \n",
    "                              for e in dict_dataset \n",
    "                              if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "        #the transformations to apply to data\n",
    "        self.transf_c = transf_c\n",
    "        self.transf_d = transf_d\n",
    "        self.truncate = truncate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chromatic_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chromatic_seq = self.chromatic_sequences[idx]\n",
    "        diatonic_seq = self.diatonic_sequences[idx]\n",
    "        duration_seq = self.durations[idx]\n",
    "        weights = [dur/4  if dur<=4 else 1 for dur in duration_seq  ] # limit the weights to (0,4)      \n",
    "\n",
    "        #transform\n",
    "        chromatic_seq = self.transf_c(chromatic_seq,weights)\n",
    "        diatonic_seq = self.transf_d(diatonic_seq,None)\n",
    "\n",
    "        if not self.truncate is None:\n",
    "            if len(diatonic_seq) > self.truncate:\n",
    "                chromatic_seq = chromatic_seq[0:self.truncate]\n",
    "                diatonic_seq = diatonic_seq[0:self.truncate]\n",
    "\n",
    "        #sanity check\n",
    "        assert len(chromatic_seq) == len(diatonic_seq)\n",
    "        seq_len = len(diatonic_seq)\n",
    "        \n",
    "        return chromatic_seq, diatonic_seq, seq_len\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True, sort = True)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\n",
    "\n",
    "print(len(train_dataset),len(validation_dataset))\n",
    "\n",
    "\n",
    "\n",
    "# test if it works\n",
    "for chrom,diat,seq_len in train_dataset:\n",
    "#     print(chrom[0:30])\n",
    "#     print(torch.argmax(chrom[0:30],1))\n",
    "#     # print([diatonic_pitches[p.item()] for p in diat[0:30]])\n",
    "#     print([accepted_pitches[p.item()] for p in diat[0:30]])\n",
    "    print(seq_len)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAubyjw2LC8P",
    "outputId": "d6f8574f-8901-41e7-fd7a-9a0c6091eafa"
   },
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (xx, yy, l) = zip(*batch)\n",
    "    \n",
    "    xx_pad = pad_sequence(xx)\n",
    "    yy_pad = pad_sequence(yy, padding_value=tag_to_ix[PAD])\n",
    "\n",
    "    #sort the sequences by length\n",
    "    seq_lengths, perm_idx = torch.Tensor(l).sort(0, descending=True)\n",
    "    xx_pad = xx_pad[:,perm_idx,:]\n",
    "    yy_pad = yy_pad[:,perm_idx]\n",
    "\n",
    "    return xx_pad, yy_pad, seq_lengths\n",
    "\n",
    "# data_loader = DataLoader(dataset=validation_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "\n",
    "\n",
    "# #test if it work\n",
    "# for batch in data_loader:\n",
    "#     print(batch[0].shape,batch[1].shape,batch[2])\n",
    "#     print(batch[1])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O1OA1AjGWO-"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QEkFBY5cUsmN"
   },
   "outputs": [],
   "source": [
    "class RNNTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='mean', ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "       \n",
    "        # # Find the positions where the token is a dummy padding token.\n",
    "        # pad_mask = (sentences == self.pad_word_id).float()\n",
    "\n",
    "        # # For these positions, we add some large number in the column corresponding\n",
    "        # # to the dummy padding label.\n",
    "        # out[:, :, self.pad_label_id] += pad_mask*10000\n",
    "\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        return [predicted[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QE7itQ88Qx17"
   },
   "outputs": [],
   "source": [
    "class RNNCRFTagger(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNCRFTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        self.crf = CRF(self.n_labels)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        ## should I initialize here??\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "      \n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # Compute the outputs of the lower layers, which will be used as emission\n",
    "        # scores for the CRF.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # We return the loss value. The CRF returns the log likelihood, but we return \n",
    "        # the *negative* log likelihood as the loss value.            \n",
    "        # PyTorch's optimizers *minimize* the loss, while we want to *maximize* the\n",
    "        # log likelihood.\n",
    "\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return -self.crf(scores, labels, mask = pad_mask )\n",
    "            \n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the emission scores, as above.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Apply the Viterbi algorithm to get the predictions. This implementation returns\n",
    "        # the result as a list of lists (not a tensor), corresponding to a matrix\n",
    "        # of shape (n_sentences, max_len).\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return self.crf.decode(scores,mask = pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNAttentionTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNAttentionTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='mean',ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "        # attention function\n",
    "        # TODO : set right parameters\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "        # use attention\n",
    "        attn_applied = self.attention(rnn_out,rnn_out,sentences_len)\n",
    "        \n",
    "        out = self.top_layer(attn_applied) #maybe remove this one?\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        return [predicted[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]\n",
    "    \n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention,self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W = torch.nn.Parameter(torch.FloatTensor(\n",
    "            hidden_dim, hidden_dim).uniform_(-0.1, 0.1))\n",
    "\n",
    "    def forward(self,\n",
    "                query, # [seq_len, batch, hidden_dim]\n",
    "                values, # [seq_len, batch, hidden_dim]\n",
    "                sentences_len\n",
    "               ):\n",
    "        weights = self._get_weights(query, values) # [batch,seq_length,hidden_dim]\n",
    "        # mask the weights\n",
    "        inverted_pad_mask = torch.arange(max(sentences_len))[None,:] > sentences_len[:,None]\n",
    "        inverted_pad_mask = (inverted_pad_mask.float()*(-10000)).unsqueeze(1).to(device)\n",
    "#         print(weights.shape,inverted_pad_mask.shape )\n",
    "        #apply the mask\n",
    "        weights = weights - inverted_pad_mask\n",
    "        \n",
    "        weights = torch.nn.functional.softmax(weights, dim=-1)\n",
    "        \n",
    "        out = torch.transpose((weights @ torch.transpose(values,0,1)),0,1)\n",
    "#         print(\"ATT out shape\", out.shape)\n",
    "        return out # [seq_len,batch,encoder_dim]\n",
    "\n",
    "    def _get_weights(self,\n",
    "        query: torch.Tensor,  # [decoder_dim]\n",
    "        values: torch.Tensor, # [seq_length, encoder_dim]\n",
    "    ):\n",
    "        #transpose to batch first to correctly handle batch multiplications\n",
    "#         print(\"shape\",query.shape,self.W.shape, values.shape)\n",
    "        query,values = torch.transpose(query,0,1),torch.transpose(values,0,1)\n",
    "#         print(\"shape\",query.shape,self.W.shape, values.shape)\n",
    "#         print(\"stape values.t\", torch.transpose(values,1,2).shape)\n",
    "        weights = query @ self.W @ torch.transpose(values,1,2)  # [seq_length]\n",
    "#         print(\"out att shape\", weights.shape)\n",
    "        return weights/np.sqrt(self.hidden_dim)  # [seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNMultAttentionTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNMultAttentionTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='mean',ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "        # attention function\n",
    "        self.attention = torch.nn.MultiheadAttention(hidden_dim,num_heads= 1)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "        # compute padding mask (True when padded, ignore True)\n",
    "        inverted_pad_mask = torch.arange(max(sentences_len))[None,:] > sentences_len[:,None]\n",
    "        \n",
    "        # use attention\n",
    "        attn_applied, _ = self.attention(rnn_out,rnn_out,rnn_out,key_padding_mask = inverted_pad_mask.to(device))\n",
    "        \n",
    "        out = self.top_layer(attn_applied)\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        return [predicted[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXixmVQfvw8T"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3m_nj4HCuCe1"
   },
   "outputs": [],
   "source": [
    "# TODO: search over the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "uAMSIlw0AJb6"
   },
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, train_dataloader, val_dataloader, n_epochs):\n",
    "    history = defaultdict(list)  \n",
    "    for i_epoch in range(1,n_epochs +1):\n",
    "        t0 = time.time()\n",
    "        loss_sum = 0\n",
    "        accuracy_sum = 0\n",
    "        model.train()\n",
    "        for seqs, targets, lens in train_dataloader: #seqs, targets, lens are batches\n",
    "            seqs, targets = seqs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "#             print(\"input seq shape:\",seqs.shape)\n",
    "\n",
    "#             loss = model(seqs,targets,lens) / sum(lens) #normalize for the number of symbol considered (without padding)\n",
    "            loss = model(seqs,targets,lens)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            predicted = model.predict(seqs,lens)\n",
    "            for i,p in enumerate(predicted):\n",
    "                acc= accuracy_score(p,targets[:,i][:len(p)].cpu()) #compute the accuracy without considering the padding\n",
    "                accuracy_sum += acc/len(lens) #normalize according to the number of sequences in the batch\n",
    "\n",
    "        train_loss = loss_sum/len(train_dataloader)\n",
    "        train_accuracy = accuracy_sum/len(train_dataloader) #normalize according to the number of batches\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_accuracy\"].append(train_accuracy)\n",
    "\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        all_predicted = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for seqs,targets, lens in val_dataloader:\n",
    "                # Predict the model's output on a batch\n",
    "                predicted = model.predict(seqs.to(device),lens)                   \n",
    "                # Update the lists that will be used to compute the accuracy\n",
    "                for i,p in enumerate(predicted):\n",
    "                    all_predicted.append(torch.Tensor(p))\n",
    "                    all_targets.append(targets[0:int(lens[i]),i])\n",
    "                \n",
    "        # Compute the overall accuracy for the validation set\n",
    "        val_accuracy = accuracy_score(torch.cat(all_predicted),torch.cat(all_targets))\n",
    "        history[\"val_accuracy\"].append(val_accuracy)\n",
    "\n",
    "#         save the model\n",
    "        torch.save(model, \"./models/temp/model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "#         files.download(\"model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "\n",
    "    \n",
    "        t1 = time.time()\n",
    "        print(f'Epoch {i_epoch}: train loss = {train_loss:.4f}, train_accuracy: {train_accuracy:.4f},val_accuracy: {val_accuracy:.4f}, time = {t1-t0:.4f}')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del train_dataset\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "2g2st8znpGW_",
    "outputId": "fe232e42-e270-4f5d-9bd8-718bba5e7151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda\n",
      "Epoch 1: train loss = 2.8723, train_accuracy: 0.0988,val_accuracy: 0.2082, time = 148.2217\n",
      "Epoch 2: train loss = 1.7630, train_accuracy: 0.3814,val_accuracy: 0.9071, time = 146.7603\n",
      "Epoch 3: train loss = 1.2579, train_accuracy: 0.4763,val_accuracy: 0.9138, time = 149.0810\n",
      "Epoch 4: train loss = 1.1895, train_accuracy: 0.4804,val_accuracy: 0.8542, time = 150.1754\n",
      "Epoch 5: train loss = 1.1735, train_accuracy: 0.4855,val_accuracy: 0.9163, time = 149.4520\n",
      "Epoch 6: train loss = 1.1775, train_accuracy: 0.4891,val_accuracy: 0.8839, time = 147.5374\n",
      "Epoch 7: train loss = 1.1635, train_accuracy: 0.4853,val_accuracy: 0.9189, time = 149.2480\n",
      "Epoch 8: train loss = 1.1304, train_accuracy: 0.4895,val_accuracy: 0.8953, time = 149.8703\n",
      "Epoch 9: train loss = 1.1453, train_accuracy: 0.4906,val_accuracy: 0.9216, time = 148.4011\n",
      "Epoch 10: train loss = 1.1400, train_accuracy: 0.4936,val_accuracy: 0.9113, time = 148.3447\n",
      "Epoch 11: train loss = 1.1532, train_accuracy: 0.4918,val_accuracy: 0.9208, time = 149.0150\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "n_epochs = 40\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 0.05\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 2\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True,sort=True, truncate = None)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\n",
    "val_dataloader = DataLoader(validation_dataset, batch_size=1, shuffle=False,collate_fn=pad_collate)\n",
    "\n",
    "# model = torch.load(\"./models/temp/model_temp_epoch30-to_restart.pkl\")\n",
    "# model = RNNTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "# model = RNNCRFTagger(len(midi_to_ix)+number_duration_classes,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "model = RNNAttentionTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "# model = RNNMultAttentionTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_WEIGHT, momentum = MOMENTUM,weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "history = training_loop(model,optimizer,train_dataloader,val_dataloader, n_epochs)\n",
    "\n",
    "# After the final evaluation, we print more detailed evaluation statistics,\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.legend(['training loss', 'training accuracy', 'validation_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy:  0.9249589391082182 at epoch 37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc224afca20>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 251,
       "width": 372
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find the best working model on the accuracy\n",
    "max_accuracy = np.max(history['val_accuracy'])\n",
    "best_epoch = np.argmax(history['val_accuracy'])\n",
    "print(\"Best validation accuracy: \",max_accuracy, \"at epoch\",best_epoch)\n",
    "\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.legend(['training loss', 'training accuracy', 'validation_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tTv2BrGbvSHh",
    "outputId": "801ff32d-24dc-4434-a436-17d9ca832214"
   },
   "outputs": [],
   "source": [
    "# torch.save(model, \"./models/model_asap_crf200dur.pkl\")\n",
    "# files.download(\"model_asap_crf300.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXcmLpCKt28l"
   },
   "source": [
    "## Test on Mdata dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./models/best_multiAttn_acc9730.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BacUqgD5usGL"
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "with open(Path(basepath,'./datasets/aug_musedata.pkl'), 'rb') as fid:\n",
    "     full_mdata_dict_dataset = pickle.load( fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgaUwW2fuwg0",
    "outputId": "89fc5f7d-884a-4ee6-fc34-b3d512f0c4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 different pieces\n",
      "Average number of notes:  858.6319771007974\n"
     ]
    }
   ],
   "source": [
    "mdata_paths = list(set([e[\"original_path\"] for e in full_mdata_dict_dataset ]))\n",
    "\n",
    "# # remove the symbphony No.100 from Haydn because of the enharmonic transposition\n",
    "# paths.remove(\"datasets\\\\opnd\\\\haydndoversyms-10004m.opnd-m\")\n",
    "\n",
    "# print(paths)\n",
    "print(len(mdata_paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_mdata_dict_dataset ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "f-Fg6gJKvNLt"
   },
   "outputs": [],
   "source": [
    "mdata_dataset = PSDataset(full_mdata_dict_dataset,mdata_paths, transform_chrom,transform_diat,False)\n",
    "mdata_dataloader  = DataLoader(mdata_dataset,  batch_size=1, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ml905Mtdvj-T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "all_inputs = []\n",
    "all_outputs = []\n",
    "all_targets = []\n",
    "model.eval() # Evaluation mode (e.g. disable dropout)\n",
    "with torch.no_grad(): # Disable gradient tracking\n",
    "    for seqs, targets,lens in mdata_dataloader:\n",
    "        # Move data to device\n",
    "        seqs = seqs.to(device)\n",
    "\n",
    "        # Predict the model's output on a batch.\n",
    "        predicted = model.predict(seqs,lens)                   \n",
    "        # Update the evaluation statistics.\n",
    "        for i,p in enumerate(predicted):\n",
    "            all_inputs.append(torch.argmax(seqs[0:int(lens[i]),i,:].cpu(),1).numpy())\n",
    "            all_outputs.append(torch.Tensor(p))\n",
    "            all_targets.append(targets[0:int(lens[i]),i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsefdSHxvrWy",
    "outputId": "33785b90-5e03-4a6d-86dd-92b6b763a505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moz', 'tel', 'viv', 'hay', 'bac', 'cor', 'bee', 'han']\n"
     ]
    }
   ],
   "source": [
    "# Divide accuracy according to author\n",
    "authors = []\n",
    "\n",
    "for sequence in all_inputs:\n",
    "    author = [e[\"original_path\"].split(\"\\\\\")[-1][:3] for e in full_mdata_dict_dataset\n",
    "              if len(e[\"midi_number\"]) == len(sequence) and\n",
    "              list(e[\"midi_number\"]) ==list(sequence) ]\n",
    "    # assert len(author) == 1\n",
    "    authors.append(author[0])\n",
    "\n",
    "considered_authors = list(set(authors))\n",
    "print(considered_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgNt_yG7vrfd",
    "outputId": "8473393f-dac6-4930-9d9e-da9c1046f1ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'moz': 149, 'tel': 46, 'viv': 53, 'hay': 256, 'bac': 34, 'cor': 20, 'bee': 155, 'han': 50}\n",
      "{'moz': 0.9939168776026782, 'tel': 0.9981224489795918, 'viv': 0.9978364697718088, 'hay': 0.9895467537770518, 'bac': 0.9986125280554988, 'cor': 0.9991834401665782, 'bee': 0.9936716612909811, 'han': 0.9979591836734694}\n",
      "{'moz': 24494, 'tel': 24500, 'viv': 24497, 'hay': 24490, 'bac': 24505, 'cor': 24493, 'bee': 24493, 'han': 24500}\n",
      "Total errors : 763\n"
     ]
    }
   ],
   "source": [
    "errors_per_author = {}\n",
    "accuracy_per_author = {}\n",
    "notes_per_author = {}\n",
    "for ca in considered_authors:\n",
    "    # ca_inputs = torch.cat([all_inputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_outputs = torch.cat([all_outputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_targets = torch.cat([all_targets[i] for i,a in enumerate(authors) if a == ca])\n",
    "    # print(ca_inputs.shape,ca_outputs.shape,ca_targets.shape,ca_predicted_pitches.shape)\n",
    "    ca_acc = accuracy_score(ca_outputs,ca_targets)\n",
    "    accuracy_per_author[ca] = float(ca_acc)\n",
    "    errors_per_author[ca] = int(len(ca_targets) - sum(torch.eq(ca_outputs,ca_targets)))\n",
    "    notes_per_author[ca] = len(ca_targets)\n",
    "\n",
    "print(errors_per_author)\n",
    "print(accuracy_per_author)\n",
    "print(notes_per_author)\n",
    "print(\"Total errors :\", sum([e for e in errors_per_author.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5s0d56evrje"
   },
   "source": [
    "### Best accuracy for now\n",
    "for now best accuracy is with  no CRF (but considering durations) n_epochs = 20\n",
    "n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 0.05\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 8\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "duration_delimiter = automatic calculated\n",
    "\n",
    "Model available in: \"model_RNNTagger9736.pkl\"\n",
    "Epoch 16: train loss = 0.2798, train_accuracy: 0.9245,val_accuracy: 0.9736, time = 78.1199\n",
    "Trained on all dataset\n",
    "\n",
    "\n",
    "{'moz': 65, 'bac': 40, 'bee': 88, 'cor': 6, 'han': 8, 'viv': 63, 'tel': 21, 'hay': 262}\n",
    "{'moz': 0.9973462888870744, 'bac': 0.9983676800652928, 'bee': 0.9964071367329441, 'cor': 0.9997550320499735, 'han': 0.9996734693877551, 'viv': 0.9974282565212067, 'tel': 0.9991428571428571, 'hay': 0.9893017558187015}\n",
    "{'moz': 24494, 'bac': 24505, 'bee': 24493, 'cor': 24493, 'han': 24500, 'viv': 24497, 'tel': 24500, 'hay': 24490}\n",
    "Total errors : 553\n",
    "\n",
    "This win by far against ps13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVvP1eH8vrl3"
   },
   "source": [
    "### Best accuracy with CRF\n",
    "n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 1\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "model = RNNCRFTagger(len(midi_to_ix)+len(duration_delimiter)+2,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "\n",
    "Model available in: \"\"./models/model_temp_CRFacc9548.pkl\"\"\n",
    "accuracy on validation set 0.9548586557910835\n",
    "Trained on all asap dataset\n",
    "\n",
    "{'viv': 36, 'tel': 41, 'bee': 185, 'bac': 101, 'han': 44, 'cor': 14, 'moz': 131, 'hay': 376}\n",
    "{'viv': 0.9985304322978323, 'tel': 0.9983265306122449, 'bee': 0.9924468215408484, 'bac': 0.9958783921648643, 'han': 0.9982040816326531, 'cor': 0.9994284081166047, 'moz': 0.9946517514493345, 'hay': 0.9846467946100449}\n",
    "{'viv': 24497, 'tel': 24500, 'bee': 24493, 'bac': 24505, 'han': 24500, 'cor': 24493, 'moz': 24494, 'hay': 24490}\n",
    "Total errors : 928\n",
    "\n",
    "Still win against ps13"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOTDh55Hh2OWCo66dGc+SES",
   "include_colab_link": true,
   "name": "rnncrf_pitch_spelling",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
