{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnncrf_pitch_spelling",
      "provenance": [],
      "authorship_tag": "ABX9TyOTDh55Hh2OWCo66dGc+SES",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fosfrancesco/pitch-spelling/blob/main/rnncrf_pitch_spelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fifMg_hxNSOg",
        "outputId": "a8b320f9-4231-40d9-8f10-a7b8acd1da37"
      },
      "source": [
        "! pip install --upgrade pytorch-crf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsciybUBNkur"
      },
      "source": [
        "import music21 as m21\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import sklearn\r\n",
        "import sklearn.model_selection\r\n",
        "import pickle\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "from pathlib import Path\r\n",
        "import json\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import sklearn.model_selection\r\n",
        "import sklearn\r\n",
        "import music21 as m21\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torchvision import transforms\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torch.utils.data import random_split\r\n",
        "from torch.nn.utils.rnn import pad_sequence\r\n",
        "from torchcrf import CRF\r\n",
        "import torchtext\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "from tqdm import tqdm, tqdm_notebook, notebook\r\n",
        "from google.colab import files\r\n",
        "import pickle\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "import time\r\n",
        "\r\n",
        "from collections import defaultdict, Counter\r\n",
        "# import optuna"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Naq6UG5jRbyK"
      },
      "source": [
        "# RNN-CRF for Pitch Spelling\r\n",
        "\r\n",
        "Dataset: different authors from ASAP collection\r\n",
        "Challenges:\r\n",
        "- extremely long sequences\r\n",
        "- small dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mHJvrZ2Wo_e",
        "outputId": "1319f78b-cfb1-4e2a-937c-c47cf952757c"
      },
      "source": [
        "pitches_dict = {\r\n",
        "    0 : [\"C\",\"B#\",\"D--\"], # nn.Linear(input_size+context_size, 3)\r\n",
        "    1 : [\"C#\",\"B##\",\"D-\"], # nn.Linear(input_size+context_size, 2)\r\n",
        "    2 : [\"D\",\"C##\",\"E--\"], # nn.Linear(input_size+context_size, 3)\r\n",
        "    3 : [\"D#\",\"E-\",\"F--\"],\r\n",
        "    4 : [\"E\",\"D##\",\"F-\"],\r\n",
        "    5 : [\"F\",\"E#\",\"G--\"],\r\n",
        "    6 : [\"F#\",\"E##\",\"G-\"],\r\n",
        "    7 : [\"G\",\"F##\",\"A--\"],\r\n",
        "    8 : [\"G#\",\"A-\"],\r\n",
        "    9 : [\"A\",\"G##\",\"B--\"],\r\n",
        "    10 : [\"A#\",\"B-\",\"C--\"],\r\n",
        "    11 : [\"B\",\"A##\",\"C-\"]\r\n",
        "}\r\n",
        "\r\n",
        "accepted_pitches = [ii for i in pitches_dict.values() for ii in i]\r\n",
        "print([e for e in enumerate(accepted_pitches)])\r\n",
        "\r\n",
        "double_acc_pitches = [ii for i in pitches_dict.values() for ii in i if ii.endswith(\"##\") or  ii.endswith(\"--\") ]\r\n",
        "print(double_acc_pitches)\r\n",
        "\r\n",
        "def score2midi_numbers(score):\r\n",
        "  return [p.midi%12 for n in score.flat.notes for p in n.pitches]\r\n",
        "\r\n",
        "def score2pitches(score):\r\n",
        "  return [p.name for n in score.flat.notes for p in n.pitches]\r\n",
        "\r\n",
        "interval_dict = {\r\n",
        "    0 : [\"P1\",\"d2\",\"A7\"], \r\n",
        "    1 : [\"m2\",\"A1\"], \r\n",
        "    2 : [\"M2\",\"d3\",\"AA1\"], \r\n",
        "    3 : [\"m3\",\"A2\"],\r\n",
        "    4 : [\"M3\",\"d4\",\"AA2\"],\r\n",
        "    5 : [\"P4\",\"A3\"],\r\n",
        "    6 : [\"d5\",\"A4\"],\r\n",
        "    7 : [\"P5\",\"d6\",\"AA4\"],\r\n",
        "    8 : [\"m6\",\"A5\"],\r\n",
        "    9 : [\"M6\",\"d7\",\"AA5\"],\r\n",
        "    10 : [\"m7\",\"A6\"],\r\n",
        "    11 : [\"M7\",\"d1\",\"AA6\"]\r\n",
        "}\r\n",
        "\r\n",
        "accepted_intervals = [ii for i in interval_dict.values() for ii in i]\r\n",
        "print([e for e in enumerate(accepted_intervals)])\r\n",
        "\r\n",
        "def transp_score(score):\r\n",
        "    \"\"\" For each input return len(accepted_intervals) transposed scores\"\"\"\r\n",
        "    return [score.transpose(interval) for interval in accepted_intervals]\r\n",
        "\r\n",
        "def smart_transp_score(score):\r\n",
        "    \"\"\" For each chromatic interval chose the interval that lead to the smallest number of accidentals\"\"\"\r\n",
        "    scores = []\r\n",
        "    for chromatic_int in interval_dict.keys():\r\n",
        "        temp_scores = []\r\n",
        "        temp_acc_number = []\r\n",
        "        for diat_interval in interval_dict[chromatic_int]:\r\n",
        "            new_score = score.transpose(diat_interval)\r\n",
        "            temp_scores.append(new_score)\r\n",
        "            temp_acc_number.append(sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in score2pitches(new_score)]))\r\n",
        "            # print(\"choice:\", [note.name for note in temp_scores[-1].flat.notes][0:10],\"acc:\",temp_acc_number[-1] )\r\n",
        "        #keep only the one with the lowest number of accidentals\r\n",
        "        min_index = np.argmin(temp_acc_number)\r\n",
        "        # print(\"preferred the number\", min_index)\r\n",
        "        scores.append(temp_scores[min_index])\r\n",
        "    return scores\r\n",
        "\r\n",
        "def acc_simple_enough(score,accepted_ratio = 0.2 ):\r\n",
        "    pitches = score2pitches(score)\r\n",
        "    double_acc = sum(el in double_acc_pitches for el in pitches)\r\n",
        "    if double_acc/len(pitches) < accepted_ratio:\r\n",
        "        return True\r\n",
        "    else:\r\n",
        "        return False\r\n",
        "\r\n",
        "def argmax(vec):\r\n",
        "    # return the argmax as a python int\r\n",
        "    _, idx = torch.max(vec, 1)\r\n",
        "    return idx.item()\r\n",
        "\r\n",
        "\r\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\r\n",
        "def log_sum_exp(vec):\r\n",
        "    max_score = vec[0, argmax(vec)]\r\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\r\n",
        "    return max_score + \\\r\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\r\n",
        "\r\n",
        "\r\n",
        "diatonic_pitches = [\"C\",\"D\", \"E\", \"F\", \"G\", \"A\", \"B\"]\r\n",
        "\r\n",
        "# #test acc_simple_enough()\r\n",
        "# score = m21.converter.parse(paths[356])\r\n",
        "# scores = smart_transp_score(score)\r\n",
        "# #delete the pieces with non accepted pitches (e.g. triple sharps)\r\n",
        "# scores = [s for s in scores if all(pitch in accepted_pitches for pitch in score2pitches(s))]\r\n",
        "# for s in scores:\r\n",
        "#     print(s.parts[0].flat.getElementsByClass(m21.key.KeySignature)[0], \"simple enough:\", acc_simple_enough(s))\r\n",
        "#     print([n.name for n in s.flat.notes])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 'C'), (1, 'B#'), (2, 'D--'), (3, 'C#'), (4, 'B##'), (5, 'D-'), (6, 'D'), (7, 'C##'), (8, 'E--'), (9, 'D#'), (10, 'E-'), (11, 'F--'), (12, 'E'), (13, 'D##'), (14, 'F-'), (15, 'F'), (16, 'E#'), (17, 'G--'), (18, 'F#'), (19, 'E##'), (20, 'G-'), (21, 'G'), (22, 'F##'), (23, 'A--'), (24, 'G#'), (25, 'A-'), (26, 'A'), (27, 'G##'), (28, 'B--'), (29, 'A#'), (30, 'B-'), (31, 'C--'), (32, 'B'), (33, 'A##'), (34, 'C-')]\n",
            "['D--', 'B##', 'C##', 'E--', 'F--', 'D##', 'G--', 'E##', 'F##', 'A--', 'G##', 'B--', 'C--', 'A##']\n",
            "[(0, 'P1'), (1, 'd2'), (2, 'A7'), (3, 'm2'), (4, 'A1'), (5, 'M2'), (6, 'd3'), (7, 'AA1'), (8, 'm3'), (9, 'A2'), (10, 'M3'), (11, 'd4'), (12, 'AA2'), (13, 'P4'), (14, 'A3'), (15, 'd5'), (16, 'A4'), (17, 'P5'), (18, 'd6'), (19, 'AA4'), (20, 'm6'), (21, 'A5'), (22, 'M6'), (23, 'd7'), (24, 'AA5'), (25, 'm7'), (26, 'A6'), (27, 'M7'), (28, 'd1'), (29, 'AA6')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw-SuL4ZB_2C"
      },
      "source": [
        "## Import ASAP dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrZ0BwLEj2Gp",
        "outputId": "6b521f78-28db-4d4f-f4ef-9345c5d91db9"
      },
      "source": [
        "!git clone https://github.com/fosfrancesco/pitch-spelling.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pitch-spelling'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 42 (delta 16), reused 14 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (42/42), done.\n",
            "Checking out files: 100% (11/11), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaINjDS2kpxE"
      },
      "source": [
        "basepath = \"/content/pitch-spelling\" #to change if running locally\r\n",
        "\r\n",
        "# load the asap datasets\r\n",
        "with open(Path(basepath,'datasets','baroque_asap.pkl'), 'rb') as fid:\r\n",
        "     dataset_baroque = pickle.load( fid)\r\n",
        "\r\n",
        "with open(Path(basepath,'datasets','classical_asap.pkl'), 'rb') as fid:\r\n",
        "     dataset_classical = pickle.load( fid)\r\n",
        "\r\n",
        "with open(Path(basepath,'datasets','romantic_asap.pkl'), 'rb') as fid:\r\n",
        "     dataset_romantic = pickle.load( fid)\r\n",
        "\r\n",
        "# merge the two files together\r\n",
        "full_dict_dataset = dataset_baroque + dataset_classical + dataset_romantic\r\n",
        "# full_dict_dataset = dataset_baroque + dataset_classical"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYQdkJAiTS6_",
        "outputId": "72835948-2884-40bb-e5b4-6ebbc8488895"
      },
      "source": [
        "paths = list(set([e[\"original_path\"] for e in full_dict_dataset ]))\r\n",
        "\r\n",
        "# print(paths)\r\n",
        "print(len(paths), \"different pieces\")\r\n",
        "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_dict_dataset ]))\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "191 different pieces\n",
            "Average number of notes:  2219.6285387474977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMdKkzNnCTrK"
      },
      "source": [
        "## Chose the convenient data augmentation\r\n",
        "Two possibilities:\r\n",
        "- for each chromatic interval, take only the diatonic transposition that produce the smallest number of accidentals (or the original if present)\r\n",
        "- take only a certain interval of time signatures\r\n",
        "\r\n",
        "The second is probably better for a smaller and simple dataset, but gives the problem of chosing between for example F# and G# that are both present in this bigger dataset. So we go for the first criterion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oign7EZ9BSX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa3f694-289a-43fd-fd14-9cad3b8dd3b7"
      },
      "source": [
        "# choose only one enharmonic version for each chromatic interval for each piece\r\n",
        "dict_dataset = []\r\n",
        "for path in paths:\r\n",
        "    for c in range(12):\r\n",
        "        pieces_to_consider = [opus for opus in full_dict_dataset \r\n",
        "                              if (opus[\"original_path\"] == path and opus[\"transposed_of\"] in interval_dict[c])  ]\r\n",
        "        # if the original is in pieces_to_consider, go with the original\r\n",
        "        originals = [opus for opus in pieces_to_consider if opus[\"transposed_of\"] == \"P1\"]\r\n",
        "        if len(originals) == 1:\r\n",
        "            dict_dataset.append(originals[0])\r\n",
        "        else: #we go with the accidental minization criteria\r\n",
        "            n_accidentals = [sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in opus[\"pitches\"]]) \r\n",
        "                            for opus in pieces_to_consider]\r\n",
        "            if len(pieces_to_consider)>0:\r\n",
        "                dict_dataset.append(pieces_to_consider[np.argmin(n_accidentals)])\r\n",
        "            else:\r\n",
        "                print(\"No options for\", path, \". Chromatic: \",c )\r\n",
        "\r\n",
        "# accepted_ks = range(-5,6)\r\n",
        "# dict_dataset = [e for e in full_dict_dataset if e[\"key_signature\"] in accepted_ks]\r\n",
        "\r\n",
        "#test if it worked\r\n",
        "for i,e in enumerate(dict_dataset):\r\n",
        "    print(e[\"original_path\"], e[\"transposed_of\"], e[\"key_signature\"])\r\n",
        "    print(e[\"pitches\"][:10])\r\n",
        "    print(e[\"midi_number\"][:10])\r\n",
        "    if i == 100:\r\n",
        "        break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No options for Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml . Chromatic:  1\n",
            "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  4\n",
            "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  6\n",
            "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  9\n",
            "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  11\n",
            "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  4\n",
            "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  9\n",
            "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  4\n",
            "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  9\n",
            "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  1\n",
            "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  4\n",
            "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  6\n",
            "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  9\n",
            "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  11\n",
            "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  1\n",
            "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  3\n",
            "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  6\n",
            "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  8\n",
            "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  10\n",
            "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  11\n",
            "No options for Chopin/Ballades/4/xml_score.musicxml . Chromatic:  6\n",
            "Haydn/Keyboard_Sonatas/48-2/xml_score.musicxml P1 0\n",
            "['G', 'G', 'A', 'G', 'C', 'E', 'F', 'E', 'E', 'D']\n",
            "[7, 7, 9, 7, 0, 4, 5, 4, 4, 2]\n",
            "Haydn/Keyboard_Sonatas/48-2/xml_score.musicxml m2 -5\n",
            "['A-', 'A-', 'B-', 'A-', 'D-', 'F', 'G-', 'F', 'F', 'E-']\n",
            "[8, 8, 10, 8, 1, 5, 6, 5, 5, 3]\n",
            "Haydn/Keyboard_Sonatas/48-2/xml_score.musicxml M2 2\n",
            "['A', 'A', 'B', 'A', 'D', 'F#', 'G', 'F#', 'F#', 'E']\n",
            "[9, 9, 11, 9, 2, 6, 7, 6, 6, 4]\n",
            "Haydn/Keyboard_Sonatas/48-2/xml_score.musicxml m3 -3\n",
            "['B-', 'B-', 'C', 'B-', 'E-', 'G', 'A-', 'G', 'G', 'F']\n",
            "[10, 10, 0, 10, 3, 7, 8, 7, 7, 5]\n",
            "Haydn/Keyboard_Sonatas/48-2/xml_score.musicxml M3 4\n",
            "['B', 'B', 'C#', 'B', 'E', 'G#', 'A', 'G#', 'G#', 'F#']\n",
            "[11, 11, 1, 11, 4, 8, 9, 8, 8, 6]\n",
            "Haydn/Keyboard_Sonatas/48-2/xml_score.musicxml P4 -1\n",
            "['C', 'C', 'D', 'C', 'F', 'A', 'B-', 'A', 'A', 'G']\n",
            "[0, 0, 2, 0, 5, 9, 10, 9, 9, 7]\n",
            "Haydn/Keyboard_Sonatas/48-2/xml_score.musicxml A4 6\n",
            "['C#', 'C#', 'D#', 'C#', 'F#', 'A#', 'B', 'A#', 'A#', 'G#']\n",
            "[1, 1, 3, 1, 6, 10, 11, 10, 10, 8]\n",
            "Haydn/Keyboard_Sonatas/48-2/xml_score.musicxml P5 1\n",
            "['D', 'D', 'E', 'D', 'G', 'B', 'C', 'B', 'B', 'A']\n",
            "[2, 2, 4, 2, 7, 11, 0, 11, 11, 9]\n",
            "Haydn/Keyboard_Sonatas/48-2/xml_score.musicxml m6 -4\n",
            "['E-', 'E-', 'F', 'E-', 'A-', 'C', 'D-', 'C', 'C', 'B-']\n",
            "[3, 3, 5, 3, 8, 0, 1, 0, 0, 10]\n",
            "Haydn/Keyboard_Sonatas/48-2/xml_score.musicxml M6 3\n",
            "['E', 'E', 'F#', 'E', 'A', 'C#', 'D', 'C#', 'C#', 'B']\n",
            "[4, 4, 6, 4, 9, 1, 2, 1, 1, 11]\n",
            "Haydn/Keyboard_Sonatas/48-2/xml_score.musicxml m7 -2\n",
            "['F', 'F', 'G', 'F', 'B-', 'D', 'E-', 'D', 'D', 'C']\n",
            "[5, 5, 7, 5, 10, 2, 3, 2, 2, 0]\n",
            "Haydn/Keyboard_Sonatas/48-2/xml_score.musicxml M7 5\n",
            "['F#', 'F#', 'G#', 'F#', 'B', 'D#', 'E', 'D#', 'D#', 'C#']\n",
            "[6, 6, 8, 6, 11, 3, 4, 3, 3, 1]\n",
            "Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml P1 -5\n",
            "['D-', 'D-', 'E', 'E', 'E', 'E', 'C#', 'G#', 'C#', 'D-']\n",
            "[1, 1, 4, 4, 4, 4, 1, 8, 1, 1]\n",
            "Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml M2 -3\n",
            "['E-', 'E-', 'F#', 'F#', 'F#', 'F#', 'D#', 'A#', 'D#', 'E-']\n",
            "[3, 3, 6, 6, 6, 6, 3, 10, 3, 3]\n",
            "Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml m3 -8\n",
            "['F-', 'F-', 'G', 'G', 'G', 'G', 'E', 'B', 'E', 'F-']\n",
            "[4, 4, 7, 7, 7, 7, 4, 11, 4, 4]\n",
            "Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml M3 -1\n",
            "['F', 'F', 'G#', 'G#', 'G#', 'G#', 'E#', 'B#', 'E#', 'F']\n",
            "[5, 5, 8, 8, 8, 8, 5, 0, 5, 5]\n",
            "Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml P4 -6\n",
            "['G-', 'G-', 'A', 'A', 'A', 'A', 'F#', 'C#', 'F#', 'G-']\n",
            "[6, 6, 9, 9, 9, 9, 6, 1, 6, 6]\n",
            "Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml A4 1\n",
            "['G', 'G', 'A#', 'A#', 'A#', 'A#', 'F##', 'C##', 'F##', 'G']\n",
            "[7, 7, 10, 10, 10, 10, 7, 2, 7, 7]\n",
            "Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml P5 -4\n",
            "['A-', 'A-', 'B', 'B', 'B', 'B', 'G#', 'D#', 'G#', 'A-']\n",
            "[8, 8, 11, 11, 11, 11, 8, 3, 8, 8]\n",
            "Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml m6 -9\n",
            "['B--', 'B--', 'C', 'C', 'C', 'C', 'A', 'E', 'A', 'B--']\n",
            "[9, 9, 0, 0, 0, 0, 9, 4, 9, 9]\n",
            "Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml M6 -2\n",
            "['B-', 'B-', 'C#', 'C#', 'C#', 'C#', 'A#', 'E#', 'A#', 'B-']\n",
            "[10, 10, 1, 1, 1, 1, 10, 5, 10, 10]\n",
            "Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml m7 -7\n",
            "['C-', 'C-', 'D', 'D', 'D', 'D', 'B', 'F#', 'B', 'C-']\n",
            "[11, 11, 2, 2, 2, 2, 11, 6, 11, 11]\n",
            "Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml M7 0\n",
            "['C', 'C', 'D#', 'D#', 'D#', 'D#', 'B#', 'F##', 'B#', 'C']\n",
            "[0, 0, 3, 3, 3, 3, 0, 7, 0, 0]\n",
            "Bach/Fugue/bwv_883/xml_score.musicxml P1 3\n",
            "['C#', 'A', 'F#', 'D', 'D', 'C#', 'B', 'C#', 'C#', 'F#']\n",
            "[1, 9, 6, 2, 2, 1, 11, 1, 1, 6]\n",
            "Bach/Fugue/bwv_883/xml_score.musicxml m2 -2\n",
            "['D', 'B-', 'G', 'E-', 'E-', 'D', 'C', 'D', 'D', 'G']\n",
            "[2, 10, 7, 3, 3, 2, 0, 2, 2, 7]\n",
            "Bach/Fugue/bwv_883/xml_score.musicxml M2 5\n",
            "['D#', 'B', 'G#', 'E', 'E', 'D#', 'C#', 'D#', 'D#', 'G#']\n",
            "[3, 11, 8, 4, 4, 3, 1, 3, 3, 8]\n",
            "Bach/Fugue/bwv_883/xml_score.musicxml m3 0\n",
            "['E', 'C', 'A', 'F', 'F', 'E', 'D', 'E', 'E', 'A']\n",
            "[4, 0, 9, 5, 5, 4, 2, 4, 4, 9]\n",
            "Bach/Fugue/bwv_883/xml_score.musicxml d4 -5\n",
            "['F', 'D-', 'B-', 'G-', 'G-', 'F', 'E-', 'F', 'F', 'B-']\n",
            "[5, 1, 10, 6, 6, 5, 3, 5, 5, 10]\n",
            "Bach/Fugue/bwv_883/xml_score.musicxml P4 2\n",
            "['F#', 'D', 'B', 'G', 'G', 'F#', 'E', 'F#', 'F#', 'B']\n",
            "[6, 2, 11, 7, 7, 6, 4, 6, 6, 11]\n",
            "Bach/Fugue/bwv_883/xml_score.musicxml d5 -3\n",
            "['G', 'E-', 'C', 'A-', 'A-', 'G', 'F', 'G', 'G', 'C']\n",
            "[7, 3, 0, 8, 8, 7, 5, 7, 7, 0]\n",
            "Bach/Fugue/bwv_883/xml_score.musicxml P5 4\n",
            "['G#', 'E', 'C#', 'A', 'A', 'G#', 'F#', 'G#', 'G#', 'C#']\n",
            "[8, 4, 1, 9, 9, 8, 6, 8, 8, 1]\n",
            "Bach/Fugue/bwv_883/xml_score.musicxml m6 -1\n",
            "['A', 'F', 'D', 'B-', 'B-', 'A', 'G', 'A', 'A', 'D']\n",
            "[9, 5, 2, 10, 10, 9, 7, 9, 9, 2]\n",
            "Bach/Fugue/bwv_883/xml_score.musicxml d7 -6\n",
            "['B-', 'G-', 'E-', 'C-', 'C-', 'B-', 'A-', 'B-', 'B-', 'E-']\n",
            "[10, 6, 3, 11, 11, 10, 8, 10, 10, 3]\n",
            "Bach/Fugue/bwv_883/xml_score.musicxml m7 1\n",
            "['B', 'G', 'E', 'C', 'C', 'B', 'A', 'B', 'B', 'E']\n",
            "[11, 7, 4, 0, 0, 11, 9, 11, 11, 4]\n",
            "Bach/Fugue/bwv_883/xml_score.musicxml d1 -4\n",
            "['C', 'A-', 'F', 'D-', 'D-', 'C', 'B-', 'C', 'C', 'F']\n",
            "[0, 8, 5, 1, 1, 0, 10, 0, 0, 5]\n",
            "Bach/Prelude/bwv_885/xml_score.musicxml P1 -2\n",
            "['G', 'G', 'D', 'F', 'E-', 'B-', 'A', 'C', 'E-', 'F#']\n",
            "[7, 7, 2, 5, 3, 10, 9, 0, 3, 6]\n",
            "Bach/Prelude/bwv_885/xml_score.musicxml A1 5\n",
            "['G#', 'G#', 'D#', 'F#', 'E', 'B', 'A#', 'C#', 'E', 'F##']\n",
            "[8, 8, 3, 6, 4, 11, 10, 1, 4, 7]\n",
            "Bach/Prelude/bwv_885/xml_score.musicxml M2 0\n",
            "['A', 'A', 'E', 'G', 'F', 'C', 'B', 'D', 'F', 'G#']\n",
            "[9, 9, 4, 7, 5, 0, 11, 2, 5, 8]\n",
            "Bach/Prelude/bwv_885/xml_score.musicxml m3 -5\n",
            "['B-', 'B-', 'F', 'A-', 'G-', 'D-', 'C', 'E-', 'G-', 'A']\n",
            "[10, 10, 5, 8, 6, 1, 0, 3, 6, 9]\n",
            "Bach/Prelude/bwv_885/xml_score.musicxml M3 2\n",
            "['B', 'B', 'F#', 'A', 'G', 'D', 'C#', 'E', 'G', 'A#']\n",
            "[11, 11, 6, 9, 7, 2, 1, 4, 7, 10]\n",
            "Bach/Prelude/bwv_885/xml_score.musicxml P4 -3\n",
            "['C', 'C', 'G', 'B-', 'A-', 'E-', 'D', 'F', 'A-', 'B']\n",
            "[0, 0, 7, 10, 8, 3, 2, 5, 8, 11]\n",
            "Bach/Prelude/bwv_885/xml_score.musicxml A4 4\n",
            "['C#', 'C#', 'G#', 'B', 'A', 'E', 'D#', 'F#', 'A', 'B#']\n",
            "[1, 1, 8, 11, 9, 4, 3, 6, 9, 0]\n",
            "Bach/Prelude/bwv_885/xml_score.musicxml P5 -1\n",
            "['D', 'D', 'A', 'C', 'B-', 'F', 'E', 'G', 'B-', 'C#']\n",
            "[2, 2, 9, 0, 10, 5, 4, 7, 10, 1]\n",
            "Bach/Prelude/bwv_885/xml_score.musicxml m6 -6\n",
            "['E-', 'E-', 'B-', 'D-', 'C-', 'G-', 'F', 'A-', 'C-', 'D']\n",
            "[3, 3, 10, 1, 11, 6, 5, 8, 11, 2]\n",
            "Bach/Prelude/bwv_885/xml_score.musicxml M6 1\n",
            "['E', 'E', 'B', 'D', 'C', 'G', 'F#', 'A', 'C', 'D#']\n",
            "[4, 4, 11, 2, 0, 7, 6, 9, 0, 3]\n",
            "Bach/Prelude/bwv_885/xml_score.musicxml m7 -4\n",
            "['F', 'F', 'C', 'E-', 'D-', 'A-', 'G', 'B-', 'D-', 'E']\n",
            "[5, 5, 0, 3, 1, 8, 7, 10, 1, 4]\n",
            "Bach/Prelude/bwv_885/xml_score.musicxml M7 3\n",
            "['F#', 'F#', 'C#', 'E', 'D', 'A', 'G#', 'B', 'D', 'E#']\n",
            "[6, 6, 1, 4, 2, 9, 8, 11, 2, 5]\n",
            "Beethoven/Piano_Sonatas/17-1/xml_score.musicxml P1 -1\n",
            "['C#', 'E', 'A', 'C#', 'E', 'A', 'C#', 'E', 'A', 'C#']\n",
            "[1, 4, 9, 1, 4, 9, 1, 4, 9, 1]\n",
            "Beethoven/Piano_Sonatas/17-1/xml_score.musicxml m2 -6\n",
            "['D', 'F', 'B-', 'D', 'F', 'B-', 'D', 'F', 'B-', 'D']\n",
            "[2, 5, 10, 2, 5, 10, 2, 5, 10, 2]\n",
            "Beethoven/Piano_Sonatas/17-1/xml_score.musicxml M2 1\n",
            "['D#', 'F#', 'B', 'D#', 'F#', 'B', 'D#', 'F#', 'B', 'D#']\n",
            "[3, 6, 11, 3, 6, 11, 3, 6, 11, 3]\n",
            "Beethoven/Piano_Sonatas/17-1/xml_score.musicxml m3 -4\n",
            "['E', 'G', 'C', 'E', 'G', 'C', 'E', 'G', 'C', 'E']\n",
            "[4, 7, 0, 4, 7, 0, 4, 7, 0, 4]\n",
            "Beethoven/Piano_Sonatas/17-1/xml_score.musicxml M3 3\n",
            "['E#', 'G#', 'C#', 'E#', 'G#', 'C#', 'E#', 'G#', 'C#', 'E#']\n",
            "[5, 8, 1, 5, 8, 1, 5, 8, 1, 5]\n",
            "Beethoven/Piano_Sonatas/17-1/xml_score.musicxml P4 -2\n",
            "['F#', 'A', 'D', 'F#', 'A', 'D', 'F#', 'A', 'D', 'F#']\n",
            "[6, 9, 2, 6, 9, 2, 6, 9, 2, 6]\n",
            "Beethoven/Piano_Sonatas/17-1/xml_score.musicxml d5 -7\n",
            "['G', 'B-', 'E-', 'G', 'B-', 'E-', 'G', 'B-', 'E-', 'G']\n",
            "[7, 10, 3, 7, 10, 3, 7, 10, 3, 7]\n",
            "Beethoven/Piano_Sonatas/17-1/xml_score.musicxml P5 0\n",
            "['G#', 'B', 'E', 'G#', 'B', 'E', 'G#', 'B', 'E', 'G#']\n",
            "[8, 11, 4, 8, 11, 4, 8, 11, 4, 8]\n",
            "Beethoven/Piano_Sonatas/17-1/xml_score.musicxml m6 -5\n",
            "['A', 'C', 'F', 'A', 'C', 'F', 'A', 'C', 'F', 'A']\n",
            "[9, 0, 5, 9, 0, 5, 9, 0, 5, 9]\n",
            "Beethoven/Piano_Sonatas/17-1/xml_score.musicxml M6 2\n",
            "['A#', 'C#', 'F#', 'A#', 'C#', 'F#', 'A#', 'C#', 'F#', 'A#']\n",
            "[10, 1, 6, 10, 1, 6, 10, 1, 6, 10]\n",
            "Beethoven/Piano_Sonatas/17-1/xml_score.musicxml m7 -3\n",
            "['B', 'D', 'G', 'B', 'D', 'G', 'B', 'D', 'G', 'B']\n",
            "[11, 2, 7, 11, 2, 7, 11, 2, 7, 11]\n",
            "Beethoven/Piano_Sonatas/17-1/xml_score.musicxml d1 -8\n",
            "['C', 'E-', 'A-', 'C', 'E-', 'A-', 'C', 'E-', 'A-', 'C']\n",
            "[0, 3, 8, 0, 3, 8, 0, 3, 8, 0]\n",
            "Beethoven/Piano_Sonatas/22-2/xml_score.musicxml P1 -1\n",
            "['F', 'A', 'C', 'F', 'G', 'E', 'A', 'F', 'B-', 'G']\n",
            "[5, 9, 0, 5, 7, 4, 9, 5, 10, 7]\n",
            "Beethoven/Piano_Sonatas/22-2/xml_score.musicxml A1 6\n",
            "['F#', 'A#', 'C#', 'F#', 'G#', 'E#', 'A#', 'F#', 'B', 'G#']\n",
            "[6, 10, 1, 6, 8, 5, 10, 6, 11, 8]\n",
            "Beethoven/Piano_Sonatas/22-2/xml_score.musicxml M2 1\n",
            "['G', 'B', 'D', 'G', 'A', 'F#', 'B', 'G', 'C', 'A']\n",
            "[7, 11, 2, 7, 9, 6, 11, 7, 0, 9]\n",
            "Beethoven/Piano_Sonatas/22-2/xml_score.musicxml m3 -4\n",
            "['A-', 'C', 'E-', 'A-', 'B-', 'G', 'C', 'A-', 'D-', 'B-']\n",
            "[8, 0, 3, 8, 10, 7, 0, 8, 1, 10]\n",
            "Beethoven/Piano_Sonatas/22-2/xml_score.musicxml M3 3\n",
            "['A', 'C#', 'E', 'A', 'B', 'G#', 'C#', 'A', 'D', 'B']\n",
            "[9, 1, 4, 9, 11, 8, 1, 9, 2, 11]\n",
            "Beethoven/Piano_Sonatas/22-2/xml_score.musicxml P4 -2\n",
            "['B-', 'D', 'F', 'B-', 'C', 'A', 'D', 'B-', 'E-', 'C']\n",
            "[10, 2, 5, 10, 0, 9, 2, 10, 3, 0]\n",
            "Beethoven/Piano_Sonatas/22-2/xml_score.musicxml A4 5\n",
            "['B', 'D#', 'F#', 'B', 'C#', 'A#', 'D#', 'B', 'E', 'C#']\n",
            "[11, 3, 6, 11, 1, 10, 3, 11, 4, 1]\n",
            "Beethoven/Piano_Sonatas/22-2/xml_score.musicxml P5 0\n",
            "['C', 'E', 'G', 'C', 'D', 'B', 'E', 'C', 'F', 'D']\n",
            "[0, 4, 7, 0, 2, 11, 4, 0, 5, 2]\n",
            "Beethoven/Piano_Sonatas/22-2/xml_score.musicxml m6 -5\n",
            "['D-', 'F', 'A-', 'D-', 'E-', 'C', 'F', 'D-', 'G-', 'E-']\n",
            "[1, 5, 8, 1, 3, 0, 5, 1, 6, 3]\n",
            "Beethoven/Piano_Sonatas/22-2/xml_score.musicxml M6 2\n",
            "['D', 'F#', 'A', 'D', 'E', 'C#', 'F#', 'D', 'G', 'E']\n",
            "[2, 6, 9, 2, 4, 1, 6, 2, 7, 4]\n",
            "Beethoven/Piano_Sonatas/22-2/xml_score.musicxml m7 -3\n",
            "['E-', 'G', 'B-', 'E-', 'F', 'D', 'G', 'E-', 'A-', 'F']\n",
            "[3, 7, 10, 3, 5, 2, 7, 3, 8, 5]\n",
            "Beethoven/Piano_Sonatas/22-2/xml_score.musicxml M7 4\n",
            "['E', 'G#', 'B', 'E', 'F#', 'D#', 'G#', 'E', 'A', 'F#']\n",
            "[4, 8, 11, 4, 6, 3, 8, 4, 9, 6]\n",
            "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml P1 3\n",
            "['A', 'A', 'A', 'C#', 'C#', 'C#', 'A', 'C#', 'C#', 'F#']\n",
            "[9, 9, 9, 1, 1, 1, 9, 1, 1, 6]\n",
            "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml m2 -2\n",
            "['B-', 'B-', 'B-', 'D', 'D', 'D', 'B-', 'D', 'D', 'G']\n",
            "[10, 10, 10, 2, 2, 2, 10, 2, 2, 7]\n",
            "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml M2 5\n",
            "['B', 'B', 'B', 'D#', 'D#', 'D#', 'B', 'D#', 'D#', 'G#']\n",
            "[11, 11, 11, 3, 3, 3, 11, 3, 3, 8]\n",
            "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml m3 0\n",
            "['C', 'C', 'C', 'E', 'E', 'E', 'C', 'E', 'E', 'A']\n",
            "[0, 0, 0, 4, 4, 4, 0, 4, 4, 9]\n",
            "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml d4 -5\n",
            "['D-', 'D-', 'D-', 'F', 'F', 'F', 'D-', 'F', 'F', 'B-']\n",
            "[1, 1, 1, 5, 5, 5, 1, 5, 5, 10]\n",
            "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml P4 2\n",
            "['D', 'D', 'D', 'F#', 'F#', 'F#', 'D', 'F#', 'F#', 'B']\n",
            "[2, 2, 2, 6, 6, 6, 2, 6, 6, 11]\n",
            "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml d5 -3\n",
            "['E-', 'E-', 'E-', 'G', 'G', 'G', 'E-', 'G', 'G', 'C']\n",
            "[3, 3, 3, 7, 7, 7, 3, 7, 7, 0]\n",
            "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml P5 4\n",
            "['E', 'E', 'E', 'G#', 'G#', 'G#', 'E', 'G#', 'G#', 'C#']\n",
            "[4, 4, 4, 8, 8, 8, 4, 8, 8, 1]\n",
            "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml m6 -1\n",
            "['F', 'F', 'F', 'A', 'A', 'A', 'F', 'A', 'A', 'D']\n",
            "[5, 5, 5, 9, 9, 9, 5, 9, 9, 2]\n",
            "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml M6 6\n",
            "['F#', 'F#', 'F#', 'A#', 'A#', 'A#', 'F#', 'A#', 'A#', 'D#']\n",
            "[6, 6, 6, 10, 10, 10, 6, 10, 10, 3]\n",
            "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml m7 1\n",
            "['G', 'G', 'G', 'B', 'B', 'B', 'G', 'B', 'B', 'E']\n",
            "[7, 7, 7, 11, 11, 11, 7, 11, 11, 4]\n",
            "Beethoven/Piano_Sonatas/29-3/xml_score.musicxml d1 -4\n",
            "['A-', 'A-', 'A-', 'C', 'C', 'C', 'A-', 'C', 'C', 'F']\n",
            "[8, 8, 8, 0, 0, 0, 8, 0, 0, 5]\n",
            "Chopin/Etudes_op_10/1/xml_score.musicxml P1 0\n",
            "['C', 'C', 'C', 'G', 'C', 'E', 'C', 'G', 'C', 'E']\n",
            "[0, 0, 0, 7, 0, 4, 0, 7, 0, 4]\n",
            "Chopin/Etudes_op_10/1/xml_score.musicxml m2 -5\n",
            "['D-', 'D-', 'D-', 'A-', 'D-', 'F', 'D-', 'A-', 'D-', 'F']\n",
            "[1, 1, 1, 8, 1, 5, 1, 8, 1, 5]\n",
            "Chopin/Etudes_op_10/1/xml_score.musicxml M2 2\n",
            "['D', 'D', 'D', 'A', 'D', 'F#', 'D', 'A', 'D', 'F#']\n",
            "[2, 2, 2, 9, 2, 6, 2, 9, 2, 6]\n",
            "Chopin/Etudes_op_10/1/xml_score.musicxml m3 -3\n",
            "['E-', 'E-', 'E-', 'B-', 'E-', 'G', 'E-', 'B-', 'E-', 'G']\n",
            "[3, 3, 3, 10, 3, 7, 3, 10, 3, 7]\n",
            "Chopin/Etudes_op_10/1/xml_score.musicxml M3 4\n",
            "['E', 'E', 'E', 'B', 'E', 'G#', 'E', 'B', 'E', 'G#']\n",
            "[4, 4, 4, 11, 4, 8, 4, 11, 4, 8]\n",
            "Chopin/Etudes_op_10/1/xml_score.musicxml P4 -1\n",
            "['F', 'F', 'F', 'C', 'F', 'A', 'F', 'C', 'F', 'A']\n",
            "[5, 5, 5, 0, 5, 9, 5, 0, 5, 9]\n",
            "Chopin/Etudes_op_10/1/xml_score.musicxml d5 -6\n",
            "['G-', 'G-', 'G-', 'D-', 'G-', 'B-', 'G-', 'D-', 'G-', 'B-']\n",
            "[6, 6, 6, 1, 6, 10, 6, 1, 6, 10]\n",
            "Chopin/Etudes_op_10/1/xml_score.musicxml P5 1\n",
            "['G', 'G', 'G', 'D', 'G', 'B', 'G', 'D', 'G', 'B']\n",
            "[7, 7, 7, 2, 7, 11, 7, 2, 7, 11]\n",
            "Chopin/Etudes_op_10/1/xml_score.musicxml m6 -4\n",
            "['A-', 'A-', 'A-', 'E-', 'A-', 'C', 'A-', 'E-', 'A-', 'C']\n",
            "[8, 8, 8, 3, 8, 0, 8, 3, 8, 0]\n",
            "Chopin/Etudes_op_10/1/xml_score.musicxml M6 3\n",
            "['A', 'A', 'A', 'E', 'A', 'C#', 'A', 'E', 'A', 'C#']\n",
            "[9, 9, 9, 4, 9, 1, 9, 4, 9, 1]\n",
            "Chopin/Etudes_op_10/1/xml_score.musicxml m7 -2\n",
            "['B-', 'B-', 'B-', 'F', 'B-', 'D', 'B-', 'F', 'B-', 'D']\n",
            "[10, 10, 10, 5, 10, 2, 10, 5, 10, 2]\n",
            "Chopin/Etudes_op_10/1/xml_score.musicxml M7 5\n",
            "['B', 'B', 'B', 'F#', 'B', 'D#', 'B', 'F#', 'B', 'D#']\n",
            "[11, 11, 11, 6, 11, 3, 11, 6, 11, 3]\n",
            "Chopin/Sonata_2/4th/xml_score.musicxml P1 -5\n",
            "['F', 'F', 'G', 'G', 'B-', 'B-', 'D-', 'D-', 'E', 'E']\n",
            "[5, 5, 7, 7, 10, 10, 1, 1, 4, 4]\n",
            "Chopin/Sonata_2/4th/xml_score.musicxml A1 2\n",
            "['F#', 'F#', 'G#', 'G#', 'B', 'B', 'D', 'D', 'E#', 'E#']\n",
            "[6, 6, 8, 8, 11, 11, 2, 2, 5, 5]\n",
            "Chopin/Sonata_2/4th/xml_score.musicxml M2 -3\n",
            "['G', 'G', 'A', 'A', 'C', 'C', 'E-', 'E-', 'F#', 'F#']\n",
            "[7, 7, 9, 9, 0, 0, 3, 3, 6, 6]\n",
            "Chopin/Sonata_2/4th/xml_score.musicxml m3 -8\n",
            "['A-', 'A-', 'B-', 'B-', 'D-', 'D-', 'F-', 'F-', 'G', 'G']\n",
            "[8, 8, 10, 10, 1, 1, 4, 4, 7, 7]\n",
            "Chopin/Sonata_2/4th/xml_score.musicxml M3 -1\n",
            "['A', 'A', 'B', 'B', 'D', 'D', 'F', 'F', 'G#', 'G#']\n",
            "[9, 9, 11, 11, 2, 2, 5, 5, 8, 8]\n",
            "Chopin/Sonata_2/4th/xml_score.musicxml P4 -6\n",
            "['B-', 'B-', 'C', 'C', 'E-', 'E-', 'G-', 'G-', 'A', 'A']\n",
            "[10, 10, 0, 0, 3, 3, 6, 6, 9, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgHkMeoJdb42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3d172f-3f93-47ce-aa1b-e37a2afba24e"
      },
      "source": [
        "print(len(dict_dataset))\r\n",
        "\r\n",
        "c = Counter()\r\n",
        "for p in paths:\r\n",
        "    c[p.split(\"/\")[0]] +=1\r\n",
        "\r\n",
        "print(c)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2271\n",
            "Counter({'Bach': 59, 'Beethoven': 57, 'Chopin': 34, 'Schubert': 13, 'Haydn': 11, 'Schumann': 10, 'Mozart': 6, 'Brahms': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GRCM2W3qqeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53c8146-8b32-43df-cd69-b7423f1ceda2"
      },
      "source": [
        "# Ignore Brahms (only one piece)\r\n",
        "paths = [p for p in paths if p.split(\"/\")[0] !=\"Brahms\"]\r\n",
        "\r\n",
        "# Divide train and validation set\r\n",
        "path_train, path_validation = sklearn.model_selection.train_test_split(paths, test_size=0.2,stratify=[p.split(\"/\")[0] for p in paths ])\r\n",
        "print(\"Train and validation lenghts: \",len(path_train),len(path_validation))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train and validation lenghts:  152 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "KIZ2_bX1bom5",
        "outputId": "ae8d5b50-ed4d-4376-f9d6-e96c6aa73046"
      },
      "source": [
        "#need to find a better way to visualize this\r\n",
        "composers = list(set([p.split(\"/\")[0] for p in paths ]))\r\n",
        "print(composers)\r\n",
        "\r\n",
        "train_composer = [composers.index(p.split(\"/\")[0]) for p in path_train]\r\n",
        "val_composer = [composers.index(p.split(\"/\")[0]) for p in path_validation]\r\n",
        "\r\n",
        "_ = plt.hist([train_composer, val_composer], label=['train', 'validation'])\r\n",
        "_ = plt.legend(loc='upper left')\r\n",
        "_ = plt.xticks(list(range(7)), composers)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Haydn', 'Mozart', 'Bach', 'Beethoven', 'Schumann', 'Schubert', 'Chopin']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 374,
              "height": 248
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-qaT10ApkCY"
      },
      "source": [
        "## Transform the input into a convenient format for the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEYec2TDOWvj",
        "outputId": "1b69573b-cfeb-4dc9-8882-da42f9c25537"
      },
      "source": [
        "# Helper functions to feed the correct input into the NN \r\n",
        "\r\n",
        "PAD = \"<PAD>\"\r\n",
        "\r\n",
        "tag_to_ix = {p: accepted_pitches.index(p) for p in accepted_pitches}\r\n",
        "#add PADDING TAD\r\n",
        "tag_to_ix[PAD] = len(accepted_pitches)\r\n",
        "\r\n",
        "midi_to_ix = {m: m for m in range(12)}\r\n",
        "# #add PADDING TAD\r\n",
        "# midi_to_ix[PAD] = 12\r\n",
        "\r\n",
        "print(midi_to_ix[1])\r\n",
        "print(len(midi_to_ix))\r\n",
        "\r\n",
        "\r\n",
        "class Pitch2Diatonic():\r\n",
        "  def __call__(self, in_seq):\r\n",
        "    return [p for p in in_seq]\r\n",
        "\r\n",
        "class Diatonic2Int():\r\n",
        "  def __call__(self, in_seq):\r\n",
        "    idxs = [tag_to_ix[w] for w in in_seq]\r\n",
        "    return idxs\r\n",
        "\r\n",
        "class Int2Pitch():\r\n",
        "  def __call__(self, in_seq):\r\n",
        "    return [accepted_pitches[i] for i in in_seq]\r\n",
        "\r\n",
        "class OneHotEncoder():\r\n",
        "    def __init__(self, alphabet_len):\r\n",
        "        self.alphabet_len = alphabet_len\r\n",
        "        \r\n",
        "    def __call__(self, sample):\r\n",
        "        onehot = np.zeros([len(sample), self.alphabet_len])\r\n",
        "        tot_chars = len(sample)\r\n",
        "        onehot[np.arange(tot_chars), sample] = 1\r\n",
        "        return onehot\r\n",
        "        \r\n",
        "class ToTensorFloat():\r\n",
        "  def __call__(self, sample):\r\n",
        "    return torch.tensor(sample,dtype=torch.float)\r\n",
        "\r\n",
        "class ToTensorLong():\r\n",
        "  def __call__(self, sample):\r\n",
        "    return torch.tensor(sample,dtype=torch.long)\r\n",
        "\r\n",
        "\r\n",
        "pitches_len = len(accepted_pitches)\r\n",
        "midinote_len = 12\r\n",
        "\r\n",
        "### Define the preprocessing pipeline\r\n",
        "transform_diat = transforms.Compose([\r\n",
        "                                     Pitch2Diatonic(),\r\n",
        "                                     Diatonic2Int(),\r\n",
        "                                     ToTensorLong()])\r\n",
        "transform_chrom = transforms.Compose([\r\n",
        "                                      OneHotEncoder(len(midi_to_ix)),\r\n",
        "                                      ToTensorFloat()])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV9boYaToUs2",
        "outputId": "92bcd8d3-87a2-4d2c-8e92-4a106139f59f"
      },
      "source": [
        "# Create the dataset\r\n",
        "\r\n",
        "class PSDataset(Dataset):\r\n",
        "    def __init__(self, dict_dataset, paths, transf_c, transf_d, augment_dataset, truncate = None):\r\n",
        "        if augment_dataset:\r\n",
        "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset if e[\"original_path\"] in paths]\r\n",
        "            self.diatonic_sequences = [e[\"pitches\"]\r\n",
        "                                       for e in dict_dataset \r\n",
        "                                       if e[\"original_path\"] in paths]\r\n",
        "        else: #consider only non transposed pieces\r\n",
        "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset \r\n",
        "                                        if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\r\n",
        "            self.diatonic_sequences = [e[\"pitches\"]\r\n",
        "                                       for e in dict_dataset \r\n",
        "                                       if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\r\n",
        "        #the transformations to apply to data\r\n",
        "        self.transf_c = transf_c\r\n",
        "        self.transf_d = transf_d\r\n",
        "        self.truncate = truncate\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.chromatic_sequences)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        chromatic_seq = self.chromatic_sequences[idx]\r\n",
        "        diatonic_seq = self.diatonic_sequences[idx]\r\n",
        "        \r\n",
        "\r\n",
        "        #transform\r\n",
        "        chromatic_seq = self.transf_c(chromatic_seq)\r\n",
        "        diatonic_seq = self.transf_d(diatonic_seq)\r\n",
        "\r\n",
        "        if not self.truncate is None:\r\n",
        "            if len(diatonic_seq) > self.truncate:\r\n",
        "                chromatic_seq = chromatic_seq[0:self.truncate]\r\n",
        "                diatonic_seq = diatonic_seq[0:self.truncate]\r\n",
        "\r\n",
        "        #sanity check\r\n",
        "        assert len(chromatic_seq) == len(diatonic_seq)\r\n",
        "        seq_len = len(diatonic_seq)\r\n",
        "        \r\n",
        "        return chromatic_seq, diatonic_seq, seq_len\r\n",
        "\r\n",
        "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True)\r\n",
        "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\r\n",
        "\r\n",
        "print(len(train_dataset),len(validation_dataset))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# test if it works\r\n",
        "chrom, diat, l = next(iter(train_dataset))\r\n",
        "print([[i for i, j in enumerate(m) if j == 1][0] for m in chrom[0:30]])\r\n",
        "# print([diatonic_pitches[p.item()] for p in diat[0:30]])\r\n",
        "print([accepted_pitches[p.item()] for p in diat[0:30]])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1812 38\n",
            "[7, 7, 9, 7, 0, 4, 5, 4, 4, 2, 0, 5, 0, 11, 0, 0, 4, 7, 0, 1, 2, 11, 7, 2, 3, 4, 0, 0, 4, 0]\n",
            "['G', 'G', 'A', 'G', 'C', 'E', 'F', 'E', 'E', 'D', 'C', 'F', 'C', 'B', 'C', 'C', 'E', 'G', 'C', 'C#', 'D', 'B', 'G', 'D', 'D#', 'E', 'C', 'C', 'E', 'C']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAubyjw2LC8P",
        "outputId": "d6f8574f-8901-41e7-fd7a-9a0c6091eafa"
      },
      "source": [
        "def pad_collate(batch):\r\n",
        "    (xx, yy, l) = zip(*batch)\r\n",
        "    \r\n",
        "    xx_pad = pad_sequence(xx)\r\n",
        "    yy_pad = pad_sequence(yy, padding_value=tag_to_ix[PAD])\r\n",
        "\r\n",
        "    #sort the sequences by length\r\n",
        "    seq_lengths, perm_idx = torch.Tensor(l).sort(0, descending=True)\r\n",
        "    xx_pad = xx_pad[:,perm_idx,:]\r\n",
        "    yy_pad = yy_pad[:,perm_idx]\r\n",
        "\r\n",
        "    return xx_pad, yy_pad, seq_lengths\r\n",
        "\r\n",
        "data_loader = DataLoader(dataset=validation_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate)\r\n",
        "\r\n",
        "#something is wrong here looking at the output\r\n",
        "\r\n",
        "\r\n",
        "#test if it work\r\n",
        "for batch in data_loader:\r\n",
        "    print(batch[0].shape,batch[1].shape,batch[2])\r\n",
        "    print(batch[1])\r\n",
        "    break\r\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3124, 4, 12]) torch.Size([3124, 4]) tensor([3124., 1810., 1300.,  772.])\n",
            "tensor([[26, 21, 26, 26],\n",
            "        [26, 12, 24, 10],\n",
            "        [26, 21,  3, 26],\n",
            "        ...,\n",
            "        [26, 35, 35, 35],\n",
            "        [ 3, 35, 35, 35],\n",
            "        [26, 35, 35, 35]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O1OA1AjGWO-"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEkFBY5cUsmN"
      },
      "source": [
        "class RNNTagger(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\r\n",
        "        super(RNNTagger,self).__init__()    \r\n",
        "        \r\n",
        "        self.n_labels = n_labels\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "\r\n",
        "        # RNN layer. We're using a bidirectional GRU\r\n",
        "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \r\n",
        "                          bidirectional=True, num_layers=n_layers)\r\n",
        "        \r\n",
        "        # Output layer. The input will be two times\r\n",
        "        # the RNN size since we are using a bidirectional RNN.\r\n",
        "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\r\n",
        "    \r\n",
        "        # Loss function that we will use during training.\r\n",
        "        self.loss = torch.nn.CrossEntropyLoss(reduction='sum',ignore_index = tag_to_ix[PAD])\r\n",
        "        \r\n",
        "    def compute_outputs(self, sentences,sentences_len):\r\n",
        "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\r\n",
        "        rnn_out, _ = self.rnn(sentences)\r\n",
        "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\r\n",
        "\r\n",
        "        out = self.top_layer(rnn_out)\r\n",
        "       \r\n",
        "        # # Find the positions where the token is a dummy padding token.\r\n",
        "        # pad_mask = (sentences == self.pad_word_id).float()\r\n",
        "\r\n",
        "        # # For these positions, we add some large number in the column corresponding\r\n",
        "        # # to the dummy padding label.\r\n",
        "        # out[:, :, self.pad_label_id] += pad_mask*10000\r\n",
        "\r\n",
        "        return out\r\n",
        "                \r\n",
        "    def forward(self, sentences, labels, sentences_len):\r\n",
        "        # First computes the predictions, and then the loss function.\r\n",
        "        \r\n",
        "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\r\n",
        "        scores = self.compute_outputs(sentences,sentences_len)\r\n",
        "        \r\n",
        "        # Flatten the outputs and the gold-standard labels, to compute the loss.\r\n",
        "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\r\n",
        "        scores = scores.view(-1, self.n_labels)\r\n",
        "        labels = labels.view(-1)\r\n",
        "        return self.loss(scores, labels)\r\n",
        "\r\n",
        "    def predict(self, sentences,sentences_len):\r\n",
        "        # Compute the outputs from the linear units.\r\n",
        "        scores = self.compute_outputs(sentences,sentences_len)\r\n",
        "\r\n",
        "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\r\n",
        "        predicted = scores.argmax(dim=2)\r\n",
        "\r\n",
        "        # We transpose the prediction to (n_sentences, max_len), and convert it\r\n",
        "        # to a NumPy matrix.\r\n",
        "        return predicted.t().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE7itQ88Qx17"
      },
      "source": [
        "class RNNCRFTagger(nn.Module):\r\n",
        "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\r\n",
        "        super(RNNCRFTagger,self).__init__()    \r\n",
        "        \r\n",
        "        self.n_labels = n_labels\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "\r\n",
        "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \r\n",
        "                          bidirectional=True, num_layers=n_layers)\r\n",
        "\r\n",
        "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\r\n",
        "    \r\n",
        "        self.crf = CRF(self.n_labels)\r\n",
        "        \r\n",
        "    def compute_outputs(self, sentences,sentences_len):\r\n",
        "        ## should I initialize here??\r\n",
        "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\r\n",
        "        rnn_out, _ = self.rnn(sentences)\r\n",
        "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\r\n",
        "\r\n",
        "        out = self.top_layer(rnn_out)\r\n",
        "      \r\n",
        "        return out\r\n",
        "                \r\n",
        "    def forward(self, sentences, labels, sentences_len):\r\n",
        "        # Compute the outputs of the lower layers, which will be used as emission\r\n",
        "        # scores for the CRF.\r\n",
        "        scores = self.compute_outputs(sentences,sentences_len)\r\n",
        "\r\n",
        "        # We return the loss value. The CRF returns the log likelihood, but we return \r\n",
        "        # the *negative* log likelihood as the loss value.            \r\n",
        "        # PyTorch's optimizers *minimize* the loss, while we want to *maximize* the\r\n",
        "        # log likelihood.\r\n",
        "\r\n",
        "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\r\n",
        "        pad_mask = pad_mask.byte().to(device)\r\n",
        "        return -self.crf(scores, labels, mask = pad_mask )\r\n",
        "            \r\n",
        "    def predict(self, sentences,sentences_len):\r\n",
        "        # Compute the emission scores, as above.\r\n",
        "        scores = self.compute_outputs(sentences,sentences_len)\r\n",
        "\r\n",
        "        # Apply the Viterbi algorithm to get the predictions. This implementation returns\r\n",
        "        # the result as a list of lists (not a tensor), corresponding to a matrix\r\n",
        "        # of shape (n_sentences, max_len).\r\n",
        "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\r\n",
        "        pad_mask = pad_mask.byte().to(device)\r\n",
        "        return self.crf.decode(scores,mask = pad_mask)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXixmVQfvw8T"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m_nj4HCuCe1"
      },
      "source": [
        "# TODO: search over the best hyperparameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAMSIlw0AJb6"
      },
      "source": [
        "def training_loop(model, optimizer, train_dataloader, val_dataloader, n_epochs):\r\n",
        "    history = defaultdict(list)  \r\n",
        "    for i_epoch in range(1,n_epochs +1):\r\n",
        "        t0 = time.time()\r\n",
        "        loss_sum = 0\r\n",
        "        accuracy_sum = 0\r\n",
        "        model.train()\r\n",
        "        for seqs, targets, lens in train_dataloader: #seqs, targets, lens are batches\r\n",
        "            seqs, targets = seqs.to(device), targets.to(device)\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            loss = model(seqs,targets,lens) / sum(lens) #normalize for the number of symbol considered (without padding)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            loss_sum += loss.item()\r\n",
        "\r\n",
        "            predicted = model.predict(seqs,lens)\r\n",
        "            for i,p in enumerate(predicted):\r\n",
        "                acc= accuracy_score(p,targets[:,i][:len(p)].cpu()) #compute the accuracy without considering the padding\r\n",
        "                accuracy_sum += acc/len(lens) #normalize according to the number of sequences in the batch\r\n",
        "\r\n",
        "        train_loss = loss_sum/len(train_dataloader)\r\n",
        "        train_accuracy = accuracy_sum/len(train_dataloader) #normalize according to the number of batches\r\n",
        "        history[\"train_loss\"].append(train_loss)\r\n",
        "        history[\"train_accuracy\"].append(train_accuracy)\r\n",
        "\r\n",
        "\r\n",
        "        # Evaluate on the validation set.\r\n",
        "        model.eval()\r\n",
        "        all_predicted = []\r\n",
        "        all_targets = []\r\n",
        "        with torch.no_grad():\r\n",
        "            for seqs,targets, lens in val_dataloader:\r\n",
        "                # Predict the model's output on a batch.\r\n",
        "                predicted = model.predict(seqs.to(device),lens)                   \r\n",
        "                # Update the evaluation statistics.\r\n",
        "                for i,p in enumerate(predicted):\r\n",
        "                    all_predicted.append(torch.Tensor(p))\r\n",
        "                    all_targets.append(targets[0:int(lens[i]),i])\r\n",
        "                \r\n",
        "        # Compute the overall accuracy for the validation set\r\n",
        "        val_accuracy = accuracy_score(torch.cat(all_predicted),torch.cat(all_targets))\r\n",
        "        history[\"val_accuracy\"].append(val_accuracy)\r\n",
        "\r\n",
        "        #save the model\r\n",
        "        torch.save(model, \"model_temp_epoch{}.pkl\".format(i_epoch))\r\n",
        "        files.download(\"model_temp_epoch{}.pkl\".format(i_epoch))\r\n",
        "\r\n",
        "    \r\n",
        "        t1 = time.time()\r\n",
        "        print(f'Epoch {i_epoch}: train loss = {train_loss:.4f}, train_accuracy: {train_accuracy:.4f},val_accuracy: {val_accuracy:.4f}, time = {t1-t0:.4f}')\r\n",
        "    return history"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "2g2st8znpGW_",
        "outputId": "fe232e42-e270-4f5d-9bd8-718bba5e7151"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\r\n",
        "print(f\"Training device: {device}\")\r\n",
        "\r\n",
        "n_epochs = 50\r\n",
        "HIDDEN_DIM = 72\r\n",
        "LEARNING_WEIGHT = 0.05\r\n",
        "WEIGHT_DECAY = 1e-4\r\n",
        "BATCH_SIZE = 16\r\n",
        "\r\n",
        "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True, truncate = None)\r\n",
        "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\r\n",
        "\r\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\r\n",
        "val_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\r\n",
        "\r\n",
        "model = RNNCRFTagger(12,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\r\n",
        "# model = RNNTagger(12,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\r\n",
        "model = model.to(device)\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_WEIGHT, weight_decay=WEIGHT_DECAY)\r\n",
        "# otimizer = torch.optim.Adam(model.parameters(),lr = 0.05, weight_decay=1e-4)\r\n",
        "\r\n",
        "history = training_loop(model,optimizer,train_dataloader,val_dataloader, n_epochs)\r\n",
        "\r\n",
        "# After the final evaluation, we print more detailed evaluation statistics,\r\n",
        "plt.plot(history['train_loss'])\r\n",
        "plt.plot(history['train_accuracy'])\r\n",
        "plt.plot(history['val_accuracy'])\r\n",
        "plt.legend(['training loss', 'training accuracy', 'validation_accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training device: cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6464265f-a50d-498a-999b-9feda731c406\", \"model_temp_epoch1.pkl\", 63501)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 3.3616, train_accuracy: 0.1200,val_accuracy: 0.2341, time = 1238.8340\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1aee510a-6ab7-478c-a340-fef98e81df25\", \"model_temp_epoch2.pkl\", 63501)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss = 2.9503, train_accuracy: 0.2989,val_accuracy: 0.4551, time = 1244.3712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9be3adf6-dd26-45fb-8532-476fc6fb2999\", \"model_temp_epoch3.pkl\", 63501)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss = 2.7448, train_accuracy: 0.4723,val_accuracy: 0.5220, time = 1226.7938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_841d9d5f-5257-4b55-b421-48084137cf5d\", \"model_temp_epoch4.pkl\", 63501)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss = 2.5715, train_accuracy: 0.5558,val_accuracy: 0.6363, time = 1273.9243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d149ff2d-c6a1-4b68-93ea-26ae63bca3ff\", \"model_temp_epoch5.pkl\", 63501)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss = 2.3452, train_accuracy: 0.6429,val_accuracy: 0.7307, time = 1241.3303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e755f4f5-69aa-466c-a331-46d2358d1bcb\", \"model_temp_epoch6.pkl\", 63501)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6: train loss = 2.0189, train_accuracy: 0.7315,val_accuracy: 0.7941, time = 1300.1969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9ca7a782-7223-4ff1-a128-e7efafa8a6fc\", \"model_temp_epoch7.pkl\", 63501)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7: train loss = 1.6427, train_accuracy: 0.7951,val_accuracy: 0.8396, time = 1277.9057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tTv2BrGbvSHh",
        "outputId": "801ff32d-24dc-4434-a436-17d9ca832214"
      },
      "source": [
        "torch.save(model, \"model_asap_crf300.pkl\")\r\n",
        "files.download(\"model_asap_crf300.pkl\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2becd0ee-42f6-49a2-a019-3deadfab3a8b\", \"model_asap_crf300.pkl\", 63501)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXcmLpCKt28l"
      },
      "source": [
        "## Test on Mdata dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BacUqgD5usGL"
      },
      "source": [
        "# load the dataset\r\n",
        "with open('/content/pitch-spelling/datasets/musedata.pkl', 'rb') as fid:\r\n",
        "     full_mdata_dict_dataset = pickle.load( fid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgaUwW2fuwg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89fc5f7d-884a-4ee6-fc34-b3d512f0c4c7"
      },
      "source": [
        "mdata_paths = list(set([e[\"original_path\"] for e in full_mdata_dict_dataset ]))\r\n",
        "\r\n",
        "# # remove the symbphony No.100 from Haydn because of the enharmonic transposition\r\n",
        "# paths.remove(\"datasets\\\\opnd\\\\haydndoversyms-10004m.opnd-m\")\r\n",
        "\r\n",
        "# print(paths)\r\n",
        "print(len(mdata_paths), \"different pieces\")\r\n",
        "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_mdata_dict_dataset ]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "216 different pieces\n",
            "Average number of notes:  858.6319771007974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Fg6gJKvNLt"
      },
      "source": [
        "mdata_dataset = PSDataset(full_mdata_dict_dataset,mdata_paths, transform_chrom,transform_diat,False)\r\n",
        "mdata_dataloader  = DataLoader(mdata_dataset,  batch_size=64, shuffle=False, collate_fn=pad_collate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml905Mtdvj-T"
      },
      "source": [
        "all_inputs = []\r\n",
        "all_outputs = []\r\n",
        "all_targets = []\r\n",
        "model.eval() # Evaluation mode (e.g. disable dropout)\r\n",
        "with torch.no_grad(): # Disable gradient tracking\r\n",
        "  for seqs, targets,lens in mdata_dataloader:\r\n",
        "    # Move data to device\r\n",
        "    seqs = seqs.to(device)\r\n",
        "\r\n",
        "    # Predict the model's output on a batch.\r\n",
        "    predicted = model.predict(seqs,lens)                   \r\n",
        "    # Update the evaluation statistics.\r\n",
        "    for i,p in enumerate(predicted):\r\n",
        "        all_inputs.append(torch.argmax(seqs[0:int(lens[i]),i,:].cpu(),1).numpy())\r\n",
        "        all_outputs.append(torch.Tensor(p))\r\n",
        "        all_targets.append(targets[0:int(lens[i]),i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsefdSHxvrWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33785b90-5e03-4a6d-86dd-92b6b763a505"
      },
      "source": [
        "# Divide accuracy according to author\r\n",
        "authors = []\r\n",
        "\r\n",
        "for sequence in all_inputs:\r\n",
        "    author = [e[\"original_path\"].split(\"\\\\\")[-1][:3] for e in full_mdata_dict_dataset\r\n",
        "              if len(e[\"midi_number\"]) == len(sequence) and\r\n",
        "              list(e[\"midi_number\"]) ==list(sequence) ]\r\n",
        "    # assert len(author) == 1\r\n",
        "    authors.append(author[0])\r\n",
        "\r\n",
        "considered_authors = list(set(authors))\r\n",
        "print(considered_authors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bac', 'hay', 'viv', 'cor', 'han', 'moz', 'tel', 'bee']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgNt_yG7vrfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8473393f-dac6-4930-9d9e-da9c1046f1ab"
      },
      "source": [
        "errors_per_author = {}\r\n",
        "accuracy_per_author = {}\r\n",
        "for ca in considered_authors:\r\n",
        "    # ca_inputs = torch.cat([all_inputs[i] for i,a in enumerate(authors) if a == ca])\r\n",
        "    ca_outputs = torch.cat([all_outputs[i] for i,a in enumerate(authors) if a == ca])\r\n",
        "    ca_targets = torch.cat([all_targets[i] for i,a in enumerate(authors) if a == ca])\r\n",
        "    # print(ca_inputs.shape,ca_outputs.shape,ca_targets.shape,ca_predicted_pitches.shape)\r\n",
        "    ca_acc = accuracy_score(ca_outputs,ca_targets)\r\n",
        "    accuracy_per_author[ca] = float(ca_acc)\r\n",
        "    errors_per_author[ca] = int(len(ca_targets) - sum(torch.eq(ca_outputs,ca_targets)))\r\n",
        "\r\n",
        "print(errors_per_author)\r\n",
        "print(accuracy_per_author)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bac': 124, 'hay': 371, 'viv': 110, 'cor': 22, 'han': 67, 'moz': 184, 'tel': 64, 'bee': 270}\n",
            "{'bac': 0.9949398082024077, 'hay': 0.9848509595753369, 'viv': 0.9955096542433768, 'cor': 0.999101784183236, 'han': 0.997265306122449, 'moz': 0.9924879562341798, 'tel': 0.9973877551020408, 'bee': 0.9889764422488058}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5s0d56evrje"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVvP1eH8vrl3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}